{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 1. å¯¼å…¥ä¾èµ–å’Œæ•°æ®åº“\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š æ­£åœ¨åŠ è½½æ•°æ®é›†...\n",
      "âœ… æ•°æ®é›†åŠ è½½å®Œæˆï¼Œå…±80æ¡è®°å½•\n",
      "\n",
      "ğŸ“‹ æ•°æ®é›†æ ·æœ¬:\n",
      "   ç›®æ ‡è¯: substance\n",
      "   ç±»åˆ«: philosophy\n",
      "   ç¦ç”¨è¯: ['center', 'centre', 'kernel', 'marrow', 'matter']\n",
      "   è¯ä¹‰æ•°: 7\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "from typing import Dict, List, Any\n",
    "from datetime import datetime\n",
    "\n",
    "# åŠ è½½æ•°æ®é›†\n",
    "def load_dataset(dataset_path: str = \"quick80_dataset.json\") -> List[Dict]:\n",
    "    \"\"\"åŠ è½½Tabooæ•°æ®é›†\"\"\"\n",
    "    with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# åŠ è½½æ•°æ®é›†\n",
    "print(\"ğŸ“š æ­£åœ¨åŠ è½½æ•°æ®é›†...\")\n",
    "dataset = load_dataset()\n",
    "print(f\"âœ… æ•°æ®é›†åŠ è½½å®Œæˆï¼Œå…±{len(dataset)}æ¡è®°å½•\")\n",
    "\n",
    "# æ˜¾ç¤ºæ•°æ®é›†æ ·æœ¬\n",
    "print(\"\\nğŸ“‹ æ•°æ®é›†æ ·æœ¬:\")\n",
    "sample = random.choice(dataset)\n",
    "print(f\"   ç›®æ ‡è¯: {sample['target']}\")\n",
    "print(f\"   ç±»åˆ«: {sample.get('category', 'unknown')}\")\n",
    "print(f\"   ç¦ç”¨è¯: {sample['taboo']}\")\n",
    "print(f\"   è¯ä¹‰æ•°: {len(sample.get('senses', []))}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 2. æ•°æ®é›†ç»Ÿè®¡åˆ†æ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š æ•°æ®é›†åŸºæœ¬ç»Ÿè®¡:\n",
      "========================================\n",
      "\n",
      "ğŸ·ï¸ ç±»åˆ«åˆ†å¸ƒ (Top 5):\n",
      "   1. general: 55 æ¡ (68.8%)\n",
      "   2. philosophy: 8 æ¡ (10.0%)\n",
      "   3. finance: 7 æ¡ (8.8%)\n",
      "   4. chemistry: 5 æ¡ (6.2%)\n",
      "   5. cs: 5 æ¡ (6.2%)\n",
      "\n",
      "ğŸš« ç¦ç”¨è¯ç»Ÿè®¡:\n",
      "   å¹³å‡æ•°é‡: 5.0\n",
      "   èŒƒå›´: 5 - 5\n",
      "\n",
      "ğŸ’­ è¯ä¹‰ç»Ÿè®¡:\n",
      "   å¹³å‡æ•°é‡: 1.9\n",
      "   èŒƒå›´: 1 - 23\n",
      "\n",
      "âœ… æ•°æ®é›†ç»Ÿè®¡å®Œæˆï¼Œè´¨é‡è‰¯å¥½ï¼Œå¯ç”¨äºå®éªŒ\n",
      "\n",
      "ğŸ² éšæœºç§å­å·²è®¾ç½®ä¸º 240ï¼Œç¡®ä¿å®éªŒå¯å¤ç°\n"
     ]
    }
   ],
   "source": [
    "# æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯\n",
    "print(\"ğŸ“Š æ•°æ®é›†åŸºæœ¬ç»Ÿè®¡:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡\n",
    "categories = {}\n",
    "taboo_counts = []\n",
    "sense_counts = []\n",
    "\n",
    "for item in dataset:\n",
    "    # ç»Ÿè®¡ç±»åˆ«\n",
    "    category = item.get('category', 'unknown')\n",
    "    categories[category] = categories.get(category, 0) + 1\n",
    "    \n",
    "    # ç»Ÿè®¡ç¦ç”¨è¯æ•°é‡\n",
    "    taboo_counts.append(len(item.get('taboo', [])))\n",
    "    \n",
    "    # ç»Ÿè®¡è¯ä¹‰æ•°é‡\n",
    "    sense_counts.append(len(item.get('senses', [])))\n",
    "\n",
    "print(f\"\\nğŸ·ï¸ ç±»åˆ«åˆ†å¸ƒ (Top 5):\")\n",
    "sorted_categories = sorted(categories.items(), key=lambda x: x[1], reverse=True)\n",
    "for i, (category, count) in enumerate(sorted_categories[:5], 1):\n",
    "    percentage = count / len(dataset) * 100\n",
    "    print(f\"   {i}. {category}: {count} æ¡ ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nğŸš« ç¦ç”¨è¯ç»Ÿè®¡:\")\n",
    "print(f\"   å¹³å‡æ•°é‡: {sum(taboo_counts) / len(taboo_counts):.1f}\")\n",
    "print(f\"   èŒƒå›´: {min(taboo_counts)} - {max(taboo_counts)}\")\n",
    "\n",
    "print(f\"\\nğŸ’­ è¯ä¹‰ç»Ÿè®¡:\")\n",
    "print(f\"   å¹³å‡æ•°é‡: {sum(sense_counts) / len(sense_counts):.1f}\")\n",
    "print(f\"   èŒƒå›´: {min(sense_counts)} - {max(sense_counts)}\")\n",
    "\n",
    "print(f\"\\nâœ… æ•°æ®é›†ç»Ÿè®¡å®Œæˆï¼Œè´¨é‡è‰¯å¥½ï¼Œå¯ç”¨äºå®éªŒ\")\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­ç”¨äºå®éªŒ\n",
    "random.seed(240)\n",
    "print(\"\\nğŸ² éšæœºç§å­å·²è®¾ç½®ä¸º 240ï¼Œç¡®ä¿å®éªŒå¯å¤ç°\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 3. APIå®¢æˆ·ç«¯è®¾ç½®\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… APIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ\n",
      "ğŸ¤– åŸå§‹æµ‹è¯•æ¨¡å‹: 4 ä¸ª\n",
      "   1. openai/gpt-4o\n",
      "   2. google/gemini-2.5-flash\n",
      "   3. deepseek/deepseek-chat-v3-0324\n",
      "   4. anthropic/claude-sonnet-4\n",
      "\n",
      "ğŸŒ™ Kimiå®éªŒæ¨¡å‹: 5 ä¸ª\n",
      "   1. moonshotai/kimi-k2\n",
      "   2. openai/gpt-4o\n",
      "   3. google/gemini-2.5-flash\n",
      "   4. deepseek/deepseek-chat-v3-0324\n",
      "   5. anthropic/claude-sonnet-4\n",
      "\n",
      "ğŸ“Š Kimiå®éªŒé…ç½®:\n",
      "   â€¢ æ€»æ¨¡å‹æ•°: 5\n",
      "   â€¢ æ¨¡å‹å¯¹ç»„åˆ: 5Ã—5 = 25\n",
      "   â€¢ åŒ…å«è‡ªå¯¹è‡ªç»„åˆ: 5ä¸ª\n",
      "   â€¢ 5+5-1å¯¹å®éªŒ: æˆ‘ä»¬å°†è¿è¡Œæ‰€æœ‰25å¯¹ç»„åˆ âœ…\n"
     ]
    }
   ],
   "source": [
    "# è®¾ç½®APIå®¢æˆ·ç«¯\n",
    "def load_api_keys(keys_path: str = \"api_keys.json\") -> Dict[str, str]:\n",
    "    \"\"\"åŠ è½½APIå¯†é’¥\"\"\"\n",
    "    with open(keys_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "class OpenRouterClient:\n",
    "    \"\"\"OpenRouter APIå®¢æˆ·ç«¯\"\"\"\n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "        self.headers = {\n",
    "            \"Authorization\": f\"Bearer {api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "    \n",
    "    def call_model(self, model: str, messages: List[Dict[str, str]], temperature: float = 0.3) -> str:\n",
    "        \"\"\"è°ƒç”¨æ¨¡å‹API\"\"\"\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": temperature,\n",
    "            \"max_tokens\": 2000\n",
    "        }\n",
    "        response = requests.post(self.base_url, headers=self.headers, json=payload, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        content = result['choices'][0]['message']['content'].strip()\n",
    "        \n",
    "        # é˜²æ­¢ä¹±ç ï¼šåªä¿ç•™ASCIIå¯æ‰“å°å­—ç¬¦\n",
    "        import re\n",
    "        content = re.sub(r'[^\\x20-\\x7E]', '', content)\n",
    "        return content\n",
    "\n",
    "# åˆå§‹åŒ–APIå®¢æˆ·ç«¯\n",
    "try:\n",
    "    api_keys = load_api_keys()\n",
    "    client = OpenRouterClient(api_keys[\"OPENROUTER_API_KEY\"])\n",
    "    print(\"âœ… APIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ APIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}\")\n",
    "    client = None\n",
    "\n",
    "# å®šä¹‰æµ‹è¯•æ¨¡å‹ - åŒ…å«Kimiæ¨¡å‹\n",
    "TEST_MODELS = [\n",
    "    \"openai/gpt-4o\",\n",
    "    \"google/gemini-2.5-flash\", \n",
    "    \"deepseek/deepseek-chat-v3-0324\",\n",
    "    \"anthropic/claude-sonnet-4\"\n",
    "]\n",
    "\n",
    "# Kimiå®éªŒä¸“ç”¨æ¨¡å‹åˆ—è¡¨ (5ä¸ªæ¨¡å‹)\n",
    "KIMI_MODELS = [\n",
    "    \"moonshotai/kimi-k2\",  # Kimiæ¨¡å‹\n",
    "    \"openai/gpt-4o\",\n",
    "    \"google/gemini-2.5-flash\", \n",
    "    \"deepseek/deepseek-chat-v3-0324\",\n",
    "    \"anthropic/claude-sonnet-4\"\n",
    "]\n",
    "\n",
    "print(f\"ğŸ¤– åŸå§‹æµ‹è¯•æ¨¡å‹: {len(TEST_MODELS)} ä¸ª\")\n",
    "for i, model in enumerate(TEST_MODELS, 1):\n",
    "    print(f\"   {i}. {model}\")\n",
    "\n",
    "print(f\"\\nğŸŒ™ Kimiå®éªŒæ¨¡å‹: {len(KIMI_MODELS)} ä¸ª\")\n",
    "for i, model in enumerate(KIMI_MODELS, 1):\n",
    "    print(f\"   {i}. {model}\")\n",
    "    \n",
    "print(f\"\\nğŸ“Š Kimiå®éªŒé…ç½®:\")\n",
    "print(f\"   â€¢ æ€»æ¨¡å‹æ•°: {len(KIMI_MODELS)}\")\n",
    "print(f\"   â€¢ æ¨¡å‹å¯¹ç»„åˆ: {len(KIMI_MODELS)}Ã—{len(KIMI_MODELS)} = {len(KIMI_MODELS)**2}\")\n",
    "print(f\"   â€¢ åŒ…å«è‡ªå¯¹è‡ªç»„åˆ: {len(KIMI_MODELS)}ä¸ª\")\n",
    "print(f\"   â€¢ 5+5-1å¯¹å®éªŒ: æˆ‘ä»¬å°†è¿è¡Œæ‰€æœ‰25å¯¹ç»„åˆ âœ…\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 4. é€šç”¨å®éªŒæ–¹æ³•\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ: 80 æ¡è®°å½•\n",
      "ğŸ“ æ•°æ®é›†è·¯å¾„: quick80_dataset.json\n",
      "\n",
      "ğŸ“‹ æ•°æ®æ ·æœ¬:\n",
      "   ç›®æ ‡è¯: behaviorism\n",
      "   ç¦ç”¨è¯: ['approach', 'behavior', 'emphasizes', 'measurable', 'observable']\n",
      "   ç±»åˆ«: philosophy\n",
      "   å®šä¹‰: an approach to psychology that emphasizes observable measurable behavior...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Any\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# åŠ è½½æ•°æ®é›†\n",
    "def load_dataset(dataset_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"åŠ è½½Tabooæ¸¸æˆæ•°æ®é›†\"\"\"\n",
    "    with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "        dataset = json.load(f)\n",
    "    return dataset\n",
    "\n",
    "# åŠ è½½é¢„ç”Ÿæˆçš„æ•°æ®é›†\n",
    "DATASET_PATH = \"quick80_dataset.json\"\n",
    "dataset = load_dataset(DATASET_PATH)\n",
    "print(f\"âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ: {len(dataset)} æ¡è®°å½•\")\n",
    "print(f\"ğŸ“ æ•°æ®é›†è·¯å¾„: {DATASET_PATH}\")\n",
    "\n",
    "# æ˜¾ç¤ºç¬¬ä¸€ä¸ªæ ·æœ¬\n",
    "if dataset:\n",
    "    sample = dataset[0]\n",
    "    print(f\"\\nğŸ“‹ æ•°æ®æ ·æœ¬:\")\n",
    "    print(f\"   ç›®æ ‡è¯: {sample['target']}\")\n",
    "    print(f\"   ç¦ç”¨è¯: {sample['taboo']}\")\n",
    "    print(f\"   ç±»åˆ«: {sample.get('category', 'N/A')}\")\n",
    "    if sample.get('senses'):\n",
    "        print(f\"   å®šä¹‰: {sample['senses'][0].get('definition', 'N/A')[:100]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ: 300 æ¡è®°å½•\n",
      "ğŸ“ æ•°æ®é›†è·¯å¾„: data/dataset.json\n",
      "\n",
      "ğŸ“‹ æ•°æ®æ ·æœ¬:\n",
      "   ç›®æ ‡è¯: crotonbug\n",
      "   ç¦ç”¨è¯: ['common', 'croton', 'europe', 'german', 'states']\n",
      "   ç±»åˆ«: general\n",
      "   å®šä¹‰: small light-brown cockroach brought to United States from Europe; a common household pest...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Any\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# åŠ è½½æ•°æ®é›†\n",
    "def load_dataset(dataset_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"åŠ è½½Tabooæ¸¸æˆæ•°æ®é›†\"\"\"\n",
    "    with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "        dataset = json.load(f)\n",
    "    return dataset\n",
    "\n",
    "# åŠ è½½é¢„ç”Ÿæˆçš„æ•°æ®é›†\n",
    "DATASET_PATH = \"data/dataset.json\"\n",
    "dataset = load_dataset(DATASET_PATH)\n",
    "print(f\"âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ: {len(dataset)} æ¡è®°å½•\")\n",
    "print(f\"ğŸ“ æ•°æ®é›†è·¯å¾„: {DATASET_PATH}\")\n",
    "\n",
    "# æ˜¾ç¤ºç¬¬ä¸€ä¸ªæ ·æœ¬\n",
    "if dataset:\n",
    "    sample = dataset[0]\n",
    "    print(f\"\\nğŸ“‹ æ•°æ®æ ·æœ¬:\")\n",
    "    print(f\"   ç›®æ ‡è¯: {sample['target']}\")\n",
    "    print(f\"   ç¦ç”¨è¯: {sample['taboo']}\")\n",
    "    print(f\"   ç±»åˆ«: {sample.get('category', 'N/A')}\")\n",
    "    if sample.get('senses'):\n",
    "        print(f\"   å®šä¹‰: {sample['senses'][0].get('definition', 'N/A')[:100]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å¢å¼ºç‰ˆæ¸¸æˆå‡½æ•°å·²å®šä¹‰ï¼ˆåŒ…å«ä¸¥æ ¼çš„taboo violationæ£€æŸ¥ï¼‰\n"
     ]
    }
   ],
   "source": [
    "# æ ¸å¿ƒæ¸¸æˆé€»è¾‘å’Œé€šç”¨å®éªŒè¿è¡Œå™¨\n",
    "\n",
    "def enhanced_play_taboo_game(client, hinter_model, guesser_model, target_word, taboo_words, max_turns=5):\n",
    "    \"\"\"å¢å¼ºç‰ˆTabooæ¸¸æˆï¼ŒåŒ…å«taboo violationæ£€æŸ¥\"\"\"\n",
    "    \n",
    "    conversation_history = []\n",
    "    taboo_list = ', '.join(taboo_words)\n",
    "    \n",
    "    # ç³»ç»Ÿæç¤º\n",
    "    hinter_system = f\"\"\"You are playing a Taboo word game as the Hinter.\n",
    "\n",
    "CRITICAL FORMAT REQUIREMENT:\n",
    "- You MUST start your response with exactly '[CLUE]' (including square brackets)\n",
    "- Do NOT add any text before [CLUE]\n",
    "- Example: [CLUE] This is a large mammal with a trunk\n",
    "\n",
    "GAME RULES:\n",
    "1. NEVER use any of these taboo words: {taboo_list}\n",
    "2. Give helpful clues to help the guesser find the target word\n",
    "3. You can see the conversation history and build on previous clues\n",
    "4. Be creative but follow the format exactly\n",
    "5. Use BRITISH ENGLISH spelling (e.g., colour not color, centre not center)\n",
    "\n",
    "Target word: {target_word}\n",
    "Taboo words (ABSOLUTELY FORBIDDEN): {taboo_list}\"\"\"\n",
    "\n",
    "    guesser_system = \"\"\"You are playing a Taboo word game as the Guesser.\n",
    "\n",
    "CRITICAL FORMAT REQUIREMENT:\n",
    "- You MUST start your response with exactly '[GUESS]' (including square brackets)\n",
    "- Do NOT add any text before [GUESS]\n",
    "- Example: [GUESS] elephant\n",
    "\n",
    "GAME RULES:\n",
    "1. Make your best guess based on all the clues you've received\n",
    "2. You can see the conversation history\n",
    "3. Give only ONE word as your guess after [GUESS]\n",
    "4. Use BRITISH ENGLISH spelling (e.g., colour not color, centre not center)\"\"\"\n",
    "\n",
    "    # è®°å½•ç»Ÿè®¡ä¿¡æ¯\n",
    "    total_hinter_attempts = 0\n",
    "    total_guesser_attempts = 0\n",
    "    format_errors = []\n",
    "    hinter_failed_outputs = []\n",
    "    guesser_failed_outputs = []\n",
    "\n",
    "    for turn in range(1, max_turns + 1):\n",
    "        # æ„å»ºHinteræç¤º\n",
    "        if turn == 1:\n",
    "            hinter_prompt = f\"{hinter_system}\\n\\nProvide your first clue:\"\n",
    "        else:\n",
    "            history_text = \"\\n\".join([f\"Turn {i}: {msg}\" for i, msg in enumerate(conversation_history, 1)])\n",
    "            hinter_prompt = f\"{hinter_system}\\n\\nConversation so far:\\n{history_text}\\n\\nThe guesser hasn't found the word yet. Provide your next clue:\"\n",
    "        \n",
    "        # Hinterç»™å‡ºçº¿ç´¢ï¼ˆå¸¦é‡è¯•ï¼‰\n",
    "        hinter_result = robust_api_call(client, hinter_model, hinter_prompt, \"[CLUE]\", max_retries=3)\n",
    "        total_hinter_attempts += hinter_result['attempts']\n",
    "        \n",
    "        if hinter_result.get('failed_outputs'):\n",
    "            hinter_failed_outputs.extend(hinter_result['failed_outputs'])\n",
    "        \n",
    "        if not hinter_result['success']:\n",
    "            error_type = \"FORMAT_FAILURE\" if \"FORMAT_ERROR_EXCEEDED\" in str(hinter_result.get('response', '')) else \"API_FAILURE\"\n",
    "            format_errors.append(f\"Turn {turn} Hinter: {hinter_result['error']}\")\n",
    "            \n",
    "            return {\n",
    "                'success': False,\n",
    "                'turns': turn,\n",
    "                'conversation': conversation_history,\n",
    "                'final_guess': f\"HINTER_{error_type}\",\n",
    "                'error': f\"{error_type}: {hinter_result['error']}\",\n",
    "                'failure_reason': error_type,\n",
    "                'total_hinter_attempts': total_hinter_attempts,\n",
    "                'total_guesser_attempts': total_guesser_attempts,\n",
    "                'format_errors': format_errors,\n",
    "                'hinter_failed_outputs': hinter_failed_outputs,\n",
    "                'guesser_failed_outputs': guesser_failed_outputs,\n",
    "                'all_hints': [msg for msg in conversation_history if msg.startswith('Hinter:')],\n",
    "                'all_guesses': [msg for msg in conversation_history if msg.startswith('Guesser:')]\n",
    "            }\n",
    "        \n",
    "        # æå–çº¿ç´¢å¹¶æ£€æŸ¥taboo violation\n",
    "        hint_text = extract_clue_text(hinter_result['response'])\n",
    "        \n",
    "        # ğŸš¨ å…³é”®ï¼šæ£€æŸ¥æ˜¯å¦è¿åtaboo wordsè§„åˆ™\n",
    "        taboo_violated = check_taboo_violation(hint_text, taboo_words)\n",
    "        if taboo_violated:\n",
    "            # è¿è§„ç«‹å³å¤±è´¥ï¼\n",
    "            return {\n",
    "                'success': False,\n",
    "                'turns': turn,\n",
    "                'conversation': conversation_history,\n",
    "                'final_guess': 'TABOO_VIOLATION: Hinterè¿åè§„åˆ™',\n",
    "                'error': f'TABOO_VIOLATION: Hinteråœ¨ç¬¬{turn}è½®è¿åè§„åˆ™ï¼Œè¯´äº†ç¦ç”¨è¯: {hint_text}',\n",
    "                'failure_reason': 'TABOO_VIOLATION',\n",
    "                'taboo_violation_turn': turn,\n",
    "                'taboo_violation_hint': hint_text,\n",
    "                'total_hinter_attempts': total_hinter_attempts,\n",
    "                'total_guesser_attempts': total_guesser_attempts,\n",
    "                'format_errors': format_errors,\n",
    "                'hinter_failed_outputs': hinter_failed_outputs,\n",
    "                'guesser_failed_outputs': guesser_failed_outputs,\n",
    "                'all_hints': [msg for msg in conversation_history if msg.startswith('Hinter:')],\n",
    "                'all_guesses': [msg for msg in conversation_history if msg.startswith('Guesser:')]\n",
    "            }\n",
    "        \n",
    "        conversation_history.append(f\"Hinter: {hinter_result['response']}\")\n",
    "        \n",
    "        # æ„å»ºGuesseræç¤º\n",
    "        history_text = \"\\n\".join([f\"Turn {i}: {msg}\" for i, msg in enumerate(conversation_history, 1)])\n",
    "        guesser_prompt = f\"{guesser_system}\\n\\nConversation so far:\\n{history_text}\\n\\nWhat is your guess?\"\n",
    "        \n",
    "        # Guesserè¿›è¡ŒçŒœæµ‹ï¼ˆå¸¦é‡è¯•ï¼‰\n",
    "        guesser_result = robust_api_call(client, guesser_model, guesser_prompt, \"[GUESS]\", max_retries=3)\n",
    "        total_guesser_attempts += guesser_result['attempts']\n",
    "        \n",
    "        if guesser_result.get('failed_outputs'):\n",
    "            guesser_failed_outputs.extend(guesser_result['failed_outputs'])\n",
    "        \n",
    "        if not guesser_result['success']:\n",
    "            error_type = \"FORMAT_FAILURE\" if \"FORMAT_ERROR_EXCEEDED\" in str(guesser_result.get('response', '')) else \"API_FAILURE\"\n",
    "            format_errors.append(f\"Turn {turn} Guesser: {guesser_result['error']}\")\n",
    "            \n",
    "            return {\n",
    "                'success': False,\n",
    "                'turns': turn,\n",
    "                'conversation': conversation_history,\n",
    "                'final_guess': f\"GUESSER_{error_type}\",\n",
    "                'error': f\"{error_type}: {guesser_result['error']}\",\n",
    "                'failure_reason': error_type,\n",
    "                'total_hinter_attempts': total_hinter_attempts,\n",
    "                'total_guesser_attempts': total_guesser_attempts,\n",
    "                'format_errors': format_errors,\n",
    "                'hinter_failed_outputs': hinter_failed_outputs,\n",
    "                'guesser_failed_outputs': guesser_failed_outputs,\n",
    "                'all_hints': [msg for msg in conversation_history if msg.startswith('Hinter:')],\n",
    "                'all_guesses': [msg for msg in conversation_history if msg.startswith('Guesser:')]\n",
    "            }\n",
    "        \n",
    "        conversation_history.append(f\"Guesser: {guesser_result['response']}\")\n",
    "        guess = extract_guess_word(guesser_result['response'])\n",
    "        \n",
    "        # æ£€æŸ¥æ˜¯å¦æˆåŠŸ\n",
    "        if guess.lower() == target_word.lower():\n",
    "            return {\n",
    "                'success': True,\n",
    "                'turns': turn,\n",
    "                'conversation': conversation_history,\n",
    "                'final_guess': guess,\n",
    "                'failure_reason': None,\n",
    "                'total_hinter_attempts': total_hinter_attempts,\n",
    "                'total_guesser_attempts': total_guesser_attempts,\n",
    "                'format_errors': format_errors,\n",
    "                'hinter_failed_outputs': hinter_failed_outputs,\n",
    "                'guesser_failed_outputs': guesser_failed_outputs,\n",
    "                'all_hints': [msg for msg in conversation_history if msg.startswith('Hinter:')],\n",
    "                'all_guesses': [msg for msg in conversation_history if msg.startswith('Guesser:')]\n",
    "            }\n",
    "        \n",
    "        # å¦‚æœä¸æ˜¯æœ€åä¸€è½®ï¼Œæ·»åŠ åé¦ˆ\n",
    "        if turn < max_turns:\n",
    "            conversation_history.append(f\"System: '{guess}' is not correct. Try again!\")\n",
    "    \n",
    "    # è¾¾åˆ°æœ€å¤§è½®æ•°ä»æœªæˆåŠŸ\n",
    "    return {\n",
    "        'success': False,\n",
    "        'turns': max_turns,\n",
    "        'conversation': conversation_history,\n",
    "        'final_guess': guess if 'guess' in locals() else 'N/A',\n",
    "        'failure_reason': 'MAX_TURNS_EXCEEDED',\n",
    "        'total_hinter_attempts': total_hinter_attempts,\n",
    "        'total_guesser_attempts': total_guesser_attempts,\n",
    "        'format_errors': format_errors,\n",
    "        'hinter_failed_outputs': hinter_failed_outputs,\n",
    "        'guesser_failed_outputs': guesser_failed_outputs,\n",
    "        'all_hints': [msg for msg in conversation_history if msg.startswith('Hinter:')],\n",
    "        'all_guesses': [msg for msg in conversation_history if msg.startswith('Guesser:')]\n",
    "    }\n",
    "\n",
    "print(\"âœ… å¢å¼ºç‰ˆæ¸¸æˆå‡½æ•°å·²å®šä¹‰ï¼ˆåŒ…å«ä¸¥æ ¼çš„taboo violationæ£€æŸ¥ï¼‰\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ç»Ÿä¸€å®éªŒè¿è¡Œå™¨å·²å®šä¹‰\n"
     ]
    }
   ],
   "source": [
    "# ç»Ÿä¸€çš„Tabooå®éªŒè¿è¡Œå™¨\n",
    "def run_taboo_experiment(client, models, dataset, config):\n",
    "    \"\"\"ç»Ÿä¸€çš„Tabooå®éªŒè¿è¡Œå™¨ï¼Œæ”¯æŒæµ‹è¯•å’Œå…¨é‡æ¨¡å¼\"\"\"\n",
    "    \n",
    "    # é…ç½®å‚æ•°\n",
    "    experiment_type = config.get('experiment_type', 'test')\n",
    "    experiment_mode = config.get('experiment_mode', 'simple')  # 'simple' æˆ– 'grouped_by_hinter'\n",
    "    max_turns = config.get('max_turns', 5)\n",
    "    output_dir = config.get('output_dir', 'results')\n",
    "    fixed_word = config.get('fixed_word', None)\n",
    "    \n",
    "    # åˆ›å»ºè¾“å‡ºç›®å½•\n",
    "    from datetime import datetime\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    if experiment_mode == 'grouped_by_hinter':\n",
    "        return run_grouped_experiment(client, models, dataset, config, timestamp)\n",
    "    else:\n",
    "        return run_simple_experiment(client, models, dataset, config, timestamp)\n",
    "\n",
    "def run_simple_experiment(client, models, dataset, config, timestamp):\n",
    "    \"\"\"ç®€å•æ¨¡å¼ï¼šæµ‹è¯•å®éªŒï¼Œä½¿ç”¨å›ºå®šè¯æ±‡\"\"\"\n",
    "    experiment_type = config.get('experiment_type', 'test')\n",
    "    output_dir = config.get('output_dir', 'results')\n",
    "    fixed_word = config.get('fixed_word', None)\n",
    "    max_turns = config.get('max_turns', 5)\n",
    "    \n",
    "    # è¾“å‡ºè®¾ç½®\n",
    "    output_path = f\"{output_dir}/test_results_{timestamp}.csv\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"ğŸš€ å¼€å§‹æ‰§è¡Œ{experiment_type}å®éªŒ...\")\n",
    "    print(f\"ğŸ“ è¾“å‡ºè·¯å¾„: {output_path}\")\n",
    "    \n",
    "    # ä½¿ç”¨å›ºå®šè¯æ±‡\n",
    "    if not fixed_word:\n",
    "        fixed_word = random.choice(dataset)\n",
    "    \n",
    "    target_word = fixed_word['target']\n",
    "    taboo_words = fixed_word['taboo']\n",
    "    print(f\"ğŸ¯ æµ‹è¯•è¯: {target_word}\")\n",
    "    print(f\"ğŸš« ç¦ç”¨è¯: {taboo_words}\")\n",
    "    \n",
    "    total_games = len(models) ** 2  # æ¯ä¸ªæ¨¡å‹å¯¹ç»„åˆ1åœºæ¸¸æˆ\n",
    "    print(f\"ğŸ“Š æ€»æ¸¸æˆæ•°: {total_games}\")\n",
    "    \n",
    "    all_results = []\n",
    "    game_counter = 0\n",
    "    \n",
    "    # è¿è¡Œæ‰€æœ‰æ¨¡å‹ç»„åˆ\n",
    "    for hinter_model in models:\n",
    "        for guesser_model in models:\n",
    "            game_counter += 1\n",
    "            pair_name = f\"{hinter_model.split('/')[-1]}â†’{guesser_model.split('/')[-1]}\"\n",
    "            \n",
    "            print(f\"ğŸ”„ æ¸¸æˆ {game_counter}/{total_games} ({game_counter/total_games*100:.1f}%): {pair_name}\")\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            # æ‰§è¡Œæ¸¸æˆ\n",
    "            game_result = enhanced_play_taboo_game(client, hinter_model, guesser_model, \n",
    "                                                 target_word, taboo_words, max_turns)\n",
    "            \n",
    "            duration = round(time.time() - start_time, 2)\n",
    "            \n",
    "            # è®°å½•ç»“æœ\n",
    "            result = {\n",
    "                'game_id': game_counter,\n",
    "                'hinter_model': hinter_model,\n",
    "                'guesser_model': guesser_model,\n",
    "                'target_word': target_word,\n",
    "                'category': fixed_word.get('category', 'unknown'),\n",
    "                'taboo_words': '|'.join(taboo_words),\n",
    "                'success': game_result['success'],\n",
    "                'turns_used': game_result['turns'],\n",
    "                'final_guess': game_result['final_guess'],\n",
    "                'failure_reason': game_result.get('failure_reason', None),\n",
    "                'taboo_violation_turn': game_result.get('taboo_violation_turn', None),\n",
    "                'taboo_violation_hint': game_result.get('taboo_violation_hint', None),\n",
    "                'has_taboo_violation': game_result.get('failure_reason') == 'TABOO_VIOLATION',\n",
    "                'all_hints': ' | '.join(game_result['all_hints']),\n",
    "                'all_guesses': ' | '.join(game_result['all_guesses']),\n",
    "                'conversation': ' | '.join(game_result['conversation']),\n",
    "                'total_api_attempts': game_result.get('total_hinter_attempts', 0) + game_result.get('total_guesser_attempts', 0),\n",
    "                'format_errors': ' | '.join(game_result.get('format_errors', [])),\n",
    "                'has_format_errors': len(game_result.get('format_errors', [])) > 0,\n",
    "                'duration_seconds': duration,\n",
    "                'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "            \n",
    "            if 'error' in game_result:\n",
    "                result['error'] = game_result['error']\n",
    "            \n",
    "            all_results.append(result)\n",
    "            \n",
    "            # æ˜¾ç¤ºç»“æœ\n",
    "            status = \"âœ… æˆåŠŸ\" if game_result['success'] else \"âŒ å¤±è´¥\"\n",
    "            failure_info = \"\"\n",
    "            if not game_result['success'] and game_result.get('failure_reason'):\n",
    "                failure_reason = game_result['failure_reason']\n",
    "                if failure_reason == 'TABOO_VIOLATION':\n",
    "                    failure_info = \" (è¿åç¦ç”¨è¯è§„åˆ™)\"\n",
    "                elif failure_reason == 'FORMAT_FAILURE':\n",
    "                    failure_info = \" (æ ¼å¼é”™è¯¯è¶…3æ¬¡)\"\n",
    "                elif failure_reason == 'API_FAILURE':\n",
    "                    failure_info = \" (APIè°ƒç”¨å¤±è´¥)\"\n",
    "                elif failure_reason == 'MAX_TURNS_EXCEEDED':\n",
    "                    failure_info = \" (è¾¾åˆ°æœ€å¤§è½®æ•°)\"\n",
    "            \n",
    "            print(f\"   {status}{failure_info} | {game_result['turns']}è½® | æœ€ç»ˆçŒœæµ‹: {game_result['final_guess']}\")\n",
    "            time.sleep(0.5)\n",
    "    \n",
    "    return save_and_analyze_results(all_results, output_path, experiment_type)\n",
    "\n",
    "print(\"âœ… ç»Ÿä¸€å®éªŒè¿è¡Œå™¨å·²å®šä¹‰\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ”¯æŒå‡½æ•°å·²å®šä¹‰\n"
     ]
    }
   ],
   "source": [
    "# æ”¯æŒå‡½æ•° - å…¨é‡å®éªŒå’Œç»“æœåˆ†æ\n",
    "def run_grouped_experiment(client, models, dataset, config, timestamp):\n",
    "    \"\"\"åˆ†ç»„æ¨¡å¼ï¼šå…¨é‡å®éªŒï¼ŒæŒ‰hinteræ¨¡å‹åˆ†ç»„ï¼Œéå†æ‰€æœ‰è¯æ±‡ï¼Œæ¯50ä¸ªæ¸¸æˆä¿å­˜ä¸€ä¸ªæ‰¹æ¬¡æ–‡ä»¶\"\"\"\n",
    "    experiment_type = config.get('experiment_type', 'formal')\n",
    "    output_dir = config.get('output_dir', 'results')\n",
    "    max_turns = config.get('max_turns', 5)\n",
    "    batch_size = config.get('batch_size', 50)  # æ¯æ‰¹æ¬¡ä¿å­˜çš„æ¸¸æˆæ•°\n",
    "    \n",
    "    main_exp_dir = f\"{output_dir}/taboo_experiment_{timestamp}\"\n",
    "    os.makedirs(main_exp_dir, exist_ok=True)\n",
    "    print(f\"ğŸ“ ä¸»å®éªŒç›®å½•: {main_exp_dir}\")\n",
    "    \n",
    "    # å…¨é‡å®éªŒé…ç½®ï¼šæ¯ä¸ªæ¨¡å‹å¯¹éå†æ‰€æœ‰300ä¸ªè¯\n",
    "    print(f\"ğŸ“Š æ•°æ®é›†è¯æ±‡æ•°: {len(dataset)}\")\n",
    "    print(f\"ğŸ¤– æ¨¡å‹ç»„åˆæ•°: {len(models)}Ã—{len(models)} = {len(models)**2}\")\n",
    "    print(f\"ğŸ® æ€»æ¸¸æˆæ•°: {len(dataset) * len(models)**2:,}\")\n",
    "    print(f\"ğŸ’¾ æ‰¹æ¬¡å¤§å°: æ¯{batch_size}ä¸ªæ¸¸æˆä¿å­˜ä¸€ä¸ªæ–‡ä»¶\")\n",
    "    \n",
    "    all_experiment_results = []\n",
    "    batch_files = []  # è®°å½•æ‰€æœ‰æ‰¹æ¬¡æ–‡ä»¶è·¯å¾„\n",
    "    \n",
    "    # æŒ‰hinteræ¨¡å‹åˆ†ç»„æ‰§è¡Œ\n",
    "    for i, hinter_model in enumerate(models, 1):\n",
    "        hinter_name = hinter_model.split('/')[-1]\n",
    "        print(f\"\\\\nğŸ¯ ç¬¬{i}/{len(models)}ç»„: Hinter = {hinter_name}\")\n",
    "        \n",
    "        # ä¸ºæ¯ä¸ªhinteræ¨¡å‹åˆ›å»ºå­ç›®å½•\n",
    "        hinter_dir = f\"{main_exp_dir}/{hinter_name}_as_hinter\"\n",
    "        os.makedirs(hinter_dir, exist_ok=True)\n",
    "        \n",
    "        # è¿è¡Œå½“å‰hinteræ¨¡å‹ä¸æ‰€æœ‰guesseræ¨¡å‹çš„ç»„åˆ\n",
    "        hinter_results = []\n",
    "        current_batch = []\n",
    "        total_games_for_hinter = len(models) * len(dataset)\n",
    "        game_counter = 0\n",
    "        batch_counter = 0\n",
    "        \n",
    "        for guesser_model in models:\n",
    "            guesser_name = guesser_model.split('/')[-1]\n",
    "            pair_name = f\"{hinter_name}â†’{guesser_name}\"\n",
    "            \n",
    "            print(f\"   ğŸ”„ è¿è¡Œç»„åˆ: {pair_name}\")\n",
    "            \n",
    "            # éå†æ‰€æœ‰è¯æ±‡\n",
    "            for word_idx, word_data in enumerate(dataset):\n",
    "                game_counter += 1\n",
    "                \n",
    "                target_word = word_data['target']\n",
    "                taboo_words = word_data['taboo']\n",
    "                \n",
    "                start_time = time.time()\n",
    "                \n",
    "                # æ‰§è¡Œæ¸¸æˆ\n",
    "                game_result = enhanced_play_taboo_game(client, hinter_model, guesser_model, \n",
    "                                                     target_word, taboo_words, max_turns)\n",
    "                \n",
    "                duration = round(time.time() - start_time, 2)\n",
    "                \n",
    "                # è®°å½•ç»“æœ\n",
    "                result = {\n",
    "                    'game_id': f\"{hinter_name}_{game_counter}\",\n",
    "                    'word_index': word_idx,\n",
    "                    'hinter_model': hinter_model,\n",
    "                    'guesser_model': guesser_model,\n",
    "                    'target_word': target_word,\n",
    "                    'category': word_data.get('category', 'unknown'),\n",
    "                    'taboo_words': '|'.join(taboo_words),\n",
    "                    'success': game_result['success'],\n",
    "                    'turns_used': game_result['turns'],\n",
    "                    'final_guess': game_result['final_guess'],\n",
    "                    'failure_reason': game_result.get('failure_reason', None),\n",
    "                    'taboo_violation_turn': game_result.get('taboo_violation_turn', None),\n",
    "                    'taboo_violation_hint': game_result.get('taboo_violation_hint', None),\n",
    "                    'has_taboo_violation': game_result.get('failure_reason') == 'TABOO_VIOLATION',\n",
    "                    'all_hints': ' | '.join(game_result['all_hints']),\n",
    "                    'all_guesses': ' | '.join(game_result['all_guesses']),\n",
    "                    'conversation': ' | '.join(game_result['conversation']),\n",
    "                    'total_api_attempts': game_result.get('total_hinter_attempts', 0) + game_result.get('total_guesser_attempts', 0),\n",
    "                    'format_errors': ' | '.join(game_result.get('format_errors', [])),\n",
    "                    'has_format_errors': len(game_result.get('format_errors', [])) > 0,\n",
    "                    'duration_seconds': duration,\n",
    "                    'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                }\n",
    "                \n",
    "                if 'error' in game_result:\n",
    "                    result['error'] = game_result['error']\n",
    "                \n",
    "                hinter_results.append(result)\n",
    "                current_batch.append(result)\n",
    "                all_experiment_results.append(result)\n",
    "                \n",
    "                # æ¯batch_sizeä¸ªæ¸¸æˆä¿å­˜ä¸€ä¸ªæ‰¹æ¬¡æ–‡ä»¶\n",
    "                if len(current_batch) >= batch_size:\n",
    "                    batch_counter += 1\n",
    "                    batch_file_path = f\"{hinter_dir}/batch_{batch_counter:03d}.csv\"\n",
    "                    batch_df = pd.DataFrame(current_batch)\n",
    "                    batch_df.to_csv(batch_file_path, index=False, encoding='utf-8')\n",
    "                    batch_files.append(batch_file_path)\n",
    "                    \n",
    "                    # è¿›åº¦æ˜¾ç¤º\n",
    "                    progress = (game_counter / total_games_for_hinter) * 100\n",
    "                    success_in_batch = sum(r['success'] for r in current_batch)\n",
    "                    batch_success_rate = success_in_batch / len(current_batch) * 100\n",
    "                    \n",
    "                    print(f\"      ğŸ’¾ æ‰¹æ¬¡{batch_counter:03d}: {len(current_batch)}åœºæ¸¸æˆå·²ä¿å­˜\")\n",
    "                    print(f\"      ğŸ“ˆ è¿›åº¦: {game_counter}/{total_games_for_hinter} ({progress:.1f}%)\")\n",
    "                    print(f\"      ğŸ“Š æ‰¹æ¬¡æˆåŠŸç‡: {batch_success_rate:.1f}%\")\n",
    "                    \n",
    "                    # æ¸…ç©ºå½“å‰æ‰¹æ¬¡\n",
    "                    current_batch = []\n",
    "                \n",
    "                time.sleep(0.3)  # APIè°ƒç”¨é—´éš”\n",
    "        \n",
    "        # ä¿å­˜å‰©ä½™çš„æ¸¸æˆï¼ˆå¦‚æœæœ‰ï¼‰\n",
    "        if current_batch:\n",
    "            batch_counter += 1\n",
    "            batch_file_path = f\"{hinter_dir}/batch_{batch_counter:03d}.csv\"\n",
    "            batch_df = pd.DataFrame(current_batch)\n",
    "            batch_df.to_csv(batch_file_path, index=False, encoding='utf-8')\n",
    "            batch_files.append(batch_file_path)\n",
    "            \n",
    "            success_in_batch = sum(r['success'] for r in current_batch)\n",
    "            batch_success_rate = success_in_batch / len(current_batch) * 100\n",
    "            print(f\"      ğŸ’¾ æœ€åæ‰¹æ¬¡{batch_counter:03d}: {len(current_batch)}åœºæ¸¸æˆå·²ä¿å­˜\")\n",
    "            print(f\"      ğŸ“Š æ‰¹æ¬¡æˆåŠŸç‡: {batch_success_rate:.1f}%\")\n",
    "        \n",
    "        # ä¿å­˜å½“å‰hinteræ¨¡å‹çš„æ±‡æ€»ç»“æœ\n",
    "        hinter_df = pd.DataFrame(hinter_results)\n",
    "        hinter_csv_path = f\"{hinter_dir}/{hinter_name}_summary.csv\"\n",
    "        hinter_df.to_csv(hinter_csv_path, index=False, encoding='utf-8')\n",
    "        \n",
    "        # ç»Ÿè®¡å½“å‰hinteræ¨¡å‹çš„ç»“æœ\n",
    "        success_count = sum(r['success'] for r in hinter_results)\n",
    "        success_rate = success_count / len(hinter_results) * 100\n",
    "        \n",
    "        print(f\"   âœ… {hinter_name}ç»„å®Œæˆ: {len(hinter_results)}åœºæ¸¸æˆ, æˆåŠŸç‡: {success_rate:.1f}%\")\n",
    "        print(f\"   ğŸ’¾ æ±‡æ€»ç»“æœå·²ä¿å­˜: {hinter_csv_path}\")\n",
    "        print(f\"   ğŸ“ æ‰¹æ¬¡æ–‡ä»¶æ•°: {batch_counter}ä¸ª\")\n",
    "        \n",
    "        # å¤±è´¥åŸå› ç»Ÿè®¡\n",
    "        print_failure_summary(hinter_df)\n",
    "    \n",
    "    # ä¿å­˜å…¨é‡å®éªŒçš„æœ€ç»ˆæ±‡æ€»ç»“æœ\n",
    "    final_csv_path = f\"{main_exp_dir}/complete_experiment_results.csv\"\n",
    "    print(f\"\\nğŸ”„ å¼€å§‹ç”Ÿæˆæœ€ç»ˆæ±‡æ€»æ–‡ä»¶...\")\n",
    "    print(f\"ğŸ“Š æ€»æ‰¹æ¬¡æ–‡ä»¶æ•°: {len(batch_files)}\")\n",
    "    \n",
    "    return save_and_analyze_grouped_results(all_experiment_results, final_csv_path, main_exp_dir, models, batch_files)\n",
    "\n",
    "def save_and_analyze_results(all_results, output_path, experiment_type):\n",
    "    \"\"\"ä¿å­˜å¹¶åˆ†æå®éªŒç»“æœ\"\"\"\n",
    "    if all_results:\n",
    "        df = pd.DataFrame(all_results)\n",
    "        df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "        \n",
    "        # ç»Ÿè®¡åˆ†æ\n",
    "        total_success = sum(r['success'] for r in all_results)\n",
    "        success_rate = total_success / len(all_results) * 100\n",
    "        \n",
    "        print(f\"\\\\nâœ… {experiment_type}å®éªŒå®Œæˆï¼\")\n",
    "        print(f\"ğŸ“ ç»“æœæ–‡ä»¶: {output_path}\")\n",
    "        print(f\"ğŸ“Š æ€»æ¸¸æˆæ•°: {len(all_results):,}\")\n",
    "        print(f\"ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1f}%\")\n",
    "        \n",
    "        print_failure_summary(df)\n",
    "        return df\n",
    "    else:\n",
    "        print(\"âŒ æ²¡æœ‰æˆåŠŸçš„å®éªŒè®°å½•\")\n",
    "        return None\n",
    "\n",
    "def save_and_analyze_grouped_results(all_experiment_results, final_csv_path, main_exp_dir, models, batch_files=None):\n",
    "    \"\"\"ä¿å­˜å¹¶åˆ†æåˆ†ç»„å®éªŒç»“æœ\"\"\"\n",
    "    if all_experiment_results:\n",
    "        final_df = pd.DataFrame(all_experiment_results)\n",
    "        final_df.to_csv(final_csv_path, index=False, encoding='utf-8')\n",
    "        \n",
    "        # å…¨é‡å®éªŒç»Ÿè®¡\n",
    "        total_success = sum(r['success'] for r in all_experiment_results)\n",
    "        total_games = len(all_experiment_results)\n",
    "        overall_success_rate = total_success / total_games * 100\n",
    "        \n",
    "        print(f\"\\\\nğŸ‰ å…¨é‡å®éªŒå®Œæˆï¼\")\n",
    "        print(f\"ğŸ“ æœ€ç»ˆæ±‡æ€»æ–‡ä»¶: {final_csv_path}\")\n",
    "        print(f\"ğŸ“Š æ€»æ¸¸æˆæ•°: {total_games:,}åœº\")\n",
    "        print(f\"ğŸ“ˆ æ•´ä½“æˆåŠŸç‡: {overall_success_rate:.1f}%\")\n",
    "        \n",
    "        if batch_files:\n",
    "            print(f\"ğŸ“¦ æ‰¹æ¬¡æ–‡ä»¶æ•°: {len(batch_files)}ä¸ª\")\n",
    "            print(f\"ğŸ’¾ å¹³å‡æ¯æ‰¹æ¬¡: {total_games / len(batch_files):.1f}åœºæ¸¸æˆ\")\n",
    "        \n",
    "        # æŒ‰hinteræ¨¡å‹çš„æˆåŠŸç‡ç»Ÿè®¡\n",
    "        print(f\"\\\\nğŸ“Š å„Hinteræ¨¡å‹æˆåŠŸç‡:\")\n",
    "        for model in models:\n",
    "            model_name = model.split('/')[-1]\n",
    "            model_games = final_df[final_df['hinter_model'] == model]\n",
    "            model_success = sum(model_games['success'])\n",
    "            model_rate = model_success / len(model_games) * 100 if len(model_games) > 0 else 0\n",
    "            print(f\"   {model_name}: {model_success}/{len(model_games)} ({model_rate:.1f}%)\")\n",
    "        \n",
    "        print_failure_summary(final_df, prefix=\"æ•´ä½“\")\n",
    "        print(f\"\\\\nğŸ’¾ æ‰€æœ‰æ•°æ®å·²ä¿å­˜è‡³ç›®å½•: {main_exp_dir}\")\n",
    "        \n",
    "        # æ‰¹æ¬¡æ–‡ä»¶æ€»ç»“\n",
    "        if batch_files:\n",
    "            print(f\"\\\\nğŸ“‚ æ‰¹æ¬¡æ–‡ä»¶è¯¦æƒ…:\")\n",
    "            for batch_file in batch_files:\n",
    "                file_name = os.path.basename(batch_file)\n",
    "                print(f\"   ğŸ“„ {file_name}\")\n",
    "        \n",
    "        return final_df\n",
    "    else:\n",
    "        print(\"âŒ å…¨é‡å®éªŒå¤±è´¥ï¼Œæ²¡æœ‰æˆåŠŸçš„æ¸¸æˆè®°å½•\")\n",
    "        return None\n",
    "\n",
    "def print_failure_summary(df, prefix=\"\"):\n",
    "    \"\"\"æ‰“å°å¤±è´¥åŸå› ç»Ÿè®¡\"\"\"\n",
    "    failed_games = df[df['success'] == False]\n",
    "    if len(failed_games) > 0:\n",
    "        title = f\"{prefix}å¤±è´¥åŸå› ç»Ÿè®¡:\" if prefix else \"å¤±è´¥åŸå› ç»Ÿè®¡:\"\n",
    "        print(f\"\\\\nğŸ“‰ {title}\")\n",
    "        failure_counts = failed_games['failure_reason'].value_counts()\n",
    "        for reason, count in failure_counts.items():\n",
    "            percentage = count / len(failed_games) * 100\n",
    "            if reason == 'TABOO_VIOLATION':\n",
    "                print(f\"   ğŸš« è¿åç¦ç”¨è¯è§„åˆ™: {count} åœº ({percentage:.1f}%)\")\n",
    "            elif reason == 'FORMAT_FAILURE':\n",
    "                print(f\"   ğŸ”¤ æ ¼å¼é”™è¯¯è¶…é™: {count} åœº ({percentage:.1f}%)\")\n",
    "            elif reason == 'API_FAILURE':\n",
    "                print(f\"   ğŸŒ APIè°ƒç”¨å¤±è´¥: {count} åœº ({percentage:.1f}%)\")\n",
    "            elif reason == 'MAX_TURNS_EXCEEDED':\n",
    "                print(f\"   â±ï¸ è½®æ•°è€—å°½: {count} åœº ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"âœ… æ”¯æŒå‡½æ•°å·²å®šä¹‰\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 8. Kimiå®éªŒ - 80ä¸ªæ ·æœ¬ï¼Œ5+5-1å¯¹æ¨¡å‹ç»„åˆ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š æ­£åœ¨åŠ è½½80ä¸ªæ ·æœ¬æ•°æ®é›†...\n",
      "âœ… Quick80æ•°æ®é›†åŠ è½½æˆåŠŸ: 80 æ¡è®°å½•\n",
      "\n",
      "ğŸ“‹ Quick80æ•°æ®é›†æ ·æœ¬:\n",
      "   ç›®æ ‡è¯: behaviorism\n",
      "   ç±»åˆ«: philosophy\n",
      "   ç¦ç”¨è¯: ['approach', 'behavior', 'emphasizes', 'measurable', 'observable']\n",
      "   å®šä¹‰: an approach to psychology that emphasizes observable measurable behavior...\n",
      "\n",
      "ğŸ·ï¸ Quick80ç±»åˆ«åˆ†å¸ƒ:\n",
      "   general: 55 æ¡ (68.8%)\n",
      "   philosophy: 8 æ¡ (10.0%)\n",
      "   finance: 7 æ¡ (8.8%)\n",
      "   chemistry: 5 æ¡ (6.2%)\n",
      "   cs: 5 æ¡ (6.2%)\n"
     ]
    }
   ],
   "source": [
    "# åŠ è½½80ä¸ªæ ·æœ¬çš„æ•°æ®é›†\n",
    "def load_quick80_dataset():\n",
    "    \"\"\"åŠ è½½80ä¸ªæ ·æœ¬çš„å¿«é€Ÿæµ‹è¯•æ•°æ®é›†\"\"\"\n",
    "    quick80_path = \"quick80_dataset.json\"\n",
    "    try:\n",
    "        with open(quick80_path, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {quick80_path}\")\n",
    "        return None\n",
    "\n",
    "print(\"ğŸ“š æ­£åœ¨åŠ è½½80ä¸ªæ ·æœ¬æ•°æ®é›†...\")\n",
    "quick80_dataset = load_quick80_dataset()\n",
    "\n",
    "if quick80_dataset:\n",
    "    print(f\"âœ… Quick80æ•°æ®é›†åŠ è½½æˆåŠŸ: {len(quick80_dataset)} æ¡è®°å½•\")\n",
    "    \n",
    "    # æ˜¾ç¤ºæ•°æ®é›†æ ·æœ¬\n",
    "    print(f\"\\nğŸ“‹ Quick80æ•°æ®é›†æ ·æœ¬:\")\n",
    "    sample = quick80_dataset[0]\n",
    "    print(f\"   ç›®æ ‡è¯: {sample['target']}\")\n",
    "    print(f\"   ç±»åˆ«: {sample.get('category', 'unknown')}\")\n",
    "    print(f\"   ç¦ç”¨è¯: {sample['taboo']}\")\n",
    "    if sample.get('senses'):\n",
    "        print(f\"   å®šä¹‰: {sample['senses'][0].get('definition', 'N/A')[:100]}...\")\n",
    "        \n",
    "    # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ\n",
    "    categories = {}\n",
    "    for item in quick80_dataset:\n",
    "        category = item.get('category', 'unknown')\n",
    "        categories[category] = categories.get(category, 0) + 1\n",
    "    \n",
    "    print(f\"\\nğŸ·ï¸ Quick80ç±»åˆ«åˆ†å¸ƒ:\")\n",
    "    for category, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):\n",
    "        percentage = count / len(quick80_dataset) * 100\n",
    "        print(f\"   {category}: {count} æ¡ ({percentage:.1f}%)\")\n",
    "else:\n",
    "    print(\"âŒ Quick80æ•°æ®é›†åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨å®Œæ•´æ•°æ®é›†çš„å‰80ä¸ªæ ·æœ¬ä½œä¸ºå¤‡é€‰\")\n",
    "    if 'dataset' in locals() and len(dataset) >= 80:\n",
    "        quick80_dataset = dataset[:80]\n",
    "        print(f\"âœ… ä½¿ç”¨å®Œæ•´æ•°æ®é›†å‰80ä¸ªæ ·æœ¬: {len(quick80_dataset)} æ¡è®°å½•\")\n",
    "    else:\n",
    "        print(\"âŒ å®Œæ•´æ•°æ®é›†ä¹Ÿä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œå®éªŒ\")\n",
    "        quick80_dataset = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ™ Kimiå®éªŒé…ç½®\n",
      "==================================================\n",
      "ğŸ“Š å®éªŒé…ç½®:\n",
      "   â€¢ æ•°æ®é›†: 80 ä¸ªè¯æ±‡ âœ…\n",
      "   â€¢ æ¨¡å‹å¯¹: 9 å¯¹ç»„åˆ âœ…\n",
      "   â€¢ æ€»æ¸¸æˆ: 720 åœº\n",
      "\\nğŸ“‹ 9å¯¹ç»„åˆè¯¦æƒ…:\n",
      "    1. kimi-k2 â†’ kimi-k2 (Kimiè‡ªå¯¹è‡ª)\n",
      "    2. kimi-k2 â†’ gpt-4o (Kimiä½œHinter)\n",
      "    3. kimi-k2 â†’ gemini-2.5-flash (Kimiä½œHinter)\n",
      "    4. kimi-k2 â†’ deepseek-chat-v3-0324 (Kimiä½œHinter)\n",
      "    5. kimi-k2 â†’ claude-sonnet-4 (Kimiä½œHinter)\n",
      "    6. gpt-4o â†’ kimi-k2 (Kimiä½œGuesser)\n",
      "    7. gemini-2.5-flash â†’ kimi-k2 (Kimiä½œGuesser)\n",
      "    8. deepseek-chat-v3-0324 â†’ kimi-k2 (Kimiä½œGuesser)\n",
      "    9. claude-sonnet-4 â†’ kimi-k2 (Kimiä½œGuesser)\n",
      "\\nâœ… Kimiå®éªŒé…ç½®å®Œæˆï¼\n",
      "ğŸ§¹ å»ºè®®: åˆ é™¤Cell 15-18çš„é‡å¤å†…å®¹ï¼Œåªä¿ç•™è¿™ä¸ªç‰ˆæœ¬ã€‚\n",
      "ğŸ“ ä¸‹ä¸€æ­¥: å®ç°å®é™…çš„å®éªŒæ‰§è¡Œä»£ç ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ğŸŒ™ Kimiå®éªŒ - ç®€æ´ç‰ˆæœ¬ï¼ˆæ›¿ä»£é‡å¤çš„å¤šä¸ªcellï¼‰\n",
    "print(\"ğŸŒ™ Kimiå®éªŒé…ç½®\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# æ£€æŸ¥å…ˆå†³æ¡ä»¶\n",
    "if not quick80_dataset:\n",
    "    print(\"âŒ Quick80æ•°æ®é›†æœªåŠ è½½\")\n",
    "elif not client:\n",
    "    print(\"âŒ APIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–\")\n",
    "else:\n",
    "    # åˆ›å»º9å¯¹æ¨¡å‹ç»„åˆ\n",
    "    kimi_model = \"moonshotai/kimi-k2\"\n",
    "    other_models = [m for m in KIMI_MODELS if m != kimi_model]\n",
    "    \n",
    "    model_pairs = []\n",
    "    # Kimiä½œä¸ºhinter (5å¯¹)\n",
    "    for guesser in KIMI_MODELS:\n",
    "        model_pairs.append((kimi_model, guesser))\n",
    "    # å…¶ä»–æ¨¡å‹ä½œä¸ºhinterï¼ŒKimiä½œä¸ºguesser (4å¯¹)\n",
    "    for hinter in other_models:\n",
    "        model_pairs.append((hinter, kimi_model))\n",
    "    \n",
    "    print(f\"ğŸ“Š å®éªŒé…ç½®:\")\n",
    "    print(f\"   â€¢ æ•°æ®é›†: {len(quick80_dataset)} ä¸ªè¯æ±‡ âœ…\")\n",
    "    print(f\"   â€¢ æ¨¡å‹å¯¹: {len(model_pairs)} å¯¹ç»„åˆ âœ…\")\n",
    "    print(f\"   â€¢ æ€»æ¸¸æˆ: {len(quick80_dataset) * len(model_pairs)} åœº\")\n",
    "    \n",
    "    print(f\"\\\\nğŸ“‹ 9å¯¹ç»„åˆè¯¦æƒ…:\")\n",
    "    for i, (h, g) in enumerate(model_pairs, 1):\n",
    "        h_name, g_name = h.split('/')[-1], g.split('/')[-1]\n",
    "        role = \"\"\n",
    "        if h == kimi_model and g == kimi_model:\n",
    "            role = \" (Kimiè‡ªå¯¹è‡ª)\"\n",
    "        elif h == kimi_model:\n",
    "            role = \" (Kimiä½œHinter)\"\n",
    "        elif g == kimi_model:\n",
    "            role = \" (Kimiä½œGuesser)\"\n",
    "        print(f\"   {i:2d}. {h_name} â†’ {g_name}{role}\")\n",
    "    \n",
    "    print(f\"\\\\nâœ… Kimiå®éªŒé…ç½®å®Œæˆï¼\")\n",
    "    print(f\"ğŸ§¹ å»ºè®®: åˆ é™¤Cell 15-18çš„é‡å¤å†…å®¹ï¼Œåªä¿ç•™è¿™ä¸ªç‰ˆæœ¬ã€‚\")\n",
    "    print(f\"ğŸ“ ä¸‹ä¸€æ­¥: å®ç°å®é™…çš„å®éªŒæ‰§è¡Œä»£ç ã€‚\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è¾…åŠ©å‡½æ•°å·²å®šä¹‰\n"
     ]
    }
   ],
   "source": [
    "# æ·»åŠ ç¼ºå¤±çš„è¾…åŠ©å‡½æ•°\n",
    "import re\n",
    "\n",
    "def robust_api_call(client, model, prompt, expected_format, max_retries=3):\n",
    "    \"\"\"å¸¦é‡è¯•çš„APIè°ƒç”¨å‡½æ•°\"\"\"\n",
    "    attempts = 0\n",
    "    failed_outputs = []\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        attempts += 1\n",
    "        try:\n",
    "            messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "            response = client.call_model(model, messages)\n",
    "            \n",
    "            # æ£€æŸ¥æ ¼å¼\n",
    "            if expected_format in response:\n",
    "                return {\n",
    "                    'success': True,\n",
    "                    'response': response,\n",
    "                    'attempts': attempts,\n",
    "                    'failed_outputs': failed_outputs\n",
    "                }\n",
    "            else:\n",
    "                failed_outputs.append(response)\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(1)  # é‡è¯•å‰ç­‰å¾…\n",
    "                    continue\n",
    "                    \n",
    "        except Exception as e:\n",
    "            failed_outputs.append(f\"API Error: {str(e)}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2)  # APIé”™è¯¯åç­‰å¾…æ›´é•¿æ—¶é—´\n",
    "                continue\n",
    "    \n",
    "    # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥\n",
    "    return {\n",
    "        'success': False,\n",
    "        'response': f\"FORMAT_ERROR_EXCEEDED_{max_retries}\",\n",
    "        'error': f\"Format check failed after {max_retries} attempts\",\n",
    "        'attempts': attempts,\n",
    "        'failed_outputs': failed_outputs\n",
    "    }\n",
    "\n",
    "def extract_clue_text(hinter_response):\n",
    "    \"\"\"ä»hinterå“åº”ä¸­æå–çº¿ç´¢æ–‡æœ¬\"\"\"\n",
    "    if '[CLUE]' in hinter_response:\n",
    "        return hinter_response.split('[CLUE]', 1)[1].strip()\n",
    "    return hinter_response.strip()\n",
    "\n",
    "def extract_guess_word(guesser_response):\n",
    "    \"\"\"ä»guesserå“åº”ä¸­æå–çŒœæµ‹è¯æ±‡\"\"\"\n",
    "    if '[GUESS]' in guesser_response:\n",
    "        guess_part = guesser_response.split('[GUESS]', 1)[1].strip()\n",
    "        # æå–ç¬¬ä¸€ä¸ªå•è¯\n",
    "        words = guess_part.split()\n",
    "        return words[0] if words else guess_part\n",
    "    return guesser_response.strip().split()[0] if guesser_response.strip() else \"\"\n",
    "\n",
    "def check_taboo_violation(hint_text, taboo_words):\n",
    "    \"\"\"æ£€æŸ¥çº¿ç´¢æ˜¯å¦è¿åtaboo wordsè§„åˆ™\"\"\"\n",
    "    hint_lower = hint_text.lower()\n",
    "    for taboo_word in taboo_words:\n",
    "        taboo_lower = taboo_word.lower()\n",
    "        # æ£€æŸ¥å®Œæ•´å•è¯åŒ¹é…\n",
    "        if re.search(r'\\b' + re.escape(taboo_lower) + r'\\b', hint_lower):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "print(\"âœ… è¾…åŠ©å‡½æ•°å·²å®šä¹‰\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ™ å¼€å§‹æ‰§è¡ŒKimiå®éªŒ\n",
      "==================================================\n",
      "ğŸ“Š å®éªŒé…ç½®ç¡®è®¤:\n",
      "   â€¢ æ•°æ®é›†: 80 ä¸ªè¯æ±‡\n",
      "   â€¢ æ¨¡å‹å¯¹: 9 å¯¹ç»„åˆ\n",
      "   â€¢ æ€»æ¸¸æˆ: 720 åœº\n",
      "   â€¢ é¢„è®¡æ—¶é•¿: 6.0 åˆ†é’Ÿ\n",
      "ğŸ“ ç»“æœç›®å½•: results/kimi_experiment_20250717_125711\n",
      "\\nğŸš€ å¼€å§‹æ‰§è¡Œå®éªŒ...\n",
      "\\nğŸ“‹ ç¬¬1/9ç»„: kimi-k2â†’kimi-k2\n",
      "   ğŸ¯ è¯æ±‡ 1/80: behaviorism (0.1%)\n",
      "      âŒ behaviorism: 5è½® (è¶…æ—¶)\n",
      "   ğŸ¯ è¯æ±‡ 2/80: carcharhinus (0.3%)\n",
      "      âœ… carcharhinus: 3è½®\n",
      "   ğŸ¯ è¯æ±‡ 3/80: aphrodisiac (0.4%)\n",
      "      âœ… aphrodisiac: 1è½®\n",
      "   ğŸ¯ è¯æ±‡ 4/80: futures (0.6%)\n",
      "      âœ… futures: 1è½®\n",
      "   ğŸ¯ è¯æ±‡ 5/80: stylus (0.7%)\n",
      "      âœ… stylus: 1è½®\n",
      "   ğŸ¯ è¯æ±‡ 11/80: debenture (1.5%)\n",
      "      âœ… parentage: 3è½®\n",
      "   ğŸ¯ è¯æ±‡ 21/80: biological (2.9%)\n",
      "   ğŸ¯ è¯æ±‡ 31/80: quaggy (4.3%)\n",
      "      âœ… stomatal: 2è½®\n",
      "   ğŸ¯ è¯æ±‡ 41/80: dishearten (5.7%)\n",
      "   ğŸ¯ è¯æ±‡ 51/80: backtracking (7.1%)\n",
      "      âŒ wickedly: 5è½® (è¿è§„)\n",
      "   ğŸ¯ è¯æ±‡ 61/80: tonight (8.5%)\n",
      "   ğŸ¯ è¯æ±‡ 71/80: centennially (9.9%)\n",
      "      âœ… brooks: 2è½®\n",
      "   ğŸ“Š kimi-k2â†’kimi-k2ç»„å®Œæˆ: 69/80 (86.2%)\n",
      "   ğŸ’¾ ç»“æœå·²ä¿å­˜: kimi-k2_vs_kimi-k2_20250717_125711.csv\n",
      "\\nğŸ“‹ ç¬¬2/9ç»„: kimi-k2â†’gpt-4o\n",
      "   ğŸ¯ è¯æ±‡ 1/80: behaviorism (11.2%)\n",
      "      âŒ behaviorism: 5è½® (è¿è§„)\n",
      "   ğŸ¯ è¯æ±‡ 2/80: carcharhinus (11.4%)\n",
      "      âœ… carcharhinus: 2è½®\n",
      "   ğŸ¯ è¯æ±‡ 3/80: aphrodisiac (11.5%)\n",
      "      âœ… aphrodisiac: 1è½®\n",
      "   ğŸ¯ è¯æ±‡ 4/80: futures (11.7%)\n",
      "      âœ… futures: 1è½®\n",
      "   ğŸ¯ è¯æ±‡ 5/80: stylus (11.8%)\n",
      "      âœ… stylus: 1è½®\n",
      "   ğŸ¯ è¯æ±‡ 11/80: debenture (12.6%)\n",
      "      âœ… parentage: 3è½®\n",
      "   ğŸ¯ è¯æ±‡ 21/80: biological (14.0%)\n",
      "   ğŸ¯ è¯æ±‡ 31/80: quaggy (15.4%)\n",
      "      âœ… stomatal: 2è½®\n",
      "   ğŸ¯ è¯æ±‡ 41/80: dishearten (16.8%)\n",
      "   ğŸ¯ è¯æ±‡ 51/80: backtracking (18.2%)\n",
      "      âœ… wickedly: 4è½®\n",
      "   ğŸ¯ è¯æ±‡ 61/80: tonight (19.6%)\n",
      "   ğŸ¯ è¯æ±‡ 71/80: centennially (21.0%)\n",
      "      âœ… brooks: 1è½®\n",
      "   ğŸ“Š kimi-k2â†’gpt-4oç»„å®Œæˆ: 70/80 (87.5%)\n",
      "   ğŸ’¾ ç»“æœå·²ä¿å­˜: kimi-k2_vs_gpt-4o_20250717_125711.csv\n",
      "\\nğŸ“‹ ç¬¬3/9ç»„: kimi-k2â†’gemini-2.5-flash\n",
      "   ğŸ¯ è¯æ±‡ 1/80: behaviorism (22.4%)\n",
      "      âœ… behaviorism: 4è½®\n",
      "   ğŸ¯ è¯æ±‡ 2/80: carcharhinus (22.5%)\n",
      "      âœ… carcharhinus: 3è½®\n",
      "   ğŸ¯ è¯æ±‡ 3/80: aphrodisiac (22.6%)\n",
      "      âœ… aphrodisiac: 1è½®\n",
      "   ğŸ¯ è¯æ±‡ 4/80: futures (22.8%)\n",
      "      âœ… futures: 1è½®\n",
      "   ğŸ¯ è¯æ±‡ 5/80: stylus (22.9%)\n",
      "      âœ… stylus: 2è½®\n",
      "   ğŸ¯ è¯æ±‡ 11/80: debenture (23.8%)\n",
      "      âŒ parentage: 5è½® (è¶…æ—¶)\n",
      "   ğŸ¯ è¯æ±‡ 21/80: biological (25.1%)\n",
      "   ğŸ¯ è¯æ±‡ 31/80: quaggy (26.5%)\n",
      "      âœ… stomatal: 2è½®\n",
      "   ğŸ¯ è¯æ±‡ 41/80: dishearten (27.9%)\n",
      "   ğŸ¯ è¯æ±‡ 51/80: backtracking (29.3%)\n",
      "      âœ… wickedly: 3è½®\n",
      "   ğŸ¯ è¯æ±‡ 61/80: tonight (30.7%)\n",
      "   ğŸ¯ è¯æ±‡ 71/80: centennially (32.1%)\n",
      "      âœ… brooks: 1è½®\n",
      "   ğŸ“Š kimi-k2â†’gemini-2.5-flashç»„å®Œæˆ: 66/80 (82.5%)\n",
      "   ğŸ’¾ ç»“æœå·²ä¿å­˜: kimi-k2_vs_gemini-2.5-flash_20250717_125711.csv\n",
      "\\nğŸ“‹ ç¬¬4/9ç»„: kimi-k2â†’deepseek-chat-v3-0324\n",
      "   ğŸ¯ è¯æ±‡ 1/80: behaviorism (33.5%)\n",
      "      âŒ behaviorism: 5è½® (è¶…æ—¶)\n",
      "   ğŸ¯ è¯æ±‡ 2/80: carcharhinus (33.6%)\n",
      "      âŒ carcharhinus: 5è½® (è¶…æ—¶)\n",
      "   ğŸ¯ è¯æ±‡ 3/80: aphrodisiac (33.8%)\n",
      "      âœ… aphrodisiac: 1è½®\n",
      "   ğŸ¯ è¯æ±‡ 4/80: futures (33.9%)\n",
      "      âœ… futures: 1è½®\n",
      "   ğŸ¯ è¯æ±‡ 5/80: stylus (34.0%)\n",
      "      âœ… stylus: 1è½®\n",
      "   ğŸ¯ è¯æ±‡ 11/80: debenture (34.9%)\n",
      "      âœ… parentage: 2è½®\n",
      "   ğŸ¯ è¯æ±‡ 21/80: biological (36.2%)\n",
      "   ğŸ¯ è¯æ±‡ 31/80: quaggy (37.6%)\n",
      "      âœ… stomatal: 2è½®\n",
      "   ğŸ¯ è¯æ±‡ 41/80: dishearten (39.0%)\n",
      "   ğŸ¯ è¯æ±‡ 51/80: backtracking (40.4%)\n",
      "      âœ… wickedly: 2è½®\n",
      "   ğŸ¯ è¯æ±‡ 61/80: tonight (41.8%)\n",
      "   ğŸ¯ è¯æ±‡ 71/80: centennially (43.2%)\n",
      "      âœ… brooks: 2è½®\n",
      "   ğŸ“Š kimi-k2â†’deepseek-chat-v3-0324ç»„å®Œæˆ: 66/80 (82.5%)\n",
      "   ğŸ’¾ ç»“æœå·²ä¿å­˜: kimi-k2_vs_deepseek-chat-v3-0324_20250717_125711.csv\n",
      "\\nğŸ“‹ ç¬¬5/9ç»„: kimi-k2â†’claude-sonnet-4\n",
      "   ğŸ¯ è¯æ±‡ 1/80: behaviorism (44.6%)\n",
      "      âœ… behaviorism: 4è½®\n",
      "   ğŸ¯ è¯æ±‡ 2/80: carcharhinus (44.7%)\n",
      "      âœ… carcharhinus: 2è½®\n",
      "   ğŸ¯ è¯æ±‡ 3/80: aphrodisiac (44.9%)\n",
      "      âœ… aphrodisiac: 1è½®\n",
      "   ğŸ¯ è¯æ±‡ 4/80: futures (45.0%)\n",
      "      âœ… futures: 1è½®\n",
      "   ğŸ¯ è¯æ±‡ 5/80: stylus (45.1%)\n",
      "      âœ… stylus: 1è½®\n",
      "   ğŸ¯ è¯æ±‡ 11/80: debenture (46.0%)\n",
      "      âœ… parentage: 4è½®\n",
      "   ğŸ¯ è¯æ±‡ 21/80: biological (47.4%)\n",
      "   ğŸ¯ è¯æ±‡ 31/80: quaggy (48.8%)\n",
      "      âœ… stomatal: 2è½®\n",
      "   ğŸ¯ è¯æ±‡ 41/80: dishearten (50.1%)\n",
      "   ğŸ¯ è¯æ±‡ 51/80: backtracking (51.5%)\n",
      "      âœ… wickedly: 2è½®\n",
      "   ğŸ¯ è¯æ±‡ 61/80: tonight (52.9%)\n",
      "   ğŸ¯ è¯æ±‡ 71/80: centennially (54.3%)\n",
      "      âœ… brooks: 1è½®\n",
      "   ğŸ“Š kimi-k2â†’claude-sonnet-4ç»„å®Œæˆ: 73/80 (91.2%)\n",
      "   ğŸ’¾ ç»“æœå·²ä¿å­˜: kimi-k2_vs_claude-sonnet-4_20250717_125711.csv\n",
      "\\nğŸ“‹ ç¬¬6/9ç»„: gpt-4oâ†’kimi-k2\n",
      "   ğŸ¯ è¯æ±‡ 1/80: behaviorism (55.7%)\n",
      "      âŒ behaviorism: 5è½® (è¶…æ—¶)\n",
      "   ğŸ¯ è¯æ±‡ 2/80: carcharhinus (55.8%)\n",
      "      âŒ carcharhinus: 5è½® (è¶…æ—¶)\n",
      "   ğŸ¯ è¯æ±‡ 3/80: aphrodisiac (56.0%)\n",
      "      âœ… aphrodisiac: 1è½®\n",
      "   ğŸ¯ è¯æ±‡ 4/80: futures (56.1%)\n",
      "      âœ… futures: 1è½®\n",
      "   ğŸ¯ è¯æ±‡ 5/80: stylus (56.2%)\n",
      "      âœ… stylus: 1è½®\n",
      "   ğŸ¯ è¯æ±‡ 11/80: debenture (57.1%)\n",
      "      âŒ parentage: 5è½® (è¶…æ—¶)\n",
      "   ğŸ¯ è¯æ±‡ 21/80: biological (58.5%)\n",
      "   ğŸ¯ è¯æ±‡ 31/80: quaggy (59.9%)\n",
      "      âœ… stomatal: 3è½®\n",
      "   ğŸ¯ è¯æ±‡ 41/80: dishearten (61.3%)\n",
      "   ğŸ¯ è¯æ±‡ 51/80: backtracking (62.6%)\n",
      "      âœ… wickedly: 3è½®\n",
      "   ğŸ¯ è¯æ±‡ 61/80: tonight (64.0%)\n",
      "   ğŸ¯ è¯æ±‡ 71/80: centennially (65.4%)\n",
      "      âœ… brooks: 2è½®\n",
      "   ğŸ“Š gpt-4oâ†’kimi-k2ç»„å®Œæˆ: 52/80 (65.0%)\n",
      "   ğŸ’¾ ç»“æœå·²ä¿å­˜: gpt-4o_vs_kimi-k2_20250717_125711.csv\n",
      "\\nğŸ“‹ ç¬¬7/9ç»„: gemini-2.5-flashâ†’kimi-k2\n",
      "   ğŸ¯ è¯æ±‡ 1/80: behaviorism (66.8%)\n",
      "      âŒ behaviorism: 5è½® (è¶…æ—¶)\n",
      "   ğŸ¯ è¯æ±‡ 2/80: carcharhinus (66.9%)\n",
      "      âœ… carcharhinus: 4è½®\n",
      "   ğŸ¯ è¯æ±‡ 3/80: aphrodisiac (67.1%)\n",
      "      âœ… aphrodisiac: 1è½®\n",
      "   ğŸ¯ è¯æ±‡ 4/80: futures (67.2%)\n",
      "      âœ… futures: 2è½®\n",
      "   ğŸ¯ è¯æ±‡ 5/80: stylus (67.4%)\n",
      "      âœ… stylus: 1è½®\n",
      "   ğŸ¯ è¯æ±‡ 11/80: debenture (68.2%)\n",
      "      âœ… parentage: 5è½®\n",
      "   ğŸ¯ è¯æ±‡ 21/80: biological (69.6%)\n",
      "   ğŸ¯ è¯æ±‡ 31/80: quaggy (71.0%)\n",
      "      âœ… stomatal: 2è½®\n",
      "   ğŸ¯ è¯æ±‡ 41/80: dishearten (72.4%)\n",
      "   ğŸ¯ è¯æ±‡ 51/80: backtracking (73.8%)\n",
      "      âŒ wickedly: 5è½® (è¶…æ—¶)\n",
      "   ğŸ¯ è¯æ±‡ 61/80: tonight (75.1%)\n",
      "   ğŸ¯ è¯æ±‡ 71/80: centennially (76.5%)\n",
      "      âœ… brooks: 2è½®\n",
      "   ğŸ“Š gemini-2.5-flashâ†’kimi-k2ç»„å®Œæˆ: 67/80 (83.8%)\n",
      "   ğŸ’¾ ç»“æœå·²ä¿å­˜: gemini-2.5-flash_vs_kimi-k2_20250717_125711.csv\n",
      "\\nğŸ“‹ ç¬¬8/9ç»„: deepseek-chat-v3-0324â†’kimi-k2\n",
      "   ğŸ¯ è¯æ±‡ 1/80: behaviorism (77.9%)\n",
      "      âŒ behaviorism: 5è½® (è¶…æ—¶)\n",
      "   ğŸ¯ è¯æ±‡ 2/80: carcharhinus (78.1%)\n",
      "      âœ… carcharhinus: 3è½®\n",
      "   ğŸ¯ è¯æ±‡ 3/80: aphrodisiac (78.2%)\n",
      "      âœ… aphrodisiac: 1è½®\n",
      "   ğŸ¯ è¯æ±‡ 4/80: futures (78.3%)\n",
      "      âœ… futures: 1è½®\n",
      "   ğŸ¯ è¯æ±‡ 5/80: stylus (78.5%)\n",
      "      âœ… stylus: 1è½®\n",
      "   ğŸ¯ è¯æ±‡ 11/80: debenture (79.3%)\n",
      "      âŒ parentage: 5è½® (è¶…æ—¶)\n",
      "   ğŸ¯ è¯æ±‡ 21/80: biological (80.7%)\n",
      "   ğŸ¯ è¯æ±‡ 31/80: quaggy (82.1%)\n",
      "      âœ… stomatal: 3è½®\n",
      "   ğŸ¯ è¯æ±‡ 41/80: dishearten (83.5%)\n",
      "   ğŸ¯ è¯æ±‡ 51/80: backtracking (84.9%)\n",
      "      âœ… wickedly: 3è½®\n",
      "   ğŸ¯ è¯æ±‡ 61/80: tonight (86.2%)\n",
      "   ğŸ¯ è¯æ±‡ 71/80: centennially (87.6%)\n",
      "      âœ… brooks: 3è½®\n",
      "   ğŸ“Š deepseek-chat-v3-0324â†’kimi-k2ç»„å®Œæˆ: 58/80 (72.5%)\n",
      "   ğŸ’¾ ç»“æœå·²ä¿å­˜: deepseek-chat-v3-0324_vs_kimi-k2_20250717_125711.csv\n",
      "\\nğŸ“‹ ç¬¬9/9ç»„: claude-sonnet-4â†’kimi-k2\n",
      "   ğŸ¯ è¯æ±‡ 1/80: behaviorism (89.0%)\n",
      "      âœ… behaviorism: 2è½®\n",
      "   ğŸ¯ è¯æ±‡ 2/80: carcharhinus (89.2%)\n",
      "      âœ… carcharhinus: 2è½®\n",
      "   ğŸ¯ è¯æ±‡ 3/80: aphrodisiac (89.3%)\n",
      "      âœ… aphrodisiac: 1è½®\n",
      "   ğŸ¯ è¯æ±‡ 4/80: futures (89.4%)\n",
      "      âœ… futures: 1è½®\n",
      "   ğŸ¯ è¯æ±‡ 5/80: stylus (89.6%)\n",
      "      âœ… stylus: 1è½®\n",
      "   ğŸ¯ è¯æ±‡ 11/80: debenture (90.4%)\n",
      "      âœ… parentage: 3è½®\n",
      "   ğŸ¯ è¯æ±‡ 21/80: biological (91.8%)\n",
      "   ğŸ¯ è¯æ±‡ 31/80: quaggy (93.2%)\n",
      "      âœ… stomatal: 2è½®\n",
      "   ğŸ¯ è¯æ±‡ 41/80: dishearten (94.6%)\n"
     ]
    }
   ],
   "source": [
    "# ğŸŒ™ Kimiå®éªŒæ‰§è¡Œ - å®é™…è¿è¡Œä»£ç \n",
    "print(\"ğŸŒ™ å¼€å§‹æ‰§è¡ŒKimiå®éªŒ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# æ£€æŸ¥å…ˆå†³æ¡ä»¶\n",
    "if not quick80_dataset:\n",
    "    print(\"âŒ Quick80æ•°æ®é›†æœªåŠ è½½ï¼Œå®éªŒæ— æ³•è¿›è¡Œ\")\n",
    "elif not client:\n",
    "    print(\"âŒ APIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œå®éªŒæ— æ³•è¿›è¡Œ\")\n",
    "else:\n",
    "    # åˆ›å»º9å¯¹æ¨¡å‹ç»„åˆ\n",
    "    kimi_model = \"moonshotai/kimi-k2\"\n",
    "    other_models = [m for m in KIMI_MODELS if m != kimi_model]\n",
    "    \n",
    "    model_pairs = []\n",
    "    # Kimiä½œä¸ºhinter (5å¯¹)\n",
    "    for guesser in KIMI_MODELS:\n",
    "        model_pairs.append((kimi_model, guesser))\n",
    "    # å…¶ä»–æ¨¡å‹ä½œä¸ºhinterï¼ŒKimiä½œä¸ºguesser (4å¯¹)\n",
    "    for hinter in other_models:\n",
    "        model_pairs.append((hinter, kimi_model))\n",
    "    \n",
    "    print(f\"ğŸ“Š å®éªŒé…ç½®ç¡®è®¤:\")\n",
    "    print(f\"   â€¢ æ•°æ®é›†: {len(quick80_dataset)} ä¸ªè¯æ±‡\")\n",
    "    print(f\"   â€¢ æ¨¡å‹å¯¹: {len(model_pairs)} å¯¹ç»„åˆ\")\n",
    "    print(f\"   â€¢ æ€»æ¸¸æˆ: {len(quick80_dataset) * len(model_pairs)} åœº\")\n",
    "    print(f\"   â€¢ é¢„è®¡æ—¶é•¿: {len(quick80_dataset) * len(model_pairs) * 0.5 / 60:.1f} åˆ†é’Ÿ\")\n",
    "    \n",
    "    # åˆ›å»ºç»“æœè¾“å‡ºç›®å½•\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_dir = f\"results/kimi_experiment_{timestamp}\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"ğŸ“ ç»“æœç›®å½•: {results_dir}\")\n",
    "    \n",
    "    # åˆå§‹åŒ–ç»“æœæ”¶é›†\n",
    "    all_results = []\n",
    "    game_counter = 0\n",
    "    total_games = len(quick80_dataset) * len(model_pairs)\n",
    "    \n",
    "    print(f\"\\\\nğŸš€ å¼€å§‹æ‰§è¡Œå®éªŒ...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # æ‰§è¡Œå®éªŒ\n",
    "    for pair_idx, (hinter_model, guesser_model) in enumerate(model_pairs, 1):\n",
    "        hinter_name = hinter_model.split('/')[-1]\n",
    "        guesser_name = guesser_model.split('/')[-1]\n",
    "        pair_name = f\"{hinter_name}â†’{guesser_name}\"\n",
    "        \n",
    "        print(f\"\\\\nğŸ“‹ ç¬¬{pair_idx}/{len(model_pairs)}ç»„: {pair_name}\")\n",
    "        \n",
    "        # å¯¹è¿™ä¸ªæ¨¡å‹ç»„åˆè¿è¡Œæ‰€æœ‰80ä¸ªè¯æ±‡\n",
    "        pair_results = []\n",
    "        \n",
    "        for word_idx, word_data in enumerate(quick80_dataset):\n",
    "            game_counter += 1\n",
    "            target_word = word_data['target']\n",
    "            taboo_words = word_data['taboo']\n",
    "            \n",
    "            # è¿›åº¦æ˜¾ç¤º\n",
    "            if word_idx % 10 == 0 or word_idx < 5:\n",
    "                progress = (game_counter / total_games) * 100\n",
    "                print(f\"   ğŸ¯ è¯æ±‡ {word_idx+1}/80: {target_word} ({progress:.1f}%)\")\n",
    "            \n",
    "            # æ‰§è¡Œå•åœºæ¸¸æˆ\n",
    "            game_start = time.time()\n",
    "            try:\n",
    "                game_result = enhanced_play_taboo_game(\n",
    "                    client, hinter_model, guesser_model, \n",
    "                    target_word, taboo_words, max_turns=5\n",
    "                )\n",
    "                \n",
    "                duration = round(time.time() - game_start, 2)\n",
    "                \n",
    "                # è®°å½•ç»“æœ\n",
    "                result = {\n",
    "                    'game_id': f\"kimi_{game_counter:04d}\",\n",
    "                    'pair_index': pair_idx,\n",
    "                    'word_index': word_idx + 1,\n",
    "                    'hinter_model': hinter_model,\n",
    "                    'guesser_model': guesser_model,\n",
    "                    'hinter_name': hinter_name,\n",
    "                    'guesser_name': guesser_name,\n",
    "                    'pair_name': pair_name,\n",
    "                    'target_word': target_word,\n",
    "                    'category': word_data.get('category', 'unknown'),\n",
    "                    'taboo_words': '|'.join(taboo_words),\n",
    "                    'success': game_result['success'],\n",
    "                    'turns_used': game_result['turns'],\n",
    "                    'final_guess': game_result['final_guess'],\n",
    "                    'failure_reason': game_result.get('failure_reason', None),\n",
    "                    'has_taboo_violation': game_result.get('failure_reason') == 'TABOO_VIOLATION',\n",
    "                    'conversation_turns': len(game_result['conversation']),\n",
    "                    'all_hints': ' | '.join(game_result.get('all_hints', [])),\n",
    "                    'all_guesses': ' | '.join(game_result.get('all_guesses', [])),\n",
    "                    'conversation': ' | '.join(game_result['conversation']),\n",
    "                    'duration_seconds': duration,\n",
    "                    'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                }\n",
    "                \n",
    "                # æ·»åŠ é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰\n",
    "                if 'error' in game_result:\n",
    "                    result['error'] = game_result['error']\n",
    "                \n",
    "                pair_results.append(result)\n",
    "                all_results.append(result)\n",
    "                \n",
    "                # ç®€çŸ­çš„ç»“æœæ˜¾ç¤º\n",
    "                if word_idx < 5 or word_idx % 20 == 19:\n",
    "                    status = \"âœ…\" if game_result['success'] else \"âŒ\"\n",
    "                    failure_info = \"\"\n",
    "                    if not game_result['success'] and game_result.get('failure_reason'):\n",
    "                        reason_map = {\n",
    "                            'TABOO_VIOLATION': 'è¿è§„',\n",
    "                            'FORMAT_FAILURE': 'æ ¼å¼',\n",
    "                            'API_FAILURE': 'API',\n",
    "                            'MAX_TURNS_EXCEEDED': 'è¶…æ—¶'\n",
    "                        }\n",
    "                        failure_info = f\" ({reason_map.get(game_result['failure_reason'], game_result['failure_reason'])})\"\n",
    "                    \n",
    "                    print(f\"      {status} {target_word}: {game_result['turns']}è½®{failure_info}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"      âŒ æ¸¸æˆæ‰§è¡Œé”™è¯¯: {target_word} - {str(e)}\")\n",
    "                # è®°å½•é”™è¯¯ç»“æœ\n",
    "                error_result = {\n",
    "                    'game_id': f\"kimi_{game_counter:04d}\",\n",
    "                    'pair_index': pair_idx,\n",
    "                    'word_index': word_idx + 1,\n",
    "                    'hinter_model': hinter_model,\n",
    "                    'guesser_model': guesser_model,\n",
    "                    'target_word': target_word,\n",
    "                    'success': False,\n",
    "                    'error': str(e),\n",
    "                    'failure_reason': 'EXECUTION_ERROR',\n",
    "                    'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                }\n",
    "                pair_results.append(error_result)\n",
    "                all_results.append(error_result)\n",
    "            \n",
    "            # APIè°ƒç”¨é—´éš”\n",
    "            time.sleep(0.3)\n",
    "        \n",
    "        # ä¿å­˜å½“å‰æ¨¡å‹å¯¹çš„ç»“æœ\n",
    "        pair_success = sum(1 for r in pair_results if r['success'])\n",
    "        pair_success_rate = pair_success / len(pair_results) * 100\n",
    "        \n",
    "        print(f\"   ğŸ“Š {pair_name}ç»„å®Œæˆ: {pair_success}/{len(pair_results)} ({pair_success_rate:.1f}%)\")\n",
    "        \n",
    "        # ä¿å­˜å•ä¸ªæ¨¡å‹å¯¹çš„ç»“æœæ–‡ä»¶\n",
    "        pair_file = f\"{results_dir}/{hinter_name}_vs_{guesser_name}_{timestamp}.csv\"\n",
    "        pair_df = pd.DataFrame(pair_results)\n",
    "        pair_df.to_csv(pair_file, index=False, encoding='utf-8')\n",
    "        print(f\"   ğŸ’¾ ç»“æœå·²ä¿å­˜: {os.path.basename(pair_file)}\")\n",
    "    \n",
    "    # ä¿å­˜æ±‡æ€»ç»“æœ\n",
    "    print(f\"\\\\nğŸ“Š å®éªŒæ±‡æ€»ç»Ÿè®¡:\")\n",
    "    total_duration = time.time() - start_time\n",
    "    total_success = sum(1 for r in all_results if r['success'])\n",
    "    overall_success_rate = total_success / len(all_results) * 100\n",
    "    \n",
    "    print(f\"   â±ï¸  æ€»è€—æ—¶: {total_duration/60:.1f} åˆ†é’Ÿ\")\n",
    "    print(f\"   ğŸ® æ€»æ¸¸æˆæ•°: {len(all_results):,} åœº\")\n",
    "    print(f\"   âœ… æ€»æˆåŠŸæ•°: {total_success:,} åœº\")\n",
    "    print(f\"   ğŸ“ˆ æ€»æˆåŠŸç‡: {overall_success_rate:.1f}%\")\n",
    "    \n",
    "    # ä¿å­˜å®Œæ•´æ±‡æ€»ç»“æœ\n",
    "    summary_file = f\"{results_dir}/kimi_experiment_summary_{timestamp}.csv\"\n",
    "    summary_df = pd.DataFrame(all_results)\n",
    "    summary_df.to_csv(summary_file, index=False, encoding='utf-8')\n",
    "    \n",
    "    print(f\"\\\\nğŸ’¾ å®Œæ•´ç»“æœå·²ä¿å­˜:\")\n",
    "    print(f\"   ğŸ“ ç›®å½•: {results_dir}\")\n",
    "    print(f\"   ğŸ“„ æ±‡æ€»æ–‡ä»¶: {os.path.basename(summary_file)}\")\n",
    "    print(f\"   ğŸ“„ å•ç‹¬æ–‡ä»¶: {len(model_pairs)} ä¸ªæ¨¡å‹å¯¹æ–‡ä»¶\")\n",
    "    \n",
    "    # å¿«é€Ÿåˆ†æ\n",
    "    print(f\"\\\\nğŸ“ˆ æŒ‰æ¨¡å‹è§’è‰²æˆåŠŸç‡:\")\n",
    "    kimi_as_hinter = summary_df[summary_df['hinter_name'] == 'kimi-k2']\n",
    "    kimi_as_guesser = summary_df[summary_df['guesser_name'] == 'kimi-k2']\n",
    "    \n",
    "    if len(kimi_as_hinter) > 0:\n",
    "        kimi_hinter_success = sum(kimi_as_hinter['success']) / len(kimi_as_hinter) * 100\n",
    "        print(f\"   ğŸŒ™ Kimiä½œHinter: {kimi_hinter_success:.1f}%\")\n",
    "    \n",
    "    if len(kimi_as_guesser) > 0:\n",
    "        kimi_guesser_success = sum(kimi_as_guesser['success']) / len(kimi_as_guesser) * 100\n",
    "        print(f\"   ğŸŒ™ Kimiä½œGuesser: {kimi_guesser_success:.1f}%\")\n",
    "    \n",
    "    print(f\"\\\\nğŸ‰ Kimiå®éªŒæ‰§è¡Œå®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ æ¢å¤å¹¶å®Œæˆä¸­æ–­çš„Kimiå®éªŒ\n",
    "print(\"ğŸ”§ æ£€æŸ¥å¹¶å®Œæˆä¸­æ–­çš„Kimiå®éªŒ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# æ£€æŸ¥å·²å®Œæˆçš„æ–‡ä»¶\n",
    "results_dir = \"results/kimi_experiment_20250717_125711\"\n",
    "if os.path.exists(results_dir):\n",
    "    existing_files = [f for f in os.listdir(results_dir) if f.endswith('.csv')]\n",
    "    print(f\"ğŸ“ æ‰¾åˆ°å®éªŒç›®å½•: {results_dir}\")\n",
    "    print(f\"ğŸ“„ å·²æœ‰æ–‡ä»¶æ•°: {len(existing_files)}\")\n",
    "    \n",
    "    # å®šä¹‰æ‰€æœ‰åº”è¯¥å­˜åœ¨çš„æ¨¡å‹å¯¹\n",
    "    kimi_model = \"moonshotai/kimi-k2\"\n",
    "    all_models = [\n",
    "        \"moonshotai/kimi-k2\",\n",
    "        \"openai/gpt-4o\", \n",
    "        \"google/gemini-2.5-flash\",\n",
    "        \"deepseek/deepseek-chat-v3-0324\",\n",
    "        \"anthropic/claude-sonnet-4\"\n",
    "    ]\n",
    "    \n",
    "    expected_pairs = []\n",
    "    # Kimiä½œä¸ºhinter (5å¯¹)\n",
    "    for guesser in all_models:\n",
    "        guesser_name = guesser.split('/')[-1]\n",
    "        expected_pairs.append(f\"kimi-k2_vs_{guesser_name}_20250717_125711.csv\")\n",
    "    \n",
    "    # å…¶ä»–æ¨¡å‹ä½œä¸ºhinterï¼ŒKimiä½œä¸ºguesser (4å¯¹)\n",
    "    for hinter in all_models:\n",
    "        if hinter != kimi_model:\n",
    "            hinter_name = hinter.split('/')[-1]\n",
    "            expected_pairs.append(f\"{hinter_name}_vs_kimi-k2_20250717_125711.csv\")\n",
    "    \n",
    "    print(f\"\\\\nğŸ“‹ åº”æœ‰æ–‡ä»¶æ¸…å• ({len(expected_pairs)}ä¸ª):\")\n",
    "    missing_files = []\n",
    "    \n",
    "    for i, expected_file in enumerate(expected_pairs, 1):\n",
    "        if expected_file in existing_files:\n",
    "            print(f\"   âœ… {i:2d}. {expected_file}\")\n",
    "        else:\n",
    "            print(f\"   âŒ {i:2d}. {expected_file} (ç¼ºå¤±)\")\n",
    "            missing_files.append(expected_file)\n",
    "    \n",
    "    print(f\"\\\\nğŸ“Š çŠ¶æ€æ€»ç»“:\")\n",
    "    print(f\"   â€¢ å·²å®Œæˆ: {len(existing_files)}/{len(expected_pairs)} ä¸ªæ–‡ä»¶\")\n",
    "    print(f\"   â€¢ ç¼ºå¤±: {len(missing_files)} ä¸ªæ–‡ä»¶\")\n",
    "    \n",
    "    if missing_files:\n",
    "        print(f\"\\\\nğŸš§ éœ€è¦è¡¥å……å®Œæˆçš„æ–‡ä»¶:\")\n",
    "        for missing in missing_files:\n",
    "            print(f\"   ğŸ“ {missing}\")\n",
    "            \n",
    "        # å¦‚æœåªç¼ºå°‘ä¸€ä¸ªæ–‡ä»¶ï¼Œç«‹å³æ‰§è¡Œ\n",
    "        if len(missing_files) == 1:\n",
    "            missing_file = missing_files[0]\n",
    "            if \"claude-sonnet-4_vs_kimi-k2\" in missing_file:\n",
    "                print(f\"\\\\nğŸš€ å¼€å§‹æ‰§è¡Œç¼ºå¤±çš„å®éªŒ: claude-sonnet-4 â†’ kimi-k2\")\n",
    "                \n",
    "                hinter_model = \"anthropic/claude-sonnet-4\"\n",
    "                guesser_model = \"moonshotai/kimi-k2\"\n",
    "                hinter_name = \"claude-sonnet-4\"\n",
    "                guesser_name = \"kimi-k2\"\n",
    "                \n",
    "                # åŠ è½½æ•°æ®é›†\n",
    "                if 'quick80_dataset' not in locals() or not quick80_dataset:\n",
    "                    quick80_dataset = load_quick80_dataset()\n",
    "                \n",
    "                if quick80_dataset and client:\n",
    "                    print(f\"   ğŸ“š æ•°æ®é›†: {len(quick80_dataset)} ä¸ªè¯æ±‡\")\n",
    "                    print(f\"   ğŸ¤– æ¨¡å‹å¯¹: {hinter_name} â†’ {guesser_name}\")\n",
    "                    \n",
    "                    # æ‰§è¡Œå®éªŒ\n",
    "                    pair_results = []\n",
    "                    game_counter = 640  # å‰8ç»„å·²å®Œæˆ640åœºæ¸¸æˆ\n",
    "                    \n",
    "                    start_time = time.time()\n",
    "                    print(f\"\\\\nâ±ï¸  å¼€å§‹æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "                    \n",
    "                    for word_idx, word_data in enumerate(quick80_dataset):\n",
    "                        game_counter += 1\n",
    "                        target_word = word_data['target']\n",
    "                        taboo_words = word_data['taboo']\n",
    "                        \n",
    "                        # è¿›åº¦æ˜¾ç¤º\n",
    "                        if word_idx % 10 == 0 or word_idx < 5:\n",
    "                            print(f\"   ğŸ¯ è¯æ±‡ {word_idx+1}/80: {target_word}\")\n",
    "                        \n",
    "                        # æ‰§è¡Œæ¸¸æˆ\n",
    "                        game_start = time.time()\n",
    "                        try:\n",
    "                            game_result = enhanced_play_taboo_game(\n",
    "                                client, hinter_model, guesser_model,\n",
    "                                target_word, taboo_words, max_turns=5\n",
    "                            )\n",
    "                            \n",
    "                            duration = round(time.time() - game_start, 2)\n",
    "                            \n",
    "                            # è®°å½•ç»“æœ\n",
    "                            result = {\n",
    "                                'game_id': f\"kimi_{game_counter:04d}\",\n",
    "                                'pair_index': 9,\n",
    "                                'word_index': word_idx + 1,\n",
    "                                'hinter_model': hinter_model,\n",
    "                                'guesser_model': guesser_model,\n",
    "                                'hinter_name': hinter_name,\n",
    "                                'guesser_name': guesser_name,\n",
    "                                'pair_name': f\"{hinter_name}â†’{guesser_name}\",\n",
    "                                'target_word': target_word,\n",
    "                                'category': word_data.get('category', 'unknown'),\n",
    "                                'taboo_words': '|'.join(taboo_words),\n",
    "                                'success': game_result['success'],\n",
    "                                'turns_used': game_result['turns'],\n",
    "                                'final_guess': game_result['final_guess'],\n",
    "                                'failure_reason': game_result.get('failure_reason', None),\n",
    "                                'has_taboo_violation': game_result.get('failure_reason') == 'TABOO_VIOLATION',\n",
    "                                'conversation_turns': len(game_result['conversation']),\n",
    "                                'all_hints': ' | '.join(game_result.get('all_hints', [])),\n",
    "                                'all_guesses': ' | '.join(game_result.get('all_guesses', [])),\n",
    "                                'conversation': ' | '.join(game_result['conversation']),\n",
    "                                'duration_seconds': duration,\n",
    "                                'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                            }\n",
    "                            \n",
    "                            if 'error' in game_result:\n",
    "                                result['error'] = game_result['error']\n",
    "                            \n",
    "                            pair_results.append(result)\n",
    "                            \n",
    "                            # ç®€çŸ­ç»“æœæ˜¾ç¤º\n",
    "                            if word_idx < 5 or word_idx % 20 == 19:\n",
    "                                status = \"âœ…\" if game_result['success'] else \"âŒ\"\n",
    "                                failure_info = \"\"\n",
    "                                if not game_result['success'] and game_result.get('failure_reason'):\n",
    "                                    reason_map = {\n",
    "                                        'TABOO_VIOLATION': 'è¿è§„',\n",
    "                                        'FORMAT_FAILURE': 'æ ¼å¼',\n",
    "                                        'API_FAILURE': 'API',\n",
    "                                        'MAX_TURNS_EXCEEDED': 'è¶…æ—¶'\n",
    "                                    }\n",
    "                                    failure_info = f\" ({reason_map.get(game_result['failure_reason'], game_result['failure_reason'])})\"\n",
    "                                \n",
    "                                print(f\"      {status} {target_word}: {game_result['turns']}è½®{failure_info}\")\n",
    "                        \n",
    "                        except Exception as e:\n",
    "                            print(f\"      âŒ æ¸¸æˆæ‰§è¡Œé”™è¯¯: {target_word} - {str(e)}\")\n",
    "                            # è®°å½•é”™è¯¯ç»“æœ\n",
    "                            error_result = {\n",
    "                                'game_id': f\"kimi_{game_counter:04d}\",\n",
    "                                'pair_index': 9,\n",
    "                                'word_index': word_idx + 1,\n",
    "                                'hinter_model': hinter_model,\n",
    "                                'guesser_model': guesser_model,\n",
    "                                'target_word': target_word,\n",
    "                                'success': False,\n",
    "                                'error': str(e),\n",
    "                                'failure_reason': 'EXECUTION_ERROR',\n",
    "                                'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                            }\n",
    "                            pair_results.append(error_result)\n",
    "                        \n",
    "                        time.sleep(0.3)  # APIè°ƒç”¨é—´éš”\n",
    "                    \n",
    "                    # è®¡ç®—ç»“æœ\n",
    "                    duration = time.time() - start_time\n",
    "                    pair_success = sum(1 for r in pair_results if r['success'])\n",
    "                    pair_success_rate = pair_success / len(pair_results) * 100\n",
    "                    \n",
    "                    print(f\"\\\\nğŸ“Š {hinter_name}â†’{guesser_name} å®Œæˆ:\")\n",
    "                    print(f\"   â±ï¸  è€—æ—¶: {duration/60:.1f} åˆ†é’Ÿ\")\n",
    "                    print(f\"   ğŸ® æ¸¸æˆæ•°: {len(pair_results)}\")\n",
    "                    print(f\"   âœ… æˆåŠŸæ•°: {pair_success}\")\n",
    "                    print(f\"   ğŸ“ˆ æˆåŠŸç‡: {pair_success_rate:.1f}%\")\n",
    "                    \n",
    "                    # ä¿å­˜ç»“æœæ–‡ä»¶\n",
    "                    pair_file = f\"{results_dir}/{hinter_name}_vs_{guesser_name}_20250717_125711.csv\"\n",
    "                    pair_df = pd.DataFrame(pair_results)\n",
    "                    pair_df.to_csv(pair_file, index=False, encoding='utf-8')\n",
    "                    print(f\"   ğŸ’¾ ç»“æœå·²ä¿å­˜: {os.path.basename(pair_file)}\")\n",
    "                    \n",
    "                    print(f\"\\\\nâœ… æœ€åä¸€ç»„å®éªŒå®Œæˆï¼\")\n",
    "                else:\n",
    "                    print(\"âŒ æ•°æ®é›†æˆ–APIå®¢æˆ·ç«¯ä¸å¯ç”¨\")\n",
    "    else:\n",
    "        print(f\"\\\\nğŸ‰ æ‰€æœ‰9ç»„å®éªŒå·²å®Œæˆï¼\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ æœªæ‰¾åˆ°å®éªŒç»“æœç›®å½•ï¼Œå¯èƒ½éœ€è¦é‡æ–°å¼€å§‹å®éªŒ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š ç”ŸæˆKimiå®éªŒæœ€ç»ˆæ±‡æ€»åˆ†æ\n",
    "print(\"ğŸ“Š ç”ŸæˆKimiå®éªŒæœ€ç»ˆæ±‡æ€»åˆ†æ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "results_dir = \"results/kimi_experiment_20250717_125711\"\n",
    "\n",
    "if os.path.exists(results_dir):\n",
    "    # æ”¶é›†æ‰€æœ‰ç»“æœæ–‡ä»¶\n",
    "    csv_files = [f for f in os.listdir(results_dir) if f.endswith('.csv') and f != 'kimi_experiment_summary_20250717_125711.csv']\n",
    "    \n",
    "    if len(csv_files) >= 9:  # ç¡®ä¿æœ‰å®Œæ•´çš„9ä¸ªæ–‡ä»¶\n",
    "        print(f\"ğŸ“ æ‰¾åˆ° {len(csv_files)} ä¸ªç»“æœæ–‡ä»¶\")\n",
    "        \n",
    "        # åˆå¹¶æ‰€æœ‰ç»“æœ\n",
    "        all_results = []\n",
    "        \n",
    "        for csv_file in csv_files:\n",
    "            file_path = os.path.join(results_dir, csv_file)\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, encoding='utf-8')\n",
    "                all_results.extend(df.to_dict('records'))\n",
    "                print(f\"   âœ… {csv_file}: {len(df)} æ¡è®°å½•\")\n",
    "            except Exception as e:\n",
    "                print(f\"   âŒ {csv_file}: è¯»å–å¤±è´¥ - {e}\")\n",
    "        \n",
    "        if all_results:\n",
    "            print(f\"\\\\nğŸ“Š æ±‡æ€»ç»Ÿè®¡:\")\n",
    "            total_games = len(all_results)\n",
    "            total_success = sum(1 for r in all_results if r['success'])\n",
    "            overall_success_rate = total_success / total_games * 100\n",
    "            \n",
    "            print(f\"   ğŸ® æ€»æ¸¸æˆæ•°: {total_games:,} åœº\")\n",
    "            print(f\"   âœ… æ€»æˆåŠŸæ•°: {total_success:,} åœº\") \n",
    "            print(f\"   ğŸ“ˆ æ€»æˆåŠŸç‡: {overall_success_rate:.1f}%\")\n",
    "            \n",
    "            # ä¿å­˜æ±‡æ€»æ–‡ä»¶\n",
    "            summary_df = pd.DataFrame(all_results)\n",
    "            summary_file = f\"{results_dir}/kimi_experiment_summary_20250717_125711.csv\"\n",
    "            summary_df.to_csv(summary_file, index=False, encoding='utf-8')\n",
    "            print(f\"\\\\nğŸ’¾ æ±‡æ€»æ–‡ä»¶å·²ä¿å­˜: {os.path.basename(summary_file)}\")\n",
    "            \n",
    "            # è¯¦ç»†åˆ†æ\n",
    "            print(f\"\\\\nğŸ­ æŒ‰è§’è‰²åˆ†æ:\")\n",
    "            kimi_as_hinter = summary_df[summary_df['hinter_name'] == 'kimi-k2']\n",
    "            kimi_as_guesser = summary_df[summary_df['guesser_name'] == 'kimi-k2']\n",
    "            \n",
    "            if len(kimi_as_hinter) > 0:\n",
    "                hinter_success = sum(kimi_as_hinter['success'])\n",
    "                hinter_rate = hinter_success / len(kimi_as_hinter) * 100\n",
    "                print(f\"   ğŸŒ™ Kimiä½œHinter: {hinter_success}/{len(kimi_as_hinter)} ({hinter_rate:.1f}%)\")\n",
    "            \n",
    "            if len(kimi_as_guesser) > 0:\n",
    "                guesser_success = sum(kimi_as_guesser['success'])\n",
    "                guesser_rate = guesser_success / len(kimi_as_guesser) * 100\n",
    "                print(f\"   ğŸŒ™ Kimiä½œGuesser: {guesser_success}/{len(kimi_as_guesser)} ({guesser_rate:.1f}%)\")\n",
    "            \n",
    "            # æŒ‰æ¨¡å‹å¯¹åˆ†æ\n",
    "            print(f\"\\\\nğŸ‘¥ å„æ¨¡å‹å¯¹æˆåŠŸç‡:\")\n",
    "            pair_stats = summary_df.groupby('pair_name').agg({\n",
    "                'success': ['count', 'sum'],\n",
    "                'turns_used': 'mean'\n",
    "            }).round(1)\n",
    "            \n",
    "            for pair_name in sorted(pair_stats.index):\n",
    "                count = int(pair_stats.loc[pair_name, ('success', 'count')])\n",
    "                success = int(pair_stats.loc[pair_name, ('success', 'sum')])\n",
    "                rate = success / count * 100\n",
    "                avg_turns = pair_stats.loc[pair_name, ('turns_used', 'mean')]\n",
    "                \n",
    "                # æ ‡è®°Kimiçš„è§’è‰²\n",
    "                if 'kimi-k2â†’' in pair_name:\n",
    "                    role = \"(ğŸŒ™H)\"\n",
    "                elif 'â†’kimi-k2' in pair_name:\n",
    "                    role = \"(ğŸŒ™G)\"\n",
    "                else:\n",
    "                    role = \"\"\n",
    "                \n",
    "                print(f\"   {pair_name:<35} {role:<5}: {success:2d}/{count} ({rate:5.1f}%) å¹³å‡{avg_turns:.1f}è½®\")\n",
    "            \n",
    "            # å¤±è´¥åŸå› åˆ†æ\n",
    "            failed_df = summary_df[summary_df['success'] == False]\n",
    "            if len(failed_df) > 0:\n",
    "                print(f\"\\\\nğŸ“‰ å¤±è´¥åŸå› åˆ†æ ({len(failed_df)}åœºå¤±è´¥):\")\n",
    "                failure_counts = failed_df['failure_reason'].value_counts()\n",
    "                \n",
    "                for reason, count in failure_counts.items():\n",
    "                    percentage = count / len(failed_df) * 100\n",
    "                    reason_map = {\n",
    "                        'TABOO_VIOLATION': 'ğŸš« è¿åç¦ç”¨è¯',\n",
    "                        'FORMAT_FAILURE': 'ğŸ”¤ æ ¼å¼é”™è¯¯', \n",
    "                        'API_FAILURE': 'ğŸŒ APIå¤±è´¥',\n",
    "                        'MAX_TURNS_EXCEEDED': 'â±ï¸ è½®æ•°è€—å°½',\n",
    "                        'EXECUTION_ERROR': 'ğŸ’¥ æ‰§è¡Œé”™è¯¯'\n",
    "                    }\n",
    "                    reason_name = reason_map.get(reason, reason)\n",
    "                    print(f\"   {reason_name}: {count} åœº ({percentage:.1f}%)\")\n",
    "            \n",
    "            # æŒ‰è¯æ±‡ç±»åˆ«åˆ†æ\n",
    "            if 'category' in summary_df.columns:\n",
    "                print(f\"\\\\nğŸ·ï¸ æŒ‰è¯æ±‡ç±»åˆ«æˆåŠŸç‡:\")\n",
    "                category_stats = summary_df.groupby('category').agg({\n",
    "                    'success': ['count', 'sum']\n",
    "                }).round(1)\n",
    "                \n",
    "                for category in sorted(category_stats.index):\n",
    "                    count = int(category_stats.loc[category, ('success', 'count')])\n",
    "                    success = int(category_stats.loc[category, ('success', 'sum')])\n",
    "                    rate = success / count * 100\n",
    "                    print(f\"   {category:<12}: {success:3d}/{count:3d} ({rate:5.1f}%)\")\n",
    "            \n",
    "            print(f\"\\\\nğŸ‰ Kimiå®éªŒå®Œæ•´åˆ†æå®Œæˆï¼\")\n",
    "            print(f\"ğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {results_dir}\")\n",
    "            print(f\"ğŸ“„ æ±‡æ€»æ–‡ä»¶: kimi_experiment_summary_20250717_125711.csv\")\n",
    "            \n",
    "        else:\n",
    "            print(\"âŒ æ— æ³•è¯»å–ç»“æœæ•°æ®\")\n",
    "    else:\n",
    "        print(f\"âŒ ç»“æœæ–‡ä»¶ä¸å®Œæ•´ï¼ŒæœŸæœ›9ä¸ªï¼Œå®é™…{len(csv_files)}ä¸ª\")\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ å®éªŒç»“æœç›®å½•ä¸å­˜åœ¨\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ è¿è¡Œæœ€åä¸€ç»„å®éªŒ: claude-sonnet-4 â†’ kimi-k2\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m missing_file = \u001b[33m\"\u001b[39m\u001b[33mclaude-sonnet-4_vs_kimi-k2_20250717_125711.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m missing_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m.path.exists(missing_path):\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ… æ–‡ä»¶å·²å­˜åœ¨: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mæ— éœ€é‡å¤è¿è¡Œå®éªŒ\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# ğŸš€ è¿è¡Œæœ€åä¸€ç»„å®éªŒ: claude-sonnet-4 â†’ kimi-k2\n",
    "print(\"ğŸš€ è¿è¡Œæœ€åä¸€ç»„å®éªŒ: claude-sonnet-4 â†’ kimi-k2\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# æ£€æŸ¥æ˜¯å¦éœ€è¦è¿è¡Œ\n",
    "results_dir = \"results/kimi_experiment_20250717_125711\"\n",
    "missing_file = \"claude-sonnet-4_vs_kimi-k2_20250717_125711.csv\"\n",
    "missing_path = f\"{results_dir}/{missing_file}\"\n",
    "\n",
    "if os.path.exists(missing_path):\n",
    "    print(f\"âœ… æ–‡ä»¶å·²å­˜åœ¨: {missing_file}\")\n",
    "    print(\"æ— éœ€é‡å¤è¿è¡Œå®éªŒ\")\n",
    "else:\n",
    "    print(f\"âŒ ç¼ºå¤±æ–‡ä»¶: {missing_file}\")\n",
    "    print(\"å¼€å§‹æ‰§è¡Œæœ€åä¸€ç»„å®éªŒ...\")\n",
    "    \n",
    "    # å®éªŒé…ç½®\n",
    "    hinter_model = \"anthropic/claude-sonnet-4\"\n",
    "    guesser_model = \"moonshotai/kimi-k2\"\n",
    "    hinter_name = \"claude-sonnet-4\"\n",
    "    guesser_name = \"kimi-k2\"\n",
    "    \n",
    "    print(f\"ğŸ¤– æ¨¡å‹å¯¹: {hinter_name} â†’ {guesser_name}\")\n",
    "    print(f\"ğŸ“š æ•°æ®é›†: {len(quick80_dataset)} ä¸ªè¯æ±‡\")\n",
    "    print(f\"ğŸ“ è¾“å‡ºç›®å½•: {results_dir}\")\n",
    "    \n",
    "    # æ‰§è¡Œå®éªŒ\n",
    "    pair_results = []\n",
    "    game_counter = 640  # å‰8ç»„å·²å®Œæˆ640åœºæ¸¸æˆ\n",
    "    \n",
    "    start_time = time.time()\n",
    "    print(f\"\\\\nâ±ï¸  å¼€å§‹æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    \n",
    "    for word_idx, word_data in enumerate(quick80_dataset):\n",
    "        game_counter += 1\n",
    "        target_word = word_data['target']\n",
    "        taboo_words = word_data['taboo']\n",
    "        \n",
    "        # è¿›åº¦æ˜¾ç¤º\n",
    "        if word_idx % 10 == 0 or word_idx < 5:\n",
    "            progress = (word_idx + 1) / len(quick80_dataset) * 100\n",
    "            print(f\"   ğŸ¯ è¯æ±‡ {word_idx+1:2d}/80: {target_word:<15} ({progress:5.1f}%)\")\n",
    "        \n",
    "        # æ‰§è¡Œæ¸¸æˆ\n",
    "        game_start = time.time()\n",
    "        try:\n",
    "            game_result = enhanced_play_taboo_game(\n",
    "                client, hinter_model, guesser_model,\n",
    "                target_word, taboo_words, max_turns=5\n",
    "            )\n",
    "            \n",
    "            duration = round(time.time() - game_start, 2)\n",
    "            \n",
    "            # è®°å½•ç»“æœ\n",
    "            result = {\n",
    "                'game_id': f\"kimi_{game_counter:04d}\",\n",
    "                'pair_index': 9,\n",
    "                'word_index': word_idx + 1,\n",
    "                'hinter_model': hinter_model,\n",
    "                'guesser_model': guesser_model,\n",
    "                'hinter_name': hinter_name,\n",
    "                'guesser_name': guesser_name,\n",
    "                'pair_name': f\"{hinter_name}â†’{guesser_name}\",\n",
    "                'target_word': target_word,\n",
    "                'category': word_data.get('category', 'unknown'),\n",
    "                'taboo_words': '|'.join(taboo_words),\n",
    "                'success': game_result['success'],\n",
    "                'turns_used': game_result['turns'],\n",
    "                'final_guess': game_result['final_guess'],\n",
    "                'failure_reason': game_result.get('failure_reason', None),\n",
    "                'has_taboo_violation': game_result.get('failure_reason') == 'TABOO_VIOLATION',\n",
    "                'conversation_turns': len(game_result['conversation']),\n",
    "                'all_hints': ' | '.join(game_result.get('all_hints', [])),\n",
    "                'all_guesses': ' | '.join(game_result.get('all_guesses', [])),\n",
    "                'conversation': ' | '.join(game_result['conversation']),\n",
    "                'duration_seconds': duration,\n",
    "                'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "            \n",
    "            if 'error' in game_result:\n",
    "                result['error'] = game_result['error']\n",
    "            \n",
    "            pair_results.append(result)\n",
    "            \n",
    "            # ç»“æœæ˜¾ç¤º\n",
    "            if word_idx < 5 or word_idx % 20 == 19 or word_idx == len(quick80_dataset) - 1:\n",
    "                status = \"âœ…\" if game_result['success'] else \"âŒ\"\n",
    "                failure_info = \"\"\n",
    "                if not game_result['success'] and game_result.get('failure_reason'):\n",
    "                    reason_map = {\n",
    "                        'TABOO_VIOLATION': 'è¿è§„',\n",
    "                        'FORMAT_FAILURE': 'æ ¼å¼',\n",
    "                        'API_FAILURE': 'API',\n",
    "                        'MAX_TURNS_EXCEEDED': 'è¶…æ—¶'\n",
    "                    }\n",
    "                    failure_info = f\" ({reason_map.get(game_result['failure_reason'], game_result['failure_reason'])})\"\n",
    "                \n",
    "                print(f\"      {status} {target_word:<15}: {game_result['turns']}è½®{failure_info}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"      âŒ æ¸¸æˆæ‰§è¡Œé”™è¯¯: {target_word} - {str(e)}\")\n",
    "            # è®°å½•é”™è¯¯ç»“æœ\n",
    "            error_result = {\n",
    "                'game_id': f\"kimi_{game_counter:04d}\",\n",
    "                'pair_index': 9,\n",
    "                'word_index': word_idx + 1,\n",
    "                'hinter_model': hinter_model,\n",
    "                'guesser_model': guesser_model,\n",
    "                'hinter_name': hinter_name,\n",
    "                'guesser_name': guesser_name,\n",
    "                'pair_name': f\"{hinter_name}â†’{guesser_name}\",\n",
    "                'target_word': target_word,\n",
    "                'category': word_data.get('category', 'unknown'),\n",
    "                'success': False,\n",
    "                'turns_used': 0,\n",
    "                'final_guess': 'EXECUTION_ERROR',\n",
    "                'error': str(e),\n",
    "                'failure_reason': 'EXECUTION_ERROR',\n",
    "                'has_taboo_violation': False,\n",
    "                'conversation_turns': 0,\n",
    "                'all_hints': '',\n",
    "                'all_guesses': '',\n",
    "                'conversation': '',\n",
    "                'duration_seconds': 0,\n",
    "                'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "            pair_results.append(error_result)\n",
    "        \n",
    "        time.sleep(0.3)  # APIè°ƒç”¨é—´éš”\n",
    "    \n",
    "    # è®¡ç®—å’Œæ˜¾ç¤ºç»“æœ\n",
    "    total_duration = time.time() - start_time\n",
    "    pair_success = sum(1 for r in pair_results if r['success'])\n",
    "    pair_success_rate = pair_success / len(pair_results) * 100\n",
    "    \n",
    "    print(f\"\\\\nğŸ“Š {hinter_name}â†’{guesser_name} å®éªŒå®Œæˆ:\")\n",
    "    print(f\"   â±ï¸  æ€»è€—æ—¶: {total_duration/60:.1f} åˆ†é’Ÿ\")\n",
    "    print(f\"   ğŸ® æ¸¸æˆæ•°: {len(pair_results)}\")\n",
    "    print(f\"   âœ… æˆåŠŸæ•°: {pair_success}\")\n",
    "    print(f\"   ğŸ“ˆ æˆåŠŸç‡: {pair_success_rate:.1f}%\")\n",
    "    \n",
    "    # å¤±è´¥åˆ†æ\n",
    "    failed_results = [r for r in pair_results if not r['success']]\n",
    "    if failed_results:\n",
    "        print(f\"   ğŸ“‰ å¤±è´¥æ•°: {len(failed_results)}\")\n",
    "        failure_reasons = {}\n",
    "        for r in failed_results:\n",
    "            reason = r.get('failure_reason', 'UNKNOWN')\n",
    "            failure_reasons[reason] = failure_reasons.get(reason, 0) + 1\n",
    "        \n",
    "        for reason, count in failure_reasons.items():\n",
    "            print(f\"      {reason}: {count}åœº\")\n",
    "    \n",
    "    # ä¿å­˜ç»“æœæ–‡ä»¶\n",
    "    try:\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        pair_df = pd.DataFrame(pair_results)\n",
    "        pair_df.to_csv(missing_path, index=False, encoding='utf-8')\n",
    "        print(f\"\\\\nğŸ’¾ ç»“æœå·²ä¿å­˜: {missing_file}\")\n",
    "        print(f\"   ğŸ“„ æ–‡ä»¶è·¯å¾„: {missing_path}\")\n",
    "        print(f\"   ğŸ“Š è®°å½•æ•°: {len(pair_results)}\")\n",
    "        \n",
    "        print(f\"\\\\nğŸ‰ æœ€åä¸€ç»„å®éªŒå®Œæˆï¼ç°åœ¨æ‰€æœ‰9ç»„å®éªŒéƒ½å·²å°±ç»ªã€‚\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\\\nâŒ ä¿å­˜å¤±è´¥: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ˆ ç»“æœåˆ†æï¼ˆå®éªŒå®Œæˆåè¿è¡Œï¼‰\n",
    "print(\"ğŸ“ˆ Kimiå®éªŒç»“æœåˆ†æ\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# åˆ†ææœ€è¿‘çš„å®éªŒç»“æœ\n",
    "def analyze_kimi_results():\n",
    "    \"\"\"åˆ†æKimiå®éªŒç»“æœ\"\"\"\n",
    "    \n",
    "    # æŸ¥æ‰¾æœ€æ–°çš„ç»“æœç›®å½•\n",
    "    results_base = \"results\"\n",
    "    if not os.path.exists(results_base):\n",
    "        print(\"âŒ æœªæ‰¾åˆ°resultsç›®å½•\")\n",
    "        return\n",
    "    \n",
    "    # æŸ¥æ‰¾kimiå®éªŒç›®å½•\n",
    "    kimi_dirs = [d for d in os.listdir(results_base) if d.startswith(\"kimi_experiment_\")]\n",
    "    if not kimi_dirs:\n",
    "        print(\"âŒ æœªæ‰¾åˆ°Kimiå®éªŒç»“æœ\")\n",
    "        return\n",
    "    \n",
    "    # ä½¿ç”¨æœ€æ–°çš„å®éªŒç›®å½•\n",
    "    latest_dir = max(kimi_dirs)\n",
    "    results_dir = os.path.join(results_base, latest_dir)\n",
    "    \n",
    "    print(f\"ğŸ“ åˆ†æç›®å½•: {latest_dir}\")\n",
    "    \n",
    "    # æŸ¥æ‰¾æ±‡æ€»æ–‡ä»¶\n",
    "    summary_files = [f for f in os.listdir(results_dir) if f.startswith(\"kimi_experiment_summary_\")]\n",
    "    if not summary_files:\n",
    "        print(\"âŒ æœªæ‰¾åˆ°æ±‡æ€»æ–‡ä»¶\")\n",
    "        return\n",
    "    \n",
    "    summary_file = os.path.join(results_dir, summary_files[0])\n",
    "    \n",
    "    try:\n",
    "        # åŠ è½½ç»“æœæ•°æ®\n",
    "        df = pd.read_csv(summary_file, encoding='utf-8')\n",
    "        print(f\"âœ… åŠ è½½æ•°æ®: {len(df)} æ¡è®°å½•\")\n",
    "        \n",
    "        # åŸºæœ¬ç»Ÿè®¡\n",
    "        total_games = len(df)\n",
    "        total_success = sum(df['success'])\n",
    "        overall_success_rate = total_success / total_games * 100\n",
    "        \n",
    "        print(f\"\\\\nğŸ“Š åŸºæœ¬ç»Ÿè®¡:\")\n",
    "        print(f\"   ğŸ® æ€»æ¸¸æˆæ•°: {total_games:,} åœº\")\n",
    "        print(f\"   âœ… æˆåŠŸæ•°: {total_success:,} åœº\")\n",
    "        print(f\"   ğŸ“ˆ æ€»æˆåŠŸç‡: {overall_success_rate:.1f}%\")\n",
    "        \n",
    "        # æŒ‰è§’è‰²åˆ†æ\n",
    "        print(f\"\\\\nğŸ­ æŒ‰è§’è‰²åˆ†æ:\")\n",
    "        kimi_as_hinter = df[df['hinter_name'] == 'kimi-k2']\n",
    "        kimi_as_guesser = df[df['guesser_name'] == 'kimi-k2']\n",
    "        \n",
    "        if len(kimi_as_hinter) > 0:\n",
    "            hinter_success = sum(kimi_as_hinter['success'])\n",
    "            hinter_rate = hinter_success / len(kimi_as_hinter) * 100\n",
    "            print(f\"   ğŸŒ™ Kimiä½œHinter: {hinter_success}/{len(kimi_as_hinter)} ({hinter_rate:.1f}%)\")\n",
    "        \n",
    "        if len(kimi_as_guesser) > 0:\n",
    "            guesser_success = sum(kimi_as_guesser['success'])\n",
    "            guesser_rate = guesser_success / len(kimi_as_guesser) * 100\n",
    "            print(f\"   ğŸŒ™ Kimiä½œGuesser: {guesser_success}/{len(kimi_as_guesser)} ({guesser_rate:.1f}%)\")\n",
    "        \n",
    "        # æŒ‰æ¨¡å‹å¯¹åˆ†æ\n",
    "        print(f\"\\\\nğŸ‘¥ æŒ‰æ¨¡å‹å¯¹åˆ†æ:\")\n",
    "        pair_stats = df.groupby('pair_name').agg({\n",
    "            'success': ['count', 'sum'],\n",
    "            'turns_used': 'mean'\n",
    "        }).round(2)\n",
    "        \n",
    "        for pair_name in pair_stats.index:\n",
    "            count = pair_stats.loc[pair_name, ('success', 'count')]\n",
    "            success = pair_stats.loc[pair_name, ('success', 'sum')]\n",
    "            rate = success / count * 100\n",
    "            avg_turns = pair_stats.loc[pair_name, ('turns_used', 'mean')]\n",
    "            print(f\"   {pair_name}: {success}/{count} ({rate:.1f}%) å¹³å‡{avg_turns:.1f}è½®\")\n",
    "        \n",
    "        # å¤±è´¥åŸå› åˆ†æ\n",
    "        failed_df = df[df['success'] == False]\n",
    "        if len(failed_df) > 0:\n",
    "            print(f\"\\\\nğŸ“‰ å¤±è´¥åŸå› åˆ†æ:\")\n",
    "            failure_counts = failed_df['failure_reason'].value_counts()\n",
    "            for reason, count in failure_counts.items():\n",
    "                percentage = count / len(failed_df) * 100\n",
    "                reason_map = {\n",
    "                    'TABOO_VIOLATION': 'ğŸš« è¿åç¦ç”¨è¯',\n",
    "                    'FORMAT_FAILURE': 'ğŸ”¤ æ ¼å¼é”™è¯¯',\n",
    "                    'API_FAILURE': 'ğŸŒ APIå¤±è´¥',\n",
    "                    'MAX_TURNS_EXCEEDED': 'â±ï¸ è½®æ•°è€—å°½',\n",
    "                    'EXECUTION_ERROR': 'ğŸ’¥ æ‰§è¡Œé”™è¯¯'\n",
    "                }\n",
    "                reason_name = reason_map.get(reason, reason)\n",
    "                print(f\"   {reason_name}: {count} åœº ({percentage:.1f}%)\")\n",
    "        \n",
    "        # æŒ‰ç±»åˆ«åˆ†æ\n",
    "        if 'category' in df.columns:\n",
    "            print(f\"\\\\nğŸ·ï¸ æŒ‰è¯æ±‡ç±»åˆ«åˆ†æ:\")\n",
    "            category_stats = df.groupby('category').agg({\n",
    "                'success': ['count', 'sum']\n",
    "            })\n",
    "            \n",
    "            for category in category_stats.index:\n",
    "                count = category_stats.loc[category, ('success', 'count')]\n",
    "                success = category_stats.loc[category, ('success', 'sum')]\n",
    "                rate = success / count * 100\n",
    "                print(f\"   {category}: {success}/{count} ({rate:.1f}%)\")\n",
    "        \n",
    "        print(f\"\\\\nğŸ’¾ è¯¦ç»†æ•°æ®ä½ç½®: {summary_file}\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ åˆ†æé”™è¯¯: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# æ‰§è¡Œåˆ†æ\n",
    "print(\"ğŸ” å¼€å§‹åˆ†ææœ€æ–°çš„Kimiå®éªŒç»“æœ...\")\n",
    "result_df = analyze_kimi_results()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
