# ä¸­æ–‡Tabooå®éªŒå®Œæ•´æ¡†æ¶

> åŸºäºbase_test.ipynbæ¡†æ¶ï¼Œä½¿ç”¨OpenHowNetæ„å»ºä¸­æ–‡æ•°æ®é›†çš„å®Œæ•´å®éªŒç³»ç»Ÿ

## ğŸ“‹ å®éªŒæ¦‚è§ˆ

### ğŸ¯ å®éªŒç›®æ ‡
1. **æ„å»ºé«˜è´¨é‡ä¸­æ–‡Tabooæ•°æ®é›†**ï¼šä½¿ç”¨OpenHowNetæ„å»º100ä¸ªä¸­æ–‡è¯æ±‡çš„è¯­ä¹‰æ•°æ®é›†
2. **è¯„ä¼°ä¸­æ–‡LLMè¡¨ç°**ï¼šæµ‹è¯•å¤šä¸ªè¯­è¨€æ¨¡å‹åœ¨ä¸­æ–‡çº¦æŸæ¡ä»¶ä¸‹çš„æ²Ÿé€šèƒ½åŠ›
3. **å»ºç«‹ä¸­æ–‡è¯„ä¼°åŸºå‡†**ï¼šä¸ºä¸­æ–‡LLMèƒ½åŠ›è¯„ä¼°æä¾›æ ‡å‡†åŒ–å·¥å…·

### ğŸ—ï¸ æŠ€æœ¯åˆ›æ–°
- **é¦–æ¬¡ä½¿ç”¨OpenHowNet**ï¼šå°†ä¸­æ–‡çŸ¥è¯†å›¾è°±åº”ç”¨äºTabooæ¸¸æˆæ•°æ®é›†æ„å»º
- **ä¸­æ–‡è¯­è¨€ç‰¹åŒ–**ï¼šé’ˆå¯¹ä¸­æ–‡è¯­è¨€ç‰¹ç‚¹ä¼˜åŒ–æ ¼å¼æ£€æŸ¥å’Œè¯„ä¼°æœºåˆ¶
- **ç»Ÿä¸€å®éªŒæ¶æ„**ï¼šç»§æ‰¿base_testæˆç†Ÿæ¡†æ¶ï¼Œç¡®ä¿å®éªŒç§‘å­¦æ€§

## ğŸ”§ å®éªŒæ¶æ„è®¾è®¡

### æ¨¡å—1: ç¯å¢ƒé…ç½® (Environment Setup)

**å‚è€ƒbase_testç¬¬1éƒ¨åˆ†**

```python
# 1.1 æ ¸å¿ƒä¾èµ–å¯¼å…¥
import json
import pandas as pd
import random
import time
import requests
import os
import jieba
import re
from typing import Dict, List, Any, Tuple
from datetime import datetime
from collections import Counter

# 1.2 ä¸­æ–‡ç‰¹åŒ–ä¾èµ–
import OpenHowNet  # ä¸­æ–‡çŸ¥è¯†å›¾è°±
jieba.setLogLevel(logging.INFO)  # å‡å°‘åˆ†è¯æ—¥å¿—è¾“å‡º

# 1.3 è®¾ç½®
random.seed(42)  # ç¡®ä¿å¯å¤ç°
print("ğŸš€ ä¸­æ–‡Tabooå®éªŒç¯å¢ƒåˆå§‹åŒ–å®Œæˆ")
```

### æ¨¡å—2: æ•°æ®é›†æ„å»º (Dataset Construction)

**å¯¹åº”base_testçš„æ•°æ®é›†åŠ è½½ï¼Œä½†è¿™é‡Œæ˜¯åŠ¨æ€æ„å»º**

#### 2.1 OpenHowNetåˆå§‹åŒ–
```python
def initialize_hownet():
    """åˆå§‹åŒ–OpenHowNetçŸ¥è¯†å›¾è°±"""
    try:
        hownet_dict = OpenHowNet.HowNetDict()
        print("âœ… OpenHowNetåˆå§‹åŒ–æˆåŠŸ")
        return hownet_dict
    except Exception as e:
        print(f"âŒ OpenHowNetåˆå§‹åŒ–å¤±è´¥: {e}")
        return None
```

#### 2.2 ä¸­æ–‡è¯æ±‡ç­›é€‰
```python
def select_chinese_words(hownet_dict, target_count=100):
    """ç­›é€‰ä¸­æ–‡è¯æ±‡"""
    # ç­›é€‰æ¡ä»¶:
    # - åŒ…å«ä¸­æ–‡å­—ç¬¦ (\\u4e00-\\u9fff)
    # - é•¿åº¦åœ¨1-6å­—ç¬¦ä¹‹é—´
    # - åœ¨HowNetä¸­æœ‰è¯­ä¹‰å®šä¹‰
    # - è¯æ€§åˆ†å¸ƒå¹³è¡¡: åè¯ã€åŠ¨è¯ã€å½¢å®¹è¯ã€å‰¯è¯å„25ä¸ª
    
    chinese_pattern = re.compile(r'[\u4e00-\u9fff]')
    selected_words = {
        'noun': [], 'verb': [], 'adj': [], 'adv': []
    }
    
    # å®ç°è¯æ±‡é€‰æ‹©é€»è¾‘...
    return selected_words
```

#### 2.3 ç¦ç”¨è¯ç”Ÿæˆ
```python
def generate_taboo_words(hownet_dict, word, sense_info):
    """ä½¿ç”¨OpenHowNetç”Ÿæˆè¯­ä¹‰ç›¸å…³çš„ç¦ç”¨è¯"""
    taboo_words = []
    
    # æ–¹æ³•1: åŒä¹‰è¯
    synonyms = hownet_dict.get_synonyms(word)
    taboo_words.extend(synonyms[:2])
    
    # æ–¹æ³•2: è¯­ä¹‰ç›¸ä¼¼è¯
    similar_words = hownet_dict.calculate_word_similarity(word, ...)
    taboo_words.extend(similar_words[:2])
    
    # æ–¹æ³•3: å®šä¹‰å…³é”®è¯æå–
    definition_keywords = extract_definition_keywords(sense_info)
    taboo_words.extend(definition_keywords[:1])
    
    return taboo_words[:5]  # æ¯ä¸ªè¯æ±‡5ä¸ªç¦ç”¨è¯
```

#### 2.4 æ•°æ®é›†æ„å»ºä¸éªŒè¯
```python
def build_chinese_dataset(hownet_dict):
    """æ„å»ºå®Œæ•´çš„ä¸­æ–‡Tabooæ•°æ®é›†"""
    dataset = []
    
    # æŒ‰è¯æ€§åˆ†åˆ«é€‰æ‹©è¯æ±‡
    for pos, words in selected_words.items():
        for word in words:
            # è·å–è¯­ä¹‰ä¿¡æ¯
            senses = hownet_dict.get_sense(word)
            
            # ç”Ÿæˆç¦ç”¨è¯
            taboo_words = generate_taboo_words(hownet_dict, word, senses)
            
            # æ„å»ºæ•°æ®é¡¹
            data_item = {
                'target': word,
                'part_of_speech': pos,
                'taboo': taboo_words,
                'category': 'chinese_general',
                'senses': format_sense_info(senses)
            }
            dataset.append(data_item)
    
    return dataset
```

### æ¨¡å—3: æ•°æ®é›†ç»Ÿè®¡åˆ†æ (Dataset Analysis)

**å¯¹åº”base_testç¬¬2éƒ¨åˆ†**

```python
def analyze_chinese_dataset(dataset):
    """åˆ†æä¸­æ–‡æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
    print("ğŸ“Š ä¸­æ–‡æ•°æ®é›†åŸºæœ¬ç»Ÿè®¡:")
    print("=" * 40)
    
    # è¯æ€§åˆ†å¸ƒç»Ÿè®¡
    pos_counts = {}
    taboo_counts = []
    sense_counts = []
    
    for item in dataset:
        pos = item.get('part_of_speech', 'unknown')
        pos_counts[pos] = pos_counts.get(pos, 0) + 1
        taboo_counts.append(len(item.get('taboo', [])))
        sense_counts.append(len(item.get('senses', [])))
    
    print(f"ğŸ·ï¸ è¯æ€§åˆ†å¸ƒ:")
    for pos, count in pos_counts.items():
        percentage = count / len(dataset) * 100
        print(f"   {pos}: {count} ä¸ª ({percentage:.1f}%)")
    
    print(f"ğŸš« ç¦ç”¨è¯ç»Ÿè®¡:")
    print(f"   å¹³å‡æ•°é‡: {sum(taboo_counts) / len(taboo_counts):.1f}")
    print(f"   èŒƒå›´: {min(taboo_counts)} - {max(taboo_counts)}")
    
    print(f"ğŸ’­ è¯ä¹‰ç»Ÿè®¡:")
    print(f"   å¹³å‡æ•°é‡: {sum(sense_counts) / len(sense_counts):.1f}")
    print(f"   èŒƒå›´: {min(sense_counts)} - {max(sense_counts)}")
    
    print("âœ… ä¸­æ–‡æ•°æ®é›†ç»Ÿè®¡å®Œæˆï¼Œè´¨é‡è‰¯å¥½")
```

### æ¨¡å—4: APIå®¢æˆ·ç«¯è®¾ç½® (API Configuration)

**å¯¹åº”base_testç¬¬3éƒ¨åˆ†ï¼Œæ·»åŠ ä¸­æ–‡æ¨¡å‹æ”¯æŒ**

```python
class ChineseAPIClient:
    """æ”¯æŒä¸­æ–‡æ¨¡å‹çš„APIå®¢æˆ·ç«¯"""
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://openrouter.ai/api/v1/chat/completions"
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
    
    def call_model(self, model: str, messages: List[Dict[str, str]], 
                   temperature: float = 0.3) -> str:
        """è°ƒç”¨æ¨¡å‹APIï¼Œä¿æŒä¸­æ–‡å­—ç¬¦"""
        payload = {
            "model": model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": 2000
        }
        response = requests.post(self.base_url, headers=self.headers, 
                               json=payload, timeout=30)
        response.raise_for_status()
        result = response.json()
        content = result['choices'][0]['message']['content'].strip()
        
        # ä¿ç•™ä¸­æ–‡å­—ç¬¦ï¼Œåªè¿‡æ»¤æ§åˆ¶å­—ç¬¦
        content = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', content)
        return content

# ä¸­æ–‡æµ‹è¯•æ¨¡å‹åˆ—è¡¨
CHINESE_MODELS = [
    "openai/gpt-4o",
    "google/gemini-2.5-pro", 
    "deepseek/deepseek-chat-v3-0324",
    "anthropic/claude-sonnet-4"
]
```

### æ¨¡å—5: ä¸­æ–‡æ¸¸æˆé€»è¾‘ (Chinese Game Logic)

**å¯¹åº”base_testç¬¬4éƒ¨åˆ†ï¼Œé€‚é…ä¸­æ–‡æ ¼å¼**

```python
def chinese_taboo_game(client, hinter_model, guesser_model, 
                      target_word, taboo_words, max_turns=5):
    """ä¸­æ–‡Tabooæ¸¸æˆæ ¸å¿ƒé€»è¾‘"""
    
    # ä¸­æ–‡æç¤ºæ¨¡æ¿
    hinter_prompt = f"""
ä½ æ­£åœ¨ç©ä¸­æ–‡Tabooæ¸¸æˆã€‚ä½ çš„ä»»åŠ¡æ˜¯è®©é˜Ÿå‹çŒœå‡ºç›®æ ‡è¯æ±‡ï¼Œä½†ä¸èƒ½ä½¿ç”¨ç¦ç”¨è¯ã€‚

ç›®æ ‡è¯æ±‡: {target_word}
ç¦ç”¨è¯æ±‡: {', '.join(taboo_words)}

è§„åˆ™:
1. ä½ éœ€è¦ç»™å‡ºçº¿ç´¢è®©é˜Ÿå‹çŒœå‡ºç›®æ ‡è¯æ±‡
2. ä½ çš„çº¿ç´¢ä¸­ä¸èƒ½åŒ…å«ä»»ä½•ç¦ç”¨è¯æ±‡
3. è¯·ç”¨æ ¼å¼ [çº¿ç´¢] å¼€å§‹ä½ çš„å›ç­”

è¯·ç»™å‡ºä½ çš„ç¬¬ä¸€ä¸ªçº¿ç´¢:
"""

    guesser_prompt = f"""
ä½ æ­£åœ¨ç©ä¸­æ–‡Tabooæ¸¸æˆã€‚æ ¹æ®é˜Ÿå‹ç»™å‡ºçš„çº¿ç´¢ï¼ŒçŒœå‡ºç›®æ ‡è¯æ±‡ã€‚

ç¦ç”¨è¯æ±‡: {', '.join(taboo_words)}

è§„åˆ™:
1. æ ¹æ®é˜Ÿå‹çš„çº¿ç´¢çŒœå‡ºç›®æ ‡è¯æ±‡
2. è¯·ç”¨æ ¼å¼ [çŒœæµ‹] å¼€å§‹ä½ çš„å›ç­”
3. åªè¯´å‡ºä½ è®¤ä¸ºçš„ç­”æ¡ˆï¼Œä¸è¦è§£é‡Š

é˜Ÿå‹çš„çº¿ç´¢æ˜¯: {hint}

ä½ çš„çŒœæµ‹æ˜¯:
"""

    # æ¸¸æˆæ‰§è¡Œé€»è¾‘
    conversation_history = []
    
    for turn in range(1, max_turns + 1):
        # Hinterç»™å‡ºçº¿ç´¢
        hinter_response = robust_chinese_api_call(
            client, hinter_model, hinter_prompt, "[çº¿ç´¢]"
        )
        
        if not hinter_response['success']:
            return create_game_result(False, turn, None, "çº¿ç´¢ç”Ÿæˆå¤±è´¥", 
                                    conversation_history)
        
        hint = hinter_response['content']
        
        # æ£€æŸ¥ç¦ç”¨è¯è¿è§„
        if check_chinese_taboo_violation(hint, taboo_words):
            return create_game_result(False, turn, None, "è¿åç¦ç”¨è¯è§„åˆ™", 
                                    conversation_history)
        
        # Guesserè¿›è¡ŒçŒœæµ‹
        current_guesser_prompt = guesser_prompt.format(hint=hint)
        guesser_response = robust_chinese_api_call(
            client, guesser_model, current_guesser_prompt, "[çŒœæµ‹]"
        )
        
        if not guesser_response['success']:
            return create_game_result(False, turn, None, "çŒœæµ‹ç”Ÿæˆå¤±è´¥", 
                                    conversation_history)
        
        guess = guesser_response['content']
        
        # è®°å½•å¯¹è¯
        conversation_history.append({
            'turn': turn,
            'hint': hint,
            'guess': guess
        })
        
        # æ£€æŸ¥æ˜¯å¦çŒœä¸­
        if check_chinese_word_match(guess, target_word):
            return create_game_result(True, turn, guess, "æˆåŠŸ", 
                                    conversation_history)
    
    # è¶…è¿‡æœ€å¤§è½®æ•°
    return create_game_result(False, max_turns, guess, "è½®æ•°è€—å°½", 
                            conversation_history)
```

### æ¨¡å—6: ä¸­æ–‡ç‰¹åŒ–è¾…åŠ©å‡½æ•° (Chinese Helper Functions)

```python
def robust_chinese_api_call(client, model, prompt, expected_prefix, 
                           max_retries=3):
    """æ”¯æŒä¸­æ–‡æ ¼å¼çš„å¥å£®APIè°ƒç”¨"""
    for attempt in range(1, max_retries + 1):
        try:
            response = client.call_model(model, 
                                       [{"role": "user", "content": prompt}])
            
            if response.strip().startswith(expected_prefix):
                content = response.strip()[len(expected_prefix):].strip()
                return {
                    'success': True,
                    'content': content,
                    'attempts': attempt
                }
            else:
                # æ ¼å¼é”™è¯¯ï¼Œæ·»åŠ æé†’é‡è¯•
                if attempt < max_retries:
                    prompt += f"""

âš ï¸ æ ¼å¼é”™è¯¯ âš ï¸
ä½ çš„å›ç­”å¿…é¡»ä»¥ '{expected_prefix}' å¼€å¤´
è¯·é‡æ–°å›ç­”:"""
                
        except Exception as e:
            if attempt == max_retries:
                return {
                    'success': False,
                    'content': f"APIè°ƒç”¨å¤±è´¥: {e}",
                    'attempts': attempt
                }
    
    return {
        'success': False,
        'content': "æ ¼å¼éªŒè¯å¤±è´¥",
        'attempts': max_retries
    }

def check_chinese_taboo_violation(text, taboo_words):
    """æ£€æŸ¥ä¸­æ–‡æ–‡æœ¬æ˜¯å¦è¿åç¦ç”¨è¯è§„åˆ™"""
    # ä½¿ç”¨jiebaåˆ†è¯
    words = jieba.cut(text, cut_all=False)
    text_words = set(words)
    
    for taboo in taboo_words:
        if taboo in text or taboo in text_words:
            return True
    return False

def check_chinese_word_match(guess, target):
    """æ£€æŸ¥ä¸­æ–‡è¯æ±‡æ˜¯å¦åŒ¹é…"""
    # ç§»é™¤æ ¼å¼æ ‡è®°å’Œç©ºæ ¼
    guess_clean = re.sub(r'[\[\]ã€ã€‘]', '', guess).strip()
    
    # ç›´æ¥åŒ¹é…æˆ–åŒ…å«åŒ¹é…
    return guess_clean == target or target in guess_clean
```

### æ¨¡å—7: å®éªŒæ‰§è¡Œå™¨ (Experiment Runner)

**å¯¹åº”base_testç¬¬5-6éƒ¨åˆ†**

```python
def run_chinese_taboo_experiment(client, models, dataset, config):
    """æ‰§è¡Œä¸­æ–‡Tabooå®éªŒ"""
    
    experiment_type = config.get('experiment_type', 'test')
    max_turns = config.get('max_turns', 5)
    output_dir = config.get('output_dir', 'results')
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    experiment_dir = f"{output_dir}/chinese_experiment_{timestamp}"
    os.makedirs(experiment_dir, exist_ok=True)
    
    print(f"ğŸš€ å¼€å§‹æ‰§è¡Œä¸­æ–‡Tabooå®éªŒ...")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {experiment_dir}")
    print(f"ğŸ¯ è¯æ±‡æ•°é‡: {len(dataset)}")
    print(f"ğŸ¤– æ¨¡å‹æ•°é‡: {len(models)}")
    
    all_results = []
    game_counter = 0
    total_games = len(dataset) * len(models) * len(models)
    
    # æ‰§è¡Œæ‰€æœ‰æ¸¸æˆ
    for word_data in dataset:
        target_word = word_data['target']
        taboo_words = word_data['taboo']
        
        for hinter_model in models:
            for guesser_model in models:
                game_counter += 1
                print(f"ğŸ® æ¸¸æˆ {game_counter}/{total_games}: "
                      f"{target_word} | "
                      f"{hinter_model.split('/')[-1]}â†’{guesser_model.split('/')[-1]}")
                
                # æ‰§è¡Œæ¸¸æˆ
                start_time = time.time()
                game_result = chinese_taboo_game(
                    client, hinter_model, guesser_model,
                    target_word, taboo_words, max_turns
                )
                duration = time.time() - start_time
                
                # è®°å½•ç»“æœ
                result = {
                    'game_id': game_counter,
                    'target_word': target_word,
                    'part_of_speech': word_data['part_of_speech'],
                    'hinter_model': hinter_model,
                    'guesser_model': guesser_model,
                    'success': game_result['success'],
                    'turns_used': game_result['turns'],
                    'final_guess': game_result.get('final_guess', ''),
                    'failure_reason': game_result.get('failure_reason', ''),
                    'duration_seconds': round(duration, 2),
                    'taboo_words': '|'.join(taboo_words)
                }
                all_results.append(result)
                
                # æ˜¾ç¤ºç»“æœ
                status = "âœ… æˆåŠŸ" if game_result['success'] else "âŒ å¤±è´¥"
                print(f"   {status} | {game_result['turns']}è½® | "
                      f"{game_result.get('failure_reason', 'æ­£å¸¸ç»“æŸ')}")
    
    # ä¿å­˜ç»“æœ
    results_df = pd.DataFrame(all_results)
    output_file = f"{experiment_dir}/chinese_test_results_{timestamp}.csv"
    results_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    
    print(f"\nâœ… ä¸­æ–‡å®éªŒå®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³: {output_file}")
    return results_df
```

### æ¨¡å—8: ç»“æœåˆ†æ (Results Analysis)

```python
def analyze_chinese_experiment_results(results_df):
    """åˆ†æä¸­æ–‡å®éªŒç»“æœ"""
    print("ğŸ“Š ä¸­æ–‡Tabooå®éªŒç»“æœåˆ†æ")
    print("=" * 50)
    
    # æ•´ä½“æˆåŠŸç‡
    total_games = len(results_df)
    successful_games = sum(results_df['success'])
    overall_success_rate = successful_games / total_games * 100
    
    print(f"ğŸ® æ€»æ¸¸æˆæ•°: {total_games}")
    print(f"âœ… æˆåŠŸæ¸¸æˆ: {successful_games}")
    print(f"ğŸ“ˆ æ•´ä½“æˆåŠŸç‡: {overall_success_rate:.1f}%")
    
    # æŒ‰æ¨¡å‹åˆ†æ
    print(f"\nğŸ¤– æ¨¡å‹è¡¨ç°åˆ†æ:")
    for model in results_df['hinter_model'].unique():
        model_name = model.split('/')[-1]
        
        # ä½œä¸ºHinterçš„è¡¨ç°
        hinter_results = results_df[results_df['hinter_model'] == model]
        hinter_success = sum(hinter_results['success'])
        hinter_total = len(hinter_results)
        hinter_rate = hinter_success / hinter_total * 100 if hinter_total > 0 else 0
        
        # ä½œä¸ºGuesserçš„è¡¨ç°
        guesser_results = results_df[results_df['guesser_model'] == model]
        guesser_success = sum(guesser_results['success'])
        guesser_total = len(guesser_results)
        guesser_rate = guesser_success / guesser_total * 100 if guesser_total > 0 else 0
        
        print(f"   {model_name}:")
        print(f"     ä½œä¸ºçº¿ç´¢ç»™å‡ºè€…: {hinter_success}/{hinter_total} ({hinter_rate:.1f}%)")
        print(f"     ä½œä¸ºçŒœæµ‹è€…: {guesser_success}/{guesser_total} ({guesser_rate:.1f}%)")
    
    # æŒ‰è¯æ€§åˆ†æ
    print(f"\nğŸ“ è¯æ€§è¡¨ç°åˆ†æ:")
    for pos in results_df['part_of_speech'].unique():
        pos_results = results_df[results_df['part_of_speech'] == pos]
        pos_success = sum(pos_results['success'])
        pos_total = len(pos_results)
        pos_rate = pos_success / pos_total * 100 if pos_total > 0 else 0
        
        print(f"   {pos}: {pos_success}/{pos_total} ({pos_rate:.1f}%)")
    
    # å¤±è´¥åŸå› åˆ†æ
    print(f"\nâŒ å¤±è´¥åŸå› åˆ†æ:")
    failed_results = results_df[results_df['success'] == False]
    failure_reasons = failed_results['failure_reason'].value_counts()
    
    for reason, count in failure_reasons.items():
        percentage = count / len(failed_results) * 100
        print(f"   {reason}: {count} æ¬¡ ({percentage:.1f}%)")
    
    return {
        'overall_success_rate': overall_success_rate,
        'total_games': total_games,
        'successful_games': successful_games
    }
```

## ğŸš€ å®éªŒæ‰§è¡Œæµç¨‹

### é˜¶æ®µ1: ç¯å¢ƒå‡†å¤‡
```python
# 1. å®‰è£…ä¾èµ–
pip install OpenHowNet jieba requests pandas numpy

# 2. é…ç½®APIå¯†é’¥
# ç¡®ä¿api_keys.jsonåŒ…å«OpenRouter APIå¯†é’¥

# 3. åˆå§‹åŒ–ç¯å¢ƒ
exec_cell_1()  # å¯¼å…¥ä¾èµ–å’Œé…ç½®
```

### é˜¶æ®µ2: æ•°æ®é›†æ„å»º
```python
# 4. åˆå§‹åŒ–OpenHowNet
hownet_dict = initialize_hownet()

# 5. æ„å»ºä¸­æ–‡æ•°æ®é›†
chinese_dataset = build_chinese_dataset(hownet_dict)

# 6. æ•°æ®é›†åˆ†æ
analyze_chinese_dataset(chinese_dataset)

# 7. ä¿å­˜æ•°æ®é›†
save_chinese_dataset(chinese_dataset)
```

### é˜¶æ®µ3: å®éªŒæ‰§è¡Œ
```python
# 8. åˆå§‹åŒ–APIå®¢æˆ·ç«¯
chinese_client = ChineseAPIClient(api_keys["OPENROUTER_API_KEY"])

# 9. æµ‹è¯•å®éªŒï¼ˆå°è§„æ¨¡éªŒè¯ï¼‰
test_config = {
    'experiment_type': 'test',
    'max_turns': 5,
    'output_dir': 'results'
}
test_results = run_chinese_taboo_experiment(
    chinese_client, CHINESE_MODELS[:2], chinese_dataset[:5], test_config
)

# 10. å…¨é‡å®éªŒ
full_config = {
    'experiment_type': 'full',
    'max_turns': 5,
    'output_dir': 'results'
}
full_results = run_chinese_taboo_experiment(
    chinese_client, CHINESE_MODELS, chinese_dataset, full_config
)
```

### é˜¶æ®µ4: ç»“æœåˆ†æ
```python
# 11. ç»“æœåˆ†æ
analysis = analyze_chinese_experiment_results(full_results)

# 12. ç”ŸæˆæŠ¥å‘Š
generate_chinese_experiment_report(full_results, analysis)
```

## ğŸ“ˆ é¢„æœŸç»“æœ

### æ•°æ®é›†æŒ‡æ ‡
- **è¯æ±‡æ€»æ•°**: 100ä¸ªä¸­æ–‡è¯æ±‡
- **è¯æ€§åˆ†å¸ƒ**: åè¯ã€åŠ¨è¯ã€å½¢å®¹è¯ã€å‰¯è¯å„25ä¸ª
- **ç¦ç”¨è¯**: æ¯ä¸ªè¯æ±‡5ä¸ªè¯­ä¹‰ç›¸å…³ç¦ç”¨è¯
- **è¯­ä¹‰è¦†ç›–**: åŸºäºOpenHowNetçš„ä¸°å¯Œè¯­ä¹‰ä¿¡æ¯

### å®éªŒè§„æ¨¡
- **æ¨¡å‹æ•°é‡**: 4ä¸ªä¸»æµä¸­æ–‡LLM
- **æ¸¸æˆæ€»æ•°**: 100è¯æ±‡ Ã— 4æ¨¡å‹ Ã— 4æ¨¡å‹ = 1,600åœºæ¸¸æˆ
- **é¢„è®¡æ—¶é•¿**: çº¦2-3å°æ—¶ï¼ˆå–å†³äºAPIå“åº”é€Ÿåº¦ï¼‰

### è¯„ä¼°ç»´åº¦
1. **æ•´ä½“æˆåŠŸç‡**: å„æ¨¡å‹åœ¨ä¸­æ–‡çº¦æŸæ²Ÿé€šä¸­çš„è¡¨ç°
2. **è§’è‰²è¡¨ç°**: ä½œä¸ºçº¿ç´¢ç»™å‡ºè€…vsçŒœæµ‹è€…çš„èƒ½åŠ›å·®å¼‚
3. **è¯æ€§å½±å“**: ä¸åŒè¯æ€§å¯¹æ¸¸æˆéš¾åº¦çš„å½±å“
4. **è¯­è¨€ç‰¹æ€§**: ä¸­æ–‡è¯­è¨€ç‰¹ç‚¹å¯¹LLMè¡¨ç°çš„å½±å“

## ğŸ’¡ æŠ€æœ¯äº®ç‚¹

1. **é¦–åˆ›æ€§**: é¦–æ¬¡å°†OpenHowNetåº”ç”¨äºLLMè¯„ä¼°
2. **ä¸­æ–‡ç‰¹åŒ–**: ä¸“é—¨é’ˆå¯¹ä¸­æ–‡è¯­è¨€ç‰¹ç‚¹ä¼˜åŒ–
3. **ç§‘å­¦æ€§**: ç»§æ‰¿base_testæˆç†Ÿæ¡†æ¶ï¼Œç¡®ä¿å®éªŒå¯é æ€§
4. **å®Œæ•´æ€§**: ä»æ•°æ®é›†æ„å»ºåˆ°ç»“æœåˆ†æçš„å…¨æµç¨‹ç³»ç»Ÿ

## ğŸ“ è¾“å‡ºæ–‡ä»¶

- `data/chinese_dataset.json` - å®Œæ•´ä¸­æ–‡æ•°æ®é›†
- `data/chinese_dataset_simple.json` - ç®€åŒ–ç‰ˆæ•°æ®é›†  
- `results/chinese_experiment_YYYYMMDD_HHMMSS/` - å®éªŒç»“æœç›®å½•
- `chinese_experiment_report.json` - å®éªŒåˆ†ææŠ¥å‘Š

---

> è¿™ä¸ªæ¡†æ¶å®Œå…¨åŸºäºbase_test.ipynbçš„æˆç†Ÿæ¶æ„ï¼Œä½†ä¸“é—¨é’ˆå¯¹ä¸­æ–‡è¯­è¨€å’ŒOpenHowNetè¿›è¡Œäº†ä¼˜åŒ–ï¼Œç¡®ä¿äº†å®éªŒçš„ç§‘å­¦æ€§å’Œä¸­æ–‡è¯­è¨€çš„ç‰¹æ®Šæ€§éƒ½å¾—åˆ°äº†å……åˆ†è€ƒè™‘ã€‚ 