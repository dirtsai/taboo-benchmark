{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 1. å¯¼å…¥ä¾èµ–å’Œæ•°æ®åº“\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SciencePlots in /opt/homebrew/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: matplotlib in /opt/homebrew/lib/python3.11/site-packages (from SciencePlots) (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->SciencePlots) (1.17.0)\n",
      "Requirement already satisfied: SciencePlots in /opt/homebrew/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: matplotlib in /opt/homebrew/lib/python3.11/site-packages (from SciencePlots) (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->SciencePlots) (1.17.0)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "'science' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/matplotlib/style/core.py:129\u001b[39m, in \u001b[36muse\u001b[39m\u001b[34m(style)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     style = \u001b[43m_rc_params_in_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/matplotlib/__init__.py:903\u001b[39m, in \u001b[36m_rc_params_in_file\u001b[39m\u001b[34m(fname, transform, fail_on_error)\u001b[39m\n\u001b[32m    902\u001b[39m rc_temp = {}\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_open_file_or_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfd\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.gen)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/matplotlib/__init__.py:880\u001b[39m, in \u001b[36m_open_file_or_url\u001b[39m\u001b[34m(fname)\u001b[39m\n\u001b[32m    879\u001b[39m fname = os.path.expanduser(fname)\n\u001b[32m--> \u001b[39m\u001b[32m880\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fname, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    881\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'science'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# ç”¨æ³•ç¤ºä¾‹\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m.\u001b[49m\u001b[43muse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mscience\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mno-latex\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      9\u001b[39m plt.style.use([\u001b[33m'\u001b[39m\u001b[33mscience\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mgrid\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/matplotlib/style/core.py:131\u001b[39m, in \u001b[36muse\u001b[39m\u001b[34m(style)\u001b[39m\n\u001b[32m    129\u001b[39m         style = _rc_params_in_file(style)\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    132\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstyle\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m is not a valid package style, path of style \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    133\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfile, URL of style file, or library style name (library \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    134\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mstyles are listed in `style.available`)\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    135\u001b[39m filtered = {}\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m style:  \u001b[38;5;66;03m# don't trigger RcParams.__getitem__('backend')\u001b[39;00m\n",
      "\u001b[31mOSError\u001b[39m: 'science' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)"
     ]
    }
   ],
   "source": [
    "!pip install SciencePlots\n",
    "!pip3 install SciencePlots\n",
    "\n",
    "# ç”¨æ³•ç¤ºä¾‹\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(['science', 'no-latex'])\n",
    "import numpy as np\n",
    "\n",
    "plt.style.use(['science', 'grid'])\n",
    "\n",
    "x = np.linspace(0, 10, 100)\n",
    "y1 = np.sin(x)\n",
    "y2 = np.cos(x)\n",
    "\n",
    "plt.plot(x, y1, label='sin(x)')\n",
    "plt.plot(x, y2, label='cos(x)')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.title('A beautiful scientific plot')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š æ­£åœ¨åŠ è½½æ•°æ®é›†...\n",
      "âœ… æ•°æ®é›†åŠ è½½å®Œæˆï¼Œå…±300æ¡è®°å½•\n",
      "\n",
      "ğŸ“‹ æ•°æ®é›†æ ·æœ¬:\n",
      "   ç›®æ ‡è¯: recovery\n",
      "   ç±»åˆ«: chemistry\n",
      "   ç¦ç”¨è¯: ['forest', 'return', 'advance', 'rapid', 'state']\n",
      "   è¯ä¹‰æ•°: 3\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "from typing import Dict, List, Any\n",
    "from datetime import datetime\n",
    "\n",
    "# åŠ è½½æ•°æ®é›†\n",
    "def load_dataset(dataset_path: str = \"data/dataset.json\") -> List[Dict]:\n",
    "    \"\"\"åŠ è½½Tabooæ•°æ®é›†\"\"\"\n",
    "    with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# åŠ è½½æ•°æ®é›†\n",
    "print(\"ğŸ“š æ­£åœ¨åŠ è½½æ•°æ®é›†...\")\n",
    "dataset = load_dataset()\n",
    "print(f\"âœ… æ•°æ®é›†åŠ è½½å®Œæˆï¼Œå…±{len(dataset)}æ¡è®°å½•\")\n",
    "\n",
    "# æ˜¾ç¤ºæ•°æ®é›†æ ·æœ¬\n",
    "print(\"\\nğŸ“‹ æ•°æ®é›†æ ·æœ¬:\")\n",
    "sample = random.choice(dataset)\n",
    "print(f\"   ç›®æ ‡è¯: {sample['target']}\")\n",
    "print(f\"   ç±»åˆ«: {sample.get('category', 'unknown')}\")\n",
    "print(f\"   ç¦ç”¨è¯: {sample['taboo']}\")\n",
    "print(f\"   è¯ä¹‰æ•°: {len(sample.get('senses', []))}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 2. æ•°æ®é›†ç»Ÿè®¡åˆ†æ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š æ•°æ®é›†åŸºæœ¬ç»Ÿè®¡:\n",
      "========================================\n",
      "\n",
      "ğŸ·ï¸ ç±»åˆ«åˆ†å¸ƒ (Top 5):\n",
      "   1. general: 100 æ¡ (33.3%)\n",
      "   2. chemistry: 50 æ¡ (16.7%)\n",
      "   3. cs: 50 æ¡ (16.7%)\n",
      "   4. finance: 50 æ¡ (16.7%)\n",
      "   5. philosophy: 50 æ¡ (16.7%)\n",
      "\n",
      "ğŸš« ç¦ç”¨è¯ç»Ÿè®¡:\n",
      "   å¹³å‡æ•°é‡: 5.0\n",
      "   èŒƒå›´: 5 - 5\n",
      "\n",
      "ğŸ’­ è¯ä¹‰ç»Ÿè®¡:\n",
      "   å¹³å‡æ•°é‡: 3.1\n",
      "   èŒƒå›´: 1 - 23\n",
      "\n",
      "âœ… æ•°æ®é›†ç»Ÿè®¡å®Œæˆï¼Œè´¨é‡è‰¯å¥½ï¼Œå¯ç”¨äºå®éªŒ\n",
      "\n",
      "ğŸ² éšæœºç§å­å·²è®¾ç½®ä¸º 240ï¼Œç¡®ä¿å®éªŒå¯å¤ç°\n"
     ]
    }
   ],
   "source": [
    "# æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯\n",
    "print(\"ğŸ“Š æ•°æ®é›†åŸºæœ¬ç»Ÿè®¡:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡\n",
    "categories = {}\n",
    "taboo_counts = []\n",
    "sense_counts = []\n",
    "\n",
    "for item in dataset:\n",
    "    # ç»Ÿè®¡ç±»åˆ«\n",
    "    category = item.get('category', 'unknown')\n",
    "    categories[category] = categories.get(category, 0) + 1\n",
    "    \n",
    "    # ç»Ÿè®¡ç¦ç”¨è¯æ•°é‡\n",
    "    taboo_counts.append(len(item.get('taboo', [])))\n",
    "    \n",
    "    # ç»Ÿè®¡è¯ä¹‰æ•°é‡\n",
    "    sense_counts.append(len(item.get('senses', [])))\n",
    "\n",
    "print(f\"\\nğŸ·ï¸ ç±»åˆ«åˆ†å¸ƒ (Top 5):\")\n",
    "sorted_categories = sorted(categories.items(), key=lambda x: x[1], reverse=True)\n",
    "for i, (category, count) in enumerate(sorted_categories[:5], 1):\n",
    "    percentage = count / len(dataset) * 100\n",
    "    print(f\"   {i}. {category}: {count} æ¡ ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nğŸš« ç¦ç”¨è¯ç»Ÿè®¡:\")\n",
    "print(f\"   å¹³å‡æ•°é‡: {sum(taboo_counts) / len(taboo_counts):.1f}\")\n",
    "print(f\"   èŒƒå›´: {min(taboo_counts)} - {max(taboo_counts)}\")\n",
    "\n",
    "print(f\"\\nğŸ’­ è¯ä¹‰ç»Ÿè®¡:\")\n",
    "print(f\"   å¹³å‡æ•°é‡: {sum(sense_counts) / len(sense_counts):.1f}\")\n",
    "print(f\"   èŒƒå›´: {min(sense_counts)} - {max(sense_counts)}\")\n",
    "\n",
    "print(f\"\\nâœ… æ•°æ®é›†ç»Ÿè®¡å®Œæˆï¼Œè´¨é‡è‰¯å¥½ï¼Œå¯ç”¨äºå®éªŒ\")\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­ç”¨äºå®éªŒ\n",
    "random.seed(240)\n",
    "print(\"\\nğŸ² éšæœºç§å­å·²è®¾ç½®ä¸º 240ï¼Œç¡®ä¿å®éªŒå¯å¤ç°\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 3. APIå®¢æˆ·ç«¯è®¾ç½®\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… APIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ\n",
      "ğŸ¤– å®éªŒæ¨¡å‹: 4 ä¸ª\n",
      "   1. openai/gpt-4o\n",
      "   2. google/gemini-2.5-pro\n",
      "   3. deepseek/deepseek-chat-v3-0324\n",
      "   4. anthropic/claude-sonnet-4\n"
     ]
    }
   ],
   "source": [
    "# è®¾ç½®APIå®¢æˆ·ç«¯\n",
    "def load_api_keys(keys_path: str = \"api_keys.json\") -> Dict[str, str]:\n",
    "    \"\"\"åŠ è½½APIå¯†é’¥\"\"\"\n",
    "    with open(keys_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "class OpenRouterClient:\n",
    "    \"\"\"OpenRouter APIå®¢æˆ·ç«¯\"\"\"\n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "        self.headers = {\n",
    "            \"Authorization\": f\"Bearer {api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "    \n",
    "    def call_model(self, model: str, messages: List[Dict[str, str]], temperature: float = 0.3) -> str:\n",
    "        \"\"\"è°ƒç”¨æ¨¡å‹API\"\"\"\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": temperature,\n",
    "            \"max_tokens\": 2000\n",
    "        }\n",
    "        response = requests.post(self.base_url, headers=self.headers, json=payload, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        content = result['choices'][0]['message']['content'].strip()\n",
    "        \n",
    "        # é˜²æ­¢ä¹±ç ï¼šåªä¿ç•™ASCIIå¯æ‰“å°å­—ç¬¦\n",
    "        import re\n",
    "        content = re.sub(r'[^\\x20-\\x7E]', '', content)\n",
    "        return content\n",
    "\n",
    "# åˆå§‹åŒ–APIå®¢æˆ·ç«¯\n",
    "try:\n",
    "    api_keys = load_api_keys()\n",
    "    client = OpenRouterClient(api_keys[\"OPENROUTER_API_KEY\"])\n",
    "    print(\"âœ… APIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ APIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}\")\n",
    "    client = None\n",
    "\n",
    "# å®šä¹‰æµ‹è¯•æ¨¡å‹\n",
    "TEST_MODELS = [\n",
    "    \"openai/gpt-4o\",\n",
    "    \"google/gemini-2.5-pro\", \n",
    "    \"deepseek/deepseek-chat-v3-0324\",\n",
    "    \"anthropic/claude-sonnet-4\"\n",
    "]\n",
    "\n",
    "print(f\"ğŸ¤– å®éªŒæ¨¡å‹: {len(TEST_MODELS)} ä¸ª\")\n",
    "for i, model in enumerate(TEST_MODELS, 1):\n",
    "    print(f\"   {i}. {model}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 4. é€šç”¨å®éªŒæ–¹æ³•\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ: 300 æ¡è®°å½•\n",
      "ğŸ“ æ•°æ®é›†è·¯å¾„: data/dataset.json\n",
      "\n",
      "ğŸ“‹ æ•°æ®æ ·æœ¬:\n",
      "   ç›®æ ‡è¯: crotonbug\n",
      "   ç¦ç”¨è¯: ['common', 'croton', 'europe', 'german', 'states']\n",
      "   ç±»åˆ«: general\n",
      "   å®šä¹‰: small light-brown cockroach brought to United States from Europe; a common household pest...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Any\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# åŠ è½½æ•°æ®é›†\n",
    "def load_dataset(dataset_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"åŠ è½½Tabooæ¸¸æˆæ•°æ®é›†\"\"\"\n",
    "    with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "        dataset = json.load(f)\n",
    "    return dataset\n",
    "\n",
    "# åŠ è½½é¢„ç”Ÿæˆçš„æ•°æ®é›†\n",
    "DATASET_PATH = \"data/dataset.json\"\n",
    "dataset = load_dataset(DATASET_PATH)\n",
    "print(f\"âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ: {len(dataset)} æ¡è®°å½•\")\n",
    "print(f\"ğŸ“ æ•°æ®é›†è·¯å¾„: {DATASET_PATH}\")\n",
    "\n",
    "# æ˜¾ç¤ºç¬¬ä¸€ä¸ªæ ·æœ¬\n",
    "if dataset:\n",
    "    sample = dataset[0]\n",
    "    print(f\"\\nğŸ“‹ æ•°æ®æ ·æœ¬:\")\n",
    "    print(f\"   ç›®æ ‡è¯: {sample['target']}\")\n",
    "    print(f\"   ç¦ç”¨è¯: {sample['taboo']}\")\n",
    "    print(f\"   ç±»åˆ«: {sample.get('category', 'N/A')}\")\n",
    "    if sample.get('senses'):\n",
    "        print(f\"   å®šä¹‰: {sample['senses'][0].get('definition', 'N/A')[:100]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ ¸å¿ƒå·¥å…·å‡½æ•°å·²å®šä¹‰\n"
     ]
    }
   ],
   "source": [
    "# é€šç”¨å®éªŒæ–¹æ³• - æ ¸å¿ƒå‡½æ•°\n",
    "\n",
    "def safe_text_cleanup(text: str, max_length: int = 200) -> str:\n",
    "    \"\"\"å®‰å…¨æ¸…ç†æ–‡æœ¬ï¼Œé˜²æ­¢ä¹±ç å’Œè¶…é•¿å†…å®¹\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    import re\n",
    "    cleaned = re.sub(r'[^\\x20-\\x7E\\n\\r\\t]', '', str(text))\n",
    "    if len(cleaned) > max_length:\n",
    "        cleaned = cleaned[:max_length] + \"...\"\n",
    "    return cleaned\n",
    "\n",
    "def robust_api_call(client, model: str, base_prompt: str, expected_prefix: str, max_retries: int = 3):\n",
    "    \"\"\"å¥å£®çš„APIè°ƒç”¨ï¼ŒåŒ…å«é‡è¯•æœºåˆ¶å’Œæ ¼å¼éªŒè¯\"\"\"\n",
    "    failed_outputs = []\n",
    "    \n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            if attempt == 1:\n",
    "                prompt = base_prompt\n",
    "            else:\n",
    "                prev_output = failed_outputs[-1] if failed_outputs else \"Unknown\"\n",
    "                format_reminder = f\"\"\"\n",
    "\n",
    "âš ï¸ FORMAT ERROR DETECTED âš ï¸\n",
    "Your previous response was: \"{prev_output}\"\n",
    "\n",
    "REQUIRED FORMAT:\n",
    "- You MUST start with exactly '{expected_prefix}' (including square brackets)\n",
    "- Do NOT add any text before {expected_prefix}\n",
    "\n",
    "Try again with the exact format:\"\"\"\n",
    "                prompt = base_prompt + format_reminder\n",
    "            \n",
    "            response = client.call_model(model, [{\"role\": \"user\", \"content\": prompt}])\n",
    "            \n",
    "            if response.strip().upper().startswith(expected_prefix.upper()):\n",
    "                return {\n",
    "                    'success': True,\n",
    "                    'response': response,\n",
    "                    'attempts': attempt,\n",
    "                    'error': None,\n",
    "                    'failed_outputs': failed_outputs\n",
    "                }\n",
    "            else:\n",
    "                safe_response = safe_text_cleanup(response, max_length=150)\n",
    "                failed_outputs.append(safe_response)\n",
    "                \n",
    "                if attempt == max_retries:\n",
    "                    all_failed = \" | \".join(failed_outputs)\n",
    "                    return {\n",
    "                        'success': False,\n",
    "                        'response': f\"FORMAT_ERROR_EXCEEDED: {safe_response}\",\n",
    "                        'attempts': attempt,\n",
    "                        'error': f\"Failed after {max_retries} attempts. Expected '{expected_prefix}'. All failed outputs: {all_failed}\",\n",
    "                        'failed_outputs': failed_outputs\n",
    "                    }\n",
    "                time.sleep(0.5)\n",
    "                \n",
    "        except Exception as e:\n",
    "            safe_error = safe_text_cleanup(str(e), max_length=150)\n",
    "            error_msg = f\"API error (attempt {attempt}/{max_retries}): {safe_error}\"\n",
    "            \n",
    "            if attempt == max_retries:\n",
    "                return {\n",
    "                    'success': False,\n",
    "                    'response': None,\n",
    "                    'attempts': attempt,\n",
    "                    'error': error_msg,\n",
    "                    'failed_outputs': failed_outputs\n",
    "                }\n",
    "            time.sleep(1.0)\n",
    "    \n",
    "    return {\n",
    "        'success': False,\n",
    "        'response': None,\n",
    "        'attempts': max_retries,\n",
    "        'error': \"Max retries exceeded\",\n",
    "        'failed_outputs': failed_outputs\n",
    "    }\n",
    "\n",
    "def extract_guess_word(response: str) -> str:\n",
    "    \"\"\"ä»å“åº”ä¸­æå–çŒœæµ‹è¯\"\"\"\n",
    "    if response.startswith(\"FORMAT_ERROR_EXCEEDED\"):\n",
    "        return \"FORMAT_ERROR\"\n",
    "    \n",
    "    if '[GUESS]' in response.upper():\n",
    "        import re\n",
    "        match = re.search(r'\\[GUESS\\]\\s*(.+)', response, re.IGNORECASE)\n",
    "        if match:\n",
    "            guess_part = match.group(1).strip()\n",
    "            guess = guess_part.split()[0] if guess_part.split() else \"\"\n",
    "            return guess.strip('.,!?;:\"\\'()[]{}')\n",
    "    \n",
    "    if 'Guess:' in response:\n",
    "        guess_part = response.split('Guess:')[1].strip()\n",
    "        guess = guess_part.split()[0] if guess_part.split() else \"\"\n",
    "        return guess.strip('.,!?;:\"\\'()[]{}')\n",
    "    \n",
    "    return \"INVALID_FORMAT\"\n",
    "\n",
    "def extract_clue_text(response: str) -> str:\n",
    "    \"\"\"ä»å“åº”ä¸­æå–çº¿ç´¢æ–‡æœ¬\"\"\"\n",
    "    if response.startswith(\"FORMAT_ERROR_EXCEEDED\"):\n",
    "        return \"FORMAT_ERROR\"\n",
    "    \n",
    "    if '[CLUE]' in response.upper():\n",
    "        import re\n",
    "        match = re.search(r'\\[CLUE\\]\\s*(.+)', response, re.IGNORECASE | re.DOTALL)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "    \n",
    "    if 'Clue:' in response:\n",
    "        return response.split('Clue:')[1].strip()\n",
    "    \n",
    "    return \"INVALID_FORMAT\"\n",
    "\n",
    "def check_taboo_violation(hint, taboo_words):\n",
    "    \"\"\"æ£€æŸ¥hinterçš„çº¿ç´¢æ˜¯å¦è¿åäº†ç¦ç”¨è¯è§„åˆ™\"\"\"\n",
    "    import re\n",
    "    hint_lower = hint.lower()\n",
    "    \n",
    "    for taboo in taboo_words:\n",
    "        taboo_lower = taboo.lower()\n",
    "        # æ£€æŸ¥å®Œæ•´å•è¯åŒ¹é…\n",
    "        if re.search(r'\\b' + re.escape(taboo_lower) + r'\\b', hint_lower):\n",
    "            return True\n",
    "        # æ£€æŸ¥éƒ¨åˆ†æ‹¼å†™ï¼ˆè‡³å°‘3ä¸ªå­—ç¬¦ï¼‰\n",
    "        if len(taboo_lower) >= 3 and taboo_lower in hint_lower:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "print(\"âœ… æ ¸å¿ƒå·¥å…·å‡½æ•°å·²å®šä¹‰\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å¢å¼ºç‰ˆæ¸¸æˆå‡½æ•°å·²å®šä¹‰ï¼ˆåŒ…å«ä¸¥æ ¼çš„taboo violationæ£€æŸ¥ï¼‰\n"
     ]
    }
   ],
   "source": [
    "# æ ¸å¿ƒæ¸¸æˆé€»è¾‘å’Œé€šç”¨å®éªŒè¿è¡Œå™¨\n",
    "\n",
    "def enhanced_play_taboo_game(client, hinter_model, guesser_model, target_word, taboo_words, max_turns=5):\n",
    "    \"\"\"å¢å¼ºç‰ˆTabooæ¸¸æˆï¼ŒåŒ…å«taboo violationæ£€æŸ¥\"\"\"\n",
    "    \n",
    "    conversation_history = []\n",
    "    taboo_list = ', '.join(taboo_words)\n",
    "    \n",
    "    # ç³»ç»Ÿæç¤º\n",
    "    hinter_system = f\"\"\"You are playing a Taboo word game as the Hinter.\n",
    "\n",
    "CRITICAL FORMAT REQUIREMENT:\n",
    "- You MUST start your response with exactly '[CLUE]' (including square brackets)\n",
    "- Do NOT add any text before [CLUE]\n",
    "- Example: [CLUE] This is a large mammal with a trunk\n",
    "\n",
    "GAME RULES:\n",
    "1. NEVER use any of these taboo words: {taboo_list}\n",
    "2. Give helpful clues to help the guesser find the target word\n",
    "3. You can see the conversation history and build on previous clues\n",
    "4. Be creative but follow the format exactly\n",
    "5. Use BRITISH ENGLISH spelling (e.g., colour not color, centre not center)\n",
    "\n",
    "Target word: {target_word}\n",
    "Taboo words (ABSOLUTELY FORBIDDEN): {taboo_list}\"\"\"\n",
    "\n",
    "    guesser_system = \"\"\"You are playing a Taboo word game as the Guesser.\n",
    "\n",
    "CRITICAL FORMAT REQUIREMENT:\n",
    "- You MUST start your response with exactly '[GUESS]' (including square brackets)\n",
    "- Do NOT add any text before [GUESS]\n",
    "- Example: [GUESS] elephant\n",
    "\n",
    "GAME RULES:\n",
    "1. Make your best guess based on all the clues you've received\n",
    "2. You can see the conversation history\n",
    "3. Give only ONE word as your guess after [GUESS]\n",
    "4. Use BRITISH ENGLISH spelling (e.g., colour not color, centre not center)\"\"\"\n",
    "\n",
    "    # è®°å½•ç»Ÿè®¡ä¿¡æ¯\n",
    "    total_hinter_attempts = 0\n",
    "    total_guesser_attempts = 0\n",
    "    format_errors = []\n",
    "    hinter_failed_outputs = []\n",
    "    guesser_failed_outputs = []\n",
    "\n",
    "    for turn in range(1, max_turns + 1):\n",
    "        # æ„å»ºHinteræç¤º\n",
    "        if turn == 1:\n",
    "            hinter_prompt = f\"{hinter_system}\\n\\nProvide your first clue:\"\n",
    "        else:\n",
    "            history_text = \"\\n\".join([f\"Turn {i}: {msg}\" for i, msg in enumerate(conversation_history, 1)])\n",
    "            hinter_prompt = f\"{hinter_system}\\n\\nConversation so far:\\n{history_text}\\n\\nThe guesser hasn't found the word yet. Provide your next clue:\"\n",
    "        \n",
    "        # Hinterç»™å‡ºçº¿ç´¢ï¼ˆå¸¦é‡è¯•ï¼‰\n",
    "        hinter_result = robust_api_call(client, hinter_model, hinter_prompt, \"[CLUE]\", max_retries=3)\n",
    "        total_hinter_attempts += hinter_result['attempts']\n",
    "        \n",
    "        if hinter_result.get('failed_outputs'):\n",
    "            hinter_failed_outputs.extend(hinter_result['failed_outputs'])\n",
    "        \n",
    "        if not hinter_result['success']:\n",
    "            error_type = \"FORMAT_FAILURE\" if \"FORMAT_ERROR_EXCEEDED\" in str(hinter_result.get('response', '')) else \"API_FAILURE\"\n",
    "            format_errors.append(f\"Turn {turn} Hinter: {hinter_result['error']}\")\n",
    "            \n",
    "            return {\n",
    "                'success': False,\n",
    "                'turns': turn,\n",
    "                'conversation': conversation_history,\n",
    "                'final_guess': f\"HINTER_{error_type}\",\n",
    "                'error': f\"{error_type}: {hinter_result['error']}\",\n",
    "                'failure_reason': error_type,\n",
    "                'total_hinter_attempts': total_hinter_attempts,\n",
    "                'total_guesser_attempts': total_guesser_attempts,\n",
    "                'format_errors': format_errors,\n",
    "                'hinter_failed_outputs': hinter_failed_outputs,\n",
    "                'guesser_failed_outputs': guesser_failed_outputs,\n",
    "                'all_hints': [msg for msg in conversation_history if msg.startswith('Hinter:')],\n",
    "                'all_guesses': [msg for msg in conversation_history if msg.startswith('Guesser:')]\n",
    "            }\n",
    "        \n",
    "        # æå–çº¿ç´¢å¹¶æ£€æŸ¥taboo violation\n",
    "        hint_text = extract_clue_text(hinter_result['response'])\n",
    "        \n",
    "        # ğŸš¨ å…³é”®ï¼šæ£€æŸ¥æ˜¯å¦è¿åtaboo wordsè§„åˆ™\n",
    "        taboo_violated = check_taboo_violation(hint_text, taboo_words)\n",
    "        if taboo_violated:\n",
    "            # è¿è§„ç«‹å³å¤±è´¥ï¼\n",
    "            return {\n",
    "                'success': False,\n",
    "                'turns': turn,\n",
    "                'conversation': conversation_history,\n",
    "                'final_guess': 'TABOO_VIOLATION: Hinterè¿åè§„åˆ™',\n",
    "                'error': f'TABOO_VIOLATION: Hinteråœ¨ç¬¬{turn}è½®è¿åè§„åˆ™ï¼Œè¯´äº†ç¦ç”¨è¯: {hint_text}',\n",
    "                'failure_reason': 'TABOO_VIOLATION',\n",
    "                'taboo_violation_turn': turn,\n",
    "                'taboo_violation_hint': hint_text,\n",
    "                'total_hinter_attempts': total_hinter_attempts,\n",
    "                'total_guesser_attempts': total_guesser_attempts,\n",
    "                'format_errors': format_errors,\n",
    "                'hinter_failed_outputs': hinter_failed_outputs,\n",
    "                'guesser_failed_outputs': guesser_failed_outputs,\n",
    "                'all_hints': [msg for msg in conversation_history if msg.startswith('Hinter:')],\n",
    "                'all_guesses': [msg for msg in conversation_history if msg.startswith('Guesser:')]\n",
    "            }\n",
    "        \n",
    "        conversation_history.append(f\"Hinter: {hinter_result['response']}\")\n",
    "        \n",
    "        # æ„å»ºGuesseræç¤º\n",
    "        history_text = \"\\n\".join([f\"Turn {i}: {msg}\" for i, msg in enumerate(conversation_history, 1)])\n",
    "        guesser_prompt = f\"{guesser_system}\\n\\nConversation so far:\\n{history_text}\\n\\nWhat is your guess?\"\n",
    "        \n",
    "        # Guesserè¿›è¡ŒçŒœæµ‹ï¼ˆå¸¦é‡è¯•ï¼‰\n",
    "        guesser_result = robust_api_call(client, guesser_model, guesser_prompt, \"[GUESS]\", max_retries=3)\n",
    "        total_guesser_attempts += guesser_result['attempts']\n",
    "        \n",
    "        if guesser_result.get('failed_outputs'):\n",
    "            guesser_failed_outputs.extend(guesser_result['failed_outputs'])\n",
    "        \n",
    "        if not guesser_result['success']:\n",
    "            error_type = \"FORMAT_FAILURE\" if \"FORMAT_ERROR_EXCEEDED\" in str(guesser_result.get('response', '')) else \"API_FAILURE\"\n",
    "            format_errors.append(f\"Turn {turn} Guesser: {guesser_result['error']}\")\n",
    "            \n",
    "            return {\n",
    "                'success': False,\n",
    "                'turns': turn,\n",
    "                'conversation': conversation_history,\n",
    "                'final_guess': f\"GUESSER_{error_type}\",\n",
    "                'error': f\"{error_type}: {guesser_result['error']}\",\n",
    "                'failure_reason': error_type,\n",
    "                'total_hinter_attempts': total_hinter_attempts,\n",
    "                'total_guesser_attempts': total_guesser_attempts,\n",
    "                'format_errors': format_errors,\n",
    "                'hinter_failed_outputs': hinter_failed_outputs,\n",
    "                'guesser_failed_outputs': guesser_failed_outputs,\n",
    "                'all_hints': [msg for msg in conversation_history if msg.startswith('Hinter:')],\n",
    "                'all_guesses': [msg for msg in conversation_history if msg.startswith('Guesser:')]\n",
    "            }\n",
    "        \n",
    "        conversation_history.append(f\"Guesser: {guesser_result['response']}\")\n",
    "        guess = extract_guess_word(guesser_result['response'])\n",
    "        \n",
    "        # æ£€æŸ¥æ˜¯å¦æˆåŠŸ\n",
    "        if guess.lower() == target_word.lower():\n",
    "            return {\n",
    "                'success': True,\n",
    "                'turns': turn,\n",
    "                'conversation': conversation_history,\n",
    "                'final_guess': guess,\n",
    "                'failure_reason': None,\n",
    "                'total_hinter_attempts': total_hinter_attempts,\n",
    "                'total_guesser_attempts': total_guesser_attempts,\n",
    "                'format_errors': format_errors,\n",
    "                'hinter_failed_outputs': hinter_failed_outputs,\n",
    "                'guesser_failed_outputs': guesser_failed_outputs,\n",
    "                'all_hints': [msg for msg in conversation_history if msg.startswith('Hinter:')],\n",
    "                'all_guesses': [msg for msg in conversation_history if msg.startswith('Guesser:')]\n",
    "            }\n",
    "        \n",
    "        # å¦‚æœä¸æ˜¯æœ€åä¸€è½®ï¼Œæ·»åŠ åé¦ˆ\n",
    "        if turn < max_turns:\n",
    "            conversation_history.append(f\"System: '{guess}' is not correct. Try again!\")\n",
    "    \n",
    "    # è¾¾åˆ°æœ€å¤§è½®æ•°ä»æœªæˆåŠŸ\n",
    "    return {\n",
    "        'success': False,\n",
    "        'turns': max_turns,\n",
    "        'conversation': conversation_history,\n",
    "        'final_guess': guess if 'guess' in locals() else 'N/A',\n",
    "        'failure_reason': 'MAX_TURNS_EXCEEDED',\n",
    "        'total_hinter_attempts': total_hinter_attempts,\n",
    "        'total_guesser_attempts': total_guesser_attempts,\n",
    "        'format_errors': format_errors,\n",
    "        'hinter_failed_outputs': hinter_failed_outputs,\n",
    "        'guesser_failed_outputs': guesser_failed_outputs,\n",
    "        'all_hints': [msg for msg in conversation_history if msg.startswith('Hinter:')],\n",
    "        'all_guesses': [msg for msg in conversation_history if msg.startswith('Guesser:')]\n",
    "    }\n",
    "\n",
    "print(\"âœ… å¢å¼ºç‰ˆæ¸¸æˆå‡½æ•°å·²å®šä¹‰ï¼ˆåŒ…å«ä¸¥æ ¼çš„taboo violationæ£€æŸ¥ï¼‰\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ç»Ÿä¸€å®éªŒè¿è¡Œå™¨å·²å®šä¹‰\n"
     ]
    }
   ],
   "source": [
    "# ç»Ÿä¸€çš„Tabooå®éªŒè¿è¡Œå™¨\n",
    "def run_taboo_experiment(client, models, dataset, config):\n",
    "    \"\"\"ç»Ÿä¸€çš„Tabooå®éªŒè¿è¡Œå™¨ï¼Œæ”¯æŒæµ‹è¯•å’Œå…¨é‡æ¨¡å¼\"\"\"\n",
    "    \n",
    "    # é…ç½®å‚æ•°\n",
    "    experiment_type = config.get('experiment_type', 'test')\n",
    "    experiment_mode = config.get('experiment_mode', 'simple')  # 'simple' æˆ– 'grouped_by_hinter'\n",
    "    max_turns = config.get('max_turns', 5)\n",
    "    output_dir = config.get('output_dir', 'results')\n",
    "    fixed_word = config.get('fixed_word', None)\n",
    "    \n",
    "    # åˆ›å»ºè¾“å‡ºç›®å½•\n",
    "    from datetime import datetime\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    if experiment_mode == 'grouped_by_hinter':\n",
    "        return run_grouped_experiment(client, models, dataset, config, timestamp)\n",
    "    else:\n",
    "        return run_simple_experiment(client, models, dataset, config, timestamp)\n",
    "\n",
    "def run_simple_experiment(client, models, dataset, config, timestamp):\n",
    "    \"\"\"ç®€å•æ¨¡å¼ï¼šæµ‹è¯•å®éªŒï¼Œä½¿ç”¨å›ºå®šè¯æ±‡\"\"\"\n",
    "    experiment_type = config.get('experiment_type', 'test')\n",
    "    output_dir = config.get('output_dir', 'results')\n",
    "    fixed_word = config.get('fixed_word', None)\n",
    "    max_turns = config.get('max_turns', 5)\n",
    "    \n",
    "    # è¾“å‡ºè®¾ç½®\n",
    "    output_path = f\"{output_dir}/test_results_{timestamp}.csv\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"ğŸš€ å¼€å§‹æ‰§è¡Œ{experiment_type}å®éªŒ...\")\n",
    "    print(f\"ğŸ“ è¾“å‡ºè·¯å¾„: {output_path}\")\n",
    "    \n",
    "    # ä½¿ç”¨å›ºå®šè¯æ±‡\n",
    "    if not fixed_word:\n",
    "        fixed_word = random.choice(dataset)\n",
    "    \n",
    "    target_word = fixed_word['target']\n",
    "    taboo_words = fixed_word['taboo']\n",
    "    print(f\"ğŸ¯ æµ‹è¯•è¯: {target_word}\")\n",
    "    print(f\"ğŸš« ç¦ç”¨è¯: {taboo_words}\")\n",
    "    \n",
    "    total_games = len(models) ** 2  # æ¯ä¸ªæ¨¡å‹å¯¹ç»„åˆ1åœºæ¸¸æˆ\n",
    "    print(f\"ğŸ“Š æ€»æ¸¸æˆæ•°: {total_games}\")\n",
    "    \n",
    "    all_results = []\n",
    "    game_counter = 0\n",
    "    \n",
    "    # è¿è¡Œæ‰€æœ‰æ¨¡å‹ç»„åˆ\n",
    "    for hinter_model in models:\n",
    "        for guesser_model in models:\n",
    "            game_counter += 1\n",
    "            pair_name = f\"{hinter_model.split('/')[-1]}â†’{guesser_model.split('/')[-1]}\"\n",
    "            \n",
    "            print(f\"ğŸ”„ æ¸¸æˆ {game_counter}/{total_games} ({game_counter/total_games*100:.1f}%): {pair_name}\")\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            # æ‰§è¡Œæ¸¸æˆ\n",
    "            game_result = enhanced_play_taboo_game(client, hinter_model, guesser_model, \n",
    "                                                 target_word, taboo_words, max_turns)\n",
    "            \n",
    "            duration = round(time.time() - start_time, 2)\n",
    "            \n",
    "            # è®°å½•ç»“æœ\n",
    "            result = {\n",
    "                'game_id': game_counter,\n",
    "                'hinter_model': hinter_model,\n",
    "                'guesser_model': guesser_model,\n",
    "                'target_word': target_word,\n",
    "                'category': fixed_word.get('category', 'unknown'),\n",
    "                'taboo_words': '|'.join(taboo_words),\n",
    "                'success': game_result['success'],\n",
    "                'turns_used': game_result['turns'],\n",
    "                'final_guess': game_result['final_guess'],\n",
    "                'failure_reason': game_result.get('failure_reason', None),\n",
    "                'taboo_violation_turn': game_result.get('taboo_violation_turn', None),\n",
    "                'taboo_violation_hint': game_result.get('taboo_violation_hint', None),\n",
    "                'has_taboo_violation': game_result.get('failure_reason') == 'TABOO_VIOLATION',\n",
    "                'all_hints': ' | '.join(game_result['all_hints']),\n",
    "                'all_guesses': ' | '.join(game_result['all_guesses']),\n",
    "                'conversation': ' | '.join(game_result['conversation']),\n",
    "                'total_api_attempts': game_result.get('total_hinter_attempts', 0) + game_result.get('total_guesser_attempts', 0),\n",
    "                'format_errors': ' | '.join(game_result.get('format_errors', [])),\n",
    "                'has_format_errors': len(game_result.get('format_errors', [])) > 0,\n",
    "                'duration_seconds': duration,\n",
    "                'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "            \n",
    "            if 'error' in game_result:\n",
    "                result['error'] = game_result['error']\n",
    "            \n",
    "            all_results.append(result)\n",
    "            \n",
    "            # æ˜¾ç¤ºç»“æœ\n",
    "            status = \"âœ… æˆåŠŸ\" if game_result['success'] else \"âŒ å¤±è´¥\"\n",
    "            failure_info = \"\"\n",
    "            if not game_result['success'] and game_result.get('failure_reason'):\n",
    "                failure_reason = game_result['failure_reason']\n",
    "                if failure_reason == 'TABOO_VIOLATION':\n",
    "                    failure_info = \" (è¿åç¦ç”¨è¯è§„åˆ™)\"\n",
    "                elif failure_reason == 'FORMAT_FAILURE':\n",
    "                    failure_info = \" (æ ¼å¼é”™è¯¯è¶…3æ¬¡)\"\n",
    "                elif failure_reason == 'API_FAILURE':\n",
    "                    failure_info = \" (APIè°ƒç”¨å¤±è´¥)\"\n",
    "                elif failure_reason == 'MAX_TURNS_EXCEEDED':\n",
    "                    failure_info = \" (è¾¾åˆ°æœ€å¤§è½®æ•°)\"\n",
    "            \n",
    "            print(f\"   {status}{failure_info} | {game_result['turns']}è½® | æœ€ç»ˆçŒœæµ‹: {game_result['final_guess']}\")\n",
    "            time.sleep(0.5)\n",
    "    \n",
    "    return save_and_analyze_results(all_results, output_path, experiment_type)\n",
    "\n",
    "print(\"âœ… ç»Ÿä¸€å®éªŒè¿è¡Œå™¨å·²å®šä¹‰\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ”¯æŒå‡½æ•°å·²å®šä¹‰\n"
     ]
    }
   ],
   "source": [
    "# æ”¯æŒå‡½æ•° - å…¨é‡å®éªŒå’Œç»“æœåˆ†æ\n",
    "def run_grouped_experiment(client, models, dataset, config, timestamp):\n",
    "    \"\"\"åˆ†ç»„æ¨¡å¼ï¼šå…¨é‡å®éªŒï¼ŒæŒ‰hinteræ¨¡å‹åˆ†ç»„ï¼Œéå†æ‰€æœ‰è¯æ±‡ï¼Œæ¯50ä¸ªæ¸¸æˆä¿å­˜ä¸€ä¸ªæ‰¹æ¬¡æ–‡ä»¶\"\"\"\n",
    "    experiment_type = config.get('experiment_type', 'formal')\n",
    "    output_dir = config.get('output_dir', 'results')\n",
    "    max_turns = config.get('max_turns', 5)\n",
    "    batch_size = config.get('batch_size', 50)  # æ¯æ‰¹æ¬¡ä¿å­˜çš„æ¸¸æˆæ•°\n",
    "    \n",
    "    main_exp_dir = f\"{output_dir}/taboo_experiment_zengliang28_20250717_130855\"\n",
    "    os.makedirs(main_exp_dir, exist_ok=True)\n",
    "    print(f\"ğŸ“ ä¸»å®éªŒç›®å½•: {main_exp_dir}\")\n",
    "    \n",
    "    # å…¨é‡å®éªŒé…ç½®ï¼šæ¯ä¸ªæ¨¡å‹å¯¹éå†æ‰€æœ‰300ä¸ªè¯\n",
    "    print(f\"ğŸ“Š æ•°æ®é›†è¯æ±‡æ•°: {len(dataset)}\")\n",
    "    print(f\"ğŸ¤– æ¨¡å‹ç»„åˆæ•°: {len(models)}Ã—{len(models)} = {len(models)**2}\")\n",
    "    print(f\"ğŸ® æ€»æ¸¸æˆæ•°: {len(dataset) * len(models)**2:,}\")\n",
    "    print(f\"ğŸ’¾ æ‰¹æ¬¡å¤§å°: æ¯{batch_size}ä¸ªæ¸¸æˆä¿å­˜ä¸€ä¸ªæ–‡ä»¶\")\n",
    "    \n",
    "    all_experiment_results = []\n",
    "    batch_files = []  # è®°å½•æ‰€æœ‰æ‰¹æ¬¡æ–‡ä»¶è·¯å¾„\n",
    "    \n",
    "    # æŒ‰hinteræ¨¡å‹åˆ†ç»„æ‰§è¡Œ\n",
    "    for i, hinter_model in enumerate(models, 1):\n",
    "        hinter_name = hinter_model.split('/')[-1]\n",
    "        print(f\"\\\\nğŸ¯ ç¬¬{i}/{len(models)}ç»„: Hinter = {hinter_name}\")\n",
    "        \n",
    "        # ä¸ºæ¯ä¸ªhinteræ¨¡å‹åˆ›å»ºå­ç›®å½•\n",
    "        hinter_dir = f\"{main_exp_dir}/{hinter_name}_as_hinter\"\n",
    "        os.makedirs(hinter_dir, exist_ok=True)\n",
    "        \n",
    "        # è¿è¡Œå½“å‰hinteræ¨¡å‹ä¸æ‰€æœ‰guesseræ¨¡å‹çš„ç»„åˆ\n",
    "        hinter_results = []\n",
    "        current_batch = []\n",
    "        total_games_for_hinter = len(models) * len(dataset)\n",
    "        game_counter = 0\n",
    "        batch_counter = 0\n",
    "        \n",
    "        for guesser_model in models:\n",
    "            guesser_name = guesser_model.split('/')[-1]\n",
    "            pair_name = f\"{hinter_name}â†’{guesser_name}\"\n",
    "            \n",
    "            print(f\"   ğŸ”„ è¿è¡Œç»„åˆ: {pair_name}\")\n",
    "            \n",
    "            # éå†æ‰€æœ‰è¯æ±‡\n",
    "            for word_idx, word_data in enumerate(dataset):\n",
    "                game_counter += 1\n",
    "                \n",
    "                target_word = word_data['target']\n",
    "                taboo_words = word_data['taboo']\n",
    "                \n",
    "                start_time = time.time()\n",
    "                \n",
    "                # æ‰§è¡Œæ¸¸æˆ\n",
    "                game_result = enhanced_play_taboo_game(client, hinter_model, guesser_model, \n",
    "                                                     target_word, taboo_words, max_turns)\n",
    "                \n",
    "                duration = round(time.time() - start_time, 2)\n",
    "                \n",
    "                # è®°å½•ç»“æœ\n",
    "                result = {\n",
    "                    'game_id': f\"{hinter_name}_{game_counter}\",\n",
    "                    'word_index': word_idx,\n",
    "                    'hinter_model': hinter_model,\n",
    "                    'guesser_model': guesser_model,\n",
    "                    'target_word': target_word,\n",
    "                    'category': word_data.get('category', 'unknown'),\n",
    "                    'taboo_words': '|'.join(taboo_words),\n",
    "                    'success': game_result['success'],\n",
    "                    'turns_used': game_result['turns'],\n",
    "                    'final_guess': game_result['final_guess'],\n",
    "                    'failure_reason': game_result.get('failure_reason', None),\n",
    "                    'taboo_violation_turn': game_result.get('taboo_violation_turn', None),\n",
    "                    'taboo_violation_hint': game_result.get('taboo_violation_hint', None),\n",
    "                    'has_taboo_violation': game_result.get('failure_reason') == 'TABOO_VIOLATION',\n",
    "                    'all_hints': ' | '.join(game_result['all_hints']),\n",
    "                    'all_guesses': ' | '.join(game_result['all_guesses']),\n",
    "                    'conversation': ' | '.join(game_result['conversation']),\n",
    "                    'total_api_attempts': game_result.get('total_hinter_attempts', 0) + game_result.get('total_guesser_attempts', 0),\n",
    "                    'format_errors': ' | '.join(game_result.get('format_errors', [])),\n",
    "                    'has_format_errors': len(game_result.get('format_errors', [])) > 0,\n",
    "                    'duration_seconds': duration,\n",
    "                    'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                }\n",
    "                \n",
    "                if 'error' in game_result:\n",
    "                    result['error'] = game_result['error']\n",
    "                \n",
    "                hinter_results.append(result)\n",
    "                current_batch.append(result)\n",
    "                all_experiment_results.append(result)\n",
    "                \n",
    "                # æ¯batch_sizeä¸ªæ¸¸æˆä¿å­˜ä¸€ä¸ªæ‰¹æ¬¡æ–‡ä»¶\n",
    "                if len(current_batch) >= batch_size:\n",
    "                    batch_counter += 1\n",
    "                    batch_file_path = f\"{hinter_dir}/batch_{batch_counter:03d}.csv\"\n",
    "                    batch_df = pd.DataFrame(current_batch)\n",
    "                    batch_df.to_csv(batch_file_path, index=False, encoding='utf-8')\n",
    "                    batch_files.append(batch_file_path)\n",
    "                    \n",
    "                    # è¿›åº¦æ˜¾ç¤º\n",
    "                    progress = (game_counter / total_games_for_hinter) * 100\n",
    "                    success_in_batch = sum(r['success'] for r in current_batch)\n",
    "                    batch_success_rate = success_in_batch / len(current_batch) * 100\n",
    "                    \n",
    "                    print(f\"      ğŸ’¾ æ‰¹æ¬¡{batch_counter:03d}: {len(current_batch)}åœºæ¸¸æˆå·²ä¿å­˜\")\n",
    "                    print(f\"      ğŸ“ˆ è¿›åº¦: {game_counter}/{total_games_for_hinter} ({progress:.1f}%)\")\n",
    "                    print(f\"      ğŸ“Š æ‰¹æ¬¡æˆåŠŸç‡: {batch_success_rate:.1f}%\")\n",
    "                    \n",
    "                    # æ¸…ç©ºå½“å‰æ‰¹æ¬¡\n",
    "                    current_batch = []\n",
    "                \n",
    "                time.sleep(0.3)  # APIè°ƒç”¨é—´éš”\n",
    "        \n",
    "        # ä¿å­˜å‰©ä½™çš„æ¸¸æˆï¼ˆå¦‚æœæœ‰ï¼‰\n",
    "        if current_batch:\n",
    "            batch_counter += 1\n",
    "            batch_file_path = f\"{hinter_dir}/batch_{batch_counter:03d}.csv\"\n",
    "            batch_df = pd.DataFrame(current_batch)\n",
    "            batch_df.to_csv(batch_file_path, index=False, encoding='utf-8')\n",
    "            batch_files.append(batch_file_path)\n",
    "            \n",
    "            success_in_batch = sum(r['success'] for r in current_batch)\n",
    "            batch_success_rate = success_in_batch / len(current_batch) * 100\n",
    "            print(f\"      ğŸ’¾ æœ€åæ‰¹æ¬¡{batch_counter:03d}: {len(current_batch)}åœºæ¸¸æˆå·²ä¿å­˜\")\n",
    "            print(f\"      ğŸ“Š æ‰¹æ¬¡æˆåŠŸç‡: {batch_success_rate:.1f}%\")\n",
    "        \n",
    "        # ä¿å­˜å½“å‰hinteræ¨¡å‹çš„æ±‡æ€»ç»“æœ\n",
    "        hinter_df = pd.DataFrame(hinter_results)\n",
    "        hinter_csv_path = f\"{hinter_dir}/{hinter_name}_summary.csv\"\n",
    "        hinter_df.to_csv(hinter_csv_path, index=False, encoding='utf-8')\n",
    "        \n",
    "        # ç»Ÿè®¡å½“å‰hinteræ¨¡å‹çš„ç»“æœ\n",
    "        success_count = sum(r['success'] for r in hinter_results)\n",
    "        success_rate = success_count / len(hinter_results) * 100\n",
    "        \n",
    "        print(f\"   âœ… {hinter_name}ç»„å®Œæˆ: {len(hinter_results)}åœºæ¸¸æˆ, æˆåŠŸç‡: {success_rate:.1f}%\")\n",
    "        print(f\"   ğŸ’¾ æ±‡æ€»ç»“æœå·²ä¿å­˜: {hinter_csv_path}\")\n",
    "        print(f\"   ğŸ“ æ‰¹æ¬¡æ–‡ä»¶æ•°: {batch_counter}ä¸ª\")\n",
    "        \n",
    "        # å¤±è´¥åŸå› ç»Ÿè®¡\n",
    "        print_failure_summary(hinter_df)\n",
    "    \n",
    "    # ä¿å­˜å…¨é‡å®éªŒçš„æœ€ç»ˆæ±‡æ€»ç»“æœ\n",
    "    final_csv_path = f\"{main_exp_dir}/complete_experiment_results.csv\"\n",
    "    print(f\"\\nğŸ”„ å¼€å§‹ç”Ÿæˆæœ€ç»ˆæ±‡æ€»æ–‡ä»¶...\")\n",
    "    print(f\"ğŸ“Š æ€»æ‰¹æ¬¡æ–‡ä»¶æ•°: {len(batch_files)}\")\n",
    "    \n",
    "    return save_and_analyze_grouped_results(all_experiment_results, final_csv_path, main_exp_dir, models, batch_files)\n",
    "\n",
    "def save_and_analyze_results(all_results, output_path, experiment_type):\n",
    "    \"\"\"ä¿å­˜å¹¶åˆ†æå®éªŒç»“æœ\"\"\"\n",
    "    if all_results:\n",
    "        df = pd.DataFrame(all_results)\n",
    "        df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "        \n",
    "        # ç»Ÿè®¡åˆ†æ\n",
    "        total_success = sum(r['success'] for r in all_results)\n",
    "        success_rate = total_success / len(all_results) * 100\n",
    "        \n",
    "        print(f\"\\\\nâœ… {experiment_type}å®éªŒå®Œæˆï¼\")\n",
    "        print(f\"ğŸ“ ç»“æœæ–‡ä»¶: {output_path}\")\n",
    "        print(f\"ğŸ“Š æ€»æ¸¸æˆæ•°: {len(all_results):,}\")\n",
    "        print(f\"ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1f}%\")\n",
    "        \n",
    "        print_failure_summary(df)\n",
    "        return df\n",
    "    else:\n",
    "        print(\"âŒ æ²¡æœ‰æˆåŠŸçš„å®éªŒè®°å½•\")\n",
    "        return None\n",
    "\n",
    "def save_and_analyze_grouped_results(all_experiment_results, final_csv_path, main_exp_dir, models, batch_files=None):\n",
    "    \"\"\"ä¿å­˜å¹¶åˆ†æåˆ†ç»„å®éªŒç»“æœ\"\"\"\n",
    "    if all_experiment_results:\n",
    "        final_df = pd.DataFrame(all_experiment_results)\n",
    "        final_df.to_csv(final_csv_path, index=False, encoding='utf-8')\n",
    "        \n",
    "        # å…¨é‡å®éªŒç»Ÿè®¡\n",
    "        total_success = sum(r['success'] for r in all_experiment_results)\n",
    "        total_games = len(all_experiment_results)\n",
    "        overall_success_rate = total_success / total_games * 100\n",
    "        \n",
    "        print(f\"\\\\nğŸ‰ å…¨é‡å®éªŒå®Œæˆï¼\")\n",
    "        print(f\"ğŸ“ æœ€ç»ˆæ±‡æ€»æ–‡ä»¶: {final_csv_path}\")\n",
    "        print(f\"ğŸ“Š æ€»æ¸¸æˆæ•°: {total_games:,}åœº\")\n",
    "        print(f\"ğŸ“ˆ æ•´ä½“æˆåŠŸç‡: {overall_success_rate:.1f}%\")\n",
    "        \n",
    "        if batch_files:\n",
    "            print(f\"ğŸ“¦ æ‰¹æ¬¡æ–‡ä»¶æ•°: {len(batch_files)}ä¸ª\")\n",
    "            print(f\"ğŸ’¾ å¹³å‡æ¯æ‰¹æ¬¡: {total_games / len(batch_files):.1f}åœºæ¸¸æˆ\")\n",
    "        \n",
    "        # æŒ‰hinteræ¨¡å‹çš„æˆåŠŸç‡ç»Ÿè®¡\n",
    "        print(f\"\\\\nğŸ“Š å„Hinteræ¨¡å‹æˆåŠŸç‡:\")\n",
    "        for model in models:\n",
    "            model_name = model.split('/')[-1]\n",
    "            model_games = final_df[final_df['hinter_model'] == model]\n",
    "            model_success = sum(model_games['success'])\n",
    "            model_rate = model_success / len(model_games) * 100 if len(model_games) > 0 else 0\n",
    "            print(f\"   {model_name}: {model_success}/{len(model_games)} ({model_rate:.1f}%)\")\n",
    "        \n",
    "        print_failure_summary(final_df, prefix=\"æ•´ä½“\")\n",
    "        print(f\"\\\\nğŸ’¾ æ‰€æœ‰æ•°æ®å·²ä¿å­˜è‡³ç›®å½•: {main_exp_dir}\")\n",
    "        \n",
    "        # æ‰¹æ¬¡æ–‡ä»¶æ€»ç»“\n",
    "        if batch_files:\n",
    "            print(f\"\\\\nğŸ“‚ æ‰¹æ¬¡æ–‡ä»¶è¯¦æƒ…:\")\n",
    "            for batch_file in batch_files:\n",
    "                file_name = os.path.basename(batch_file)\n",
    "                print(f\"   ğŸ“„ {file_name}\")\n",
    "        \n",
    "        return final_df\n",
    "    else:\n",
    "        print(\"âŒ å…¨é‡å®éªŒå¤±è´¥ï¼Œæ²¡æœ‰æˆåŠŸçš„æ¸¸æˆè®°å½•\")\n",
    "        return None\n",
    "\n",
    "def print_failure_summary(df, prefix=\"\"):\n",
    "    \"\"\"æ‰“å°å¤±è´¥åŸå› ç»Ÿè®¡\"\"\"\n",
    "    failed_games = df[df['success'] == False]\n",
    "    if len(failed_games) > 0:\n",
    "        title = f\"{prefix}å¤±è´¥åŸå› ç»Ÿè®¡:\" if prefix else \"å¤±è´¥åŸå› ç»Ÿè®¡:\"\n",
    "        print(f\"\\\\nğŸ“‰ {title}\")\n",
    "        failure_counts = failed_games['failure_reason'].value_counts()\n",
    "        for reason, count in failure_counts.items():\n",
    "            percentage = count / len(failed_games) * 100\n",
    "            if reason == 'TABOO_VIOLATION':\n",
    "                print(f\"   ğŸš« è¿åç¦ç”¨è¯è§„åˆ™: {count} åœº ({percentage:.1f}%)\")\n",
    "            elif reason == 'FORMAT_FAILURE':\n",
    "                print(f\"   ğŸ”¤ æ ¼å¼é”™è¯¯è¶…é™: {count} åœº ({percentage:.1f}%)\")\n",
    "            elif reason == 'API_FAILURE':\n",
    "                print(f\"   ğŸŒ APIè°ƒç”¨å¤±è´¥: {count} åœº ({percentage:.1f}%)\")\n",
    "            elif reason == 'MAX_TURNS_EXCEEDED':\n",
    "                print(f\"   â±ï¸ è½®æ•°è€—å°½: {count} åœº ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"âœ… æ”¯æŒå‡½æ•°å·²å®šä¹‰\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 5. å…¨é‡å®éªŒæ§åˆ¶å™¨ - æ‰¹æ¬¡ä¿å­˜æœºåˆ¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª å¼€å§‹æ‰§è¡Œæµ‹è¯•å®éªŒ...\n",
      "ğŸš€ å¼€å§‹æ‰§è¡Œtestå®éªŒ...\n",
      "ğŸ“ è¾“å‡ºè·¯å¾„: results/test_results_20250711_232922.csv\n",
      "ğŸ¯ æµ‹è¯•è¯: colouration\n",
      "ğŸš« ç¦ç”¨è¯: ['colour', 'timber', 'timbre', 'capture', 'color']\n",
      "ğŸ“Š æ€»æ¸¸æˆæ•°: 16\n",
      "ğŸ”„ æ¸¸æˆ 1/16 (6.2%): gpt-4oâ†’gpt-4o\n",
      "   âœ… æˆåŠŸ | 4è½® | æœ€ç»ˆçŒœæµ‹: colouration\n",
      "ğŸ”„ æ¸¸æˆ 2/16 (12.5%): gpt-4oâ†’gemini-2.5-pro\n",
      "   âœ… æˆåŠŸ | 2è½® | æœ€ç»ˆçŒœæµ‹: colouration\n",
      "ğŸ”„ æ¸¸æˆ 3/16 (18.8%): gpt-4oâ†’deepseek-chat-v3-0324\n",
      "   âœ… æˆåŠŸ | 2è½® | æœ€ç»ˆçŒœæµ‹: colouration\n",
      "ğŸ”„ æ¸¸æˆ 4/16 (25.0%): gpt-4oâ†’claude-sonnet-4\n",
      "   âœ… æˆåŠŸ | 2è½® | æœ€ç»ˆçŒœæµ‹: colouration\n",
      "ğŸ”„ æ¸¸æˆ 5/16 (31.2%): gemini-2.5-proâ†’gpt-4o\n",
      "   âœ… æˆåŠŸ | 2è½® | æœ€ç»ˆçŒœæµ‹: colouration\n",
      "ğŸ”„ æ¸¸æˆ 6/16 (37.5%): gemini-2.5-proâ†’gemini-2.5-pro\n",
      "   âœ… æˆåŠŸ | 1è½® | æœ€ç»ˆçŒœæµ‹: colouration\n",
      "ğŸ”„ æ¸¸æˆ 7/16 (43.8%): gemini-2.5-proâ†’deepseek-chat-v3-0324\n",
      "   âœ… æˆåŠŸ | 2è½® | æœ€ç»ˆçŒœæµ‹: colouration\n",
      "ğŸ”„ æ¸¸æˆ 8/16 (50.0%): gemini-2.5-proâ†’claude-sonnet-4\n",
      "   âœ… æˆåŠŸ | 1è½® | æœ€ç»ˆçŒœæµ‹: colouration\n",
      "ğŸ”„ æ¸¸æˆ 9/16 (56.2%): deepseek-chat-v3-0324â†’gpt-4o\n",
      "   âœ… æˆåŠŸ | 4è½® | æœ€ç»ˆçŒœæµ‹: colouration\n",
      "ğŸ”„ æ¸¸æˆ 10/16 (62.5%): deepseek-chat-v3-0324â†’gemini-2.5-pro\n",
      "   âœ… æˆåŠŸ | 2è½® | æœ€ç»ˆçŒœæµ‹: colouration\n",
      "ğŸ”„ æ¸¸æˆ 11/16 (68.8%): deepseek-chat-v3-0324â†’deepseek-chat-v3-0324\n",
      "   âœ… æˆåŠŸ | 3è½® | æœ€ç»ˆçŒœæµ‹: colouration\n",
      "ğŸ”„ æ¸¸æˆ 12/16 (75.0%): deepseek-chat-v3-0324â†’claude-sonnet-4\n",
      "   âœ… æˆåŠŸ | 1è½® | æœ€ç»ˆçŒœæµ‹: colouration\n",
      "ğŸ”„ æ¸¸æˆ 13/16 (81.2%): claude-sonnet-4â†’gpt-4o\n",
      "   âœ… æˆåŠŸ | 1è½® | æœ€ç»ˆçŒœæµ‹: colouration\n",
      "ğŸ”„ æ¸¸æˆ 14/16 (87.5%): claude-sonnet-4â†’gemini-2.5-pro\n",
      "   âœ… æˆåŠŸ | 1è½® | æœ€ç»ˆçŒœæµ‹: colouration\n",
      "ğŸ”„ æ¸¸æˆ 15/16 (93.8%): claude-sonnet-4â†’deepseek-chat-v3-0324\n",
      "   âœ… æˆåŠŸ | 5è½® | æœ€ç»ˆçŒœæµ‹: colouration\n",
      "ğŸ”„ æ¸¸æˆ 16/16 (100.0%): claude-sonnet-4â†’claude-sonnet-4\n",
      "   âœ… æˆåŠŸ | 3è½® | æœ€ç»ˆçŒœæµ‹: colouration\n",
      "\\nâœ… testå®éªŒå®Œæˆï¼\n",
      "ğŸ“ ç»“æœæ–‡ä»¶: results/test_results_20250711_232922.csv\n",
      "ğŸ“Š æ€»æ¸¸æˆæ•°: 16\n",
      "ğŸ“ˆ æˆåŠŸç‡: 100.0%\n",
      "âœ… æµ‹è¯•å®éªŒå®Œæˆï¼Œå…±16åœºæ¸¸æˆ\n",
      "\n",
      "ğŸ“Š æµ‹è¯•ç»“æœç»Ÿè®¡:\n",
      "   gpt-4o: Hinter 4/4, Guesser 4/4\n",
      "   gemini-2.5-pro: Hinter 4/4, Guesser 4/4\n",
      "   deepseek-chat-v3-0324: Hinter 4/4, Guesser 4/4\n",
      "   claude-sonnet-4: Hinter 4/4, Guesser 4/4\n"
     ]
    }
   ],
   "source": [
    "# æ‰§è¡Œæµ‹è¯•å®éªŒ\n",
    "print(\"ğŸ§ª å¼€å§‹æ‰§è¡Œæµ‹è¯•å®éªŒ...\")\n",
    "\n",
    "# é€‰æ‹©ä¸€ä¸ªæµ‹è¯•è¯\n",
    "test_word_data = random.choice(dataset)\n",
    "\n",
    "config = {\n",
    "    'experiment_type': 'test',\n",
    "    'experiment_mode': 'simple',  # ç®€å•æ¨¡å¼\n",
    "    'max_turns': 5,\n",
    "    'output_dir': 'results',\n",
    "    'fixed_word': test_word_data\n",
    "}\n",
    "\n",
    "# è¿è¡Œæµ‹è¯•å®éªŒ\n",
    "test_results = run_taboo_experiment(client, TEST_MODELS, dataset, config)\n",
    "\n",
    "if test_results is not None:\n",
    "    print(f\"âœ… æµ‹è¯•å®éªŒå®Œæˆï¼Œå…±{len(test_results)}åœºæ¸¸æˆ\")\n",
    "    \n",
    "    # æ˜¾ç¤ºæµ‹è¯•ç»“æœç»Ÿè®¡\n",
    "    print(\"\\nğŸ“Š æµ‹è¯•ç»“æœç»Ÿè®¡:\")\n",
    "    for model in TEST_MODELS:\n",
    "        model_name = model.split('/')[-1]\n",
    "        model_as_hinter = test_results[test_results['hinter_model'] == model]\n",
    "        model_as_guesser = test_results[test_results['guesser_model'] == model]\n",
    "        \n",
    "        hinter_success = sum(model_as_hinter['success']) if len(model_as_hinter) > 0 else 0\n",
    "        guesser_success = sum(model_as_guesser['success']) if len(model_as_guesser) > 0 else 0\n",
    "        \n",
    "        print(f\"   {model_name}: Hinter {hinter_success}/4, Guesser {guesser_success}/4\")\n",
    "else:\n",
    "    print(\"âŒ æµ‹è¯•å®éªŒå¤±è´¥\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 7. å…¨é‡å®éªŒï¼ˆæŒ‰hinteræ¨¡å‹åˆ†ç»„ï¼Œæ‰¹æ¬¡ä¿å­˜ï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰§è¡Œå…¨é‡å®éªŒï¼ˆæŒ‰hinteræ¨¡å‹åˆ†ç»„ï¼Œæ‰¹æ¬¡ä¿å­˜ï¼‰\n",
    "print(\"ğŸš€ å¼€å§‹æ‰§è¡Œå…¨é‡å®éªŒ...\")\n",
    "print(\"ğŸ’¡ æ–°åŠŸèƒ½ï¼šæ‰¹æ¬¡ä¿å­˜æœºåˆ¶\")\n",
    "print(\"   â€¢ æ¯300ä¸ªæ¸¸æˆè‡ªåŠ¨ä¿å­˜ä¸€ä¸ªæ‰¹æ¬¡æ–‡ä»¶\")\n",
    "print(\"   â€¢ å³ä½¿å®éªŒä¸­æ–­ï¼Œå·²å®Œæˆçš„æ‰¹æ¬¡æ•°æ®ä¹Ÿä¼šä¿ç•™\")\n",
    "print(\"   â€¢ æ–¹ä¾¿ç›‘æ§å®éªŒè¿›åº¦å’Œè°ƒè¯•é—®é¢˜\")\n",
    "\n",
    "config = {\n",
    "    'experiment_type': 'formal',\n",
    "    'experiment_mode': 'grouped_by_hinter',  # åˆ†ç»„æ¨¡å¼\n",
    "    'max_turns': 5,\n",
    "    'output_dir': 'results',\n",
    "    'batch_size': 300  # æ¯300ä¸ªæ¸¸æˆä¿å­˜ä¸€ä¸ªæ‰¹æ¬¡æ–‡ä»¶\n",
    "}\n",
    "\n",
    "# è¿è¡Œå…¨é‡å®éªŒ\n",
    "formal_results = run_taboo_experiment(client, TEST_MODELS, dataset, config)\n",
    "\n",
    "if formal_results is not None:\n",
    "    print(f\"\\\\nğŸ‰ å…¨é‡å®éªŒå®Œæˆï¼å…±{len(formal_results):,}åœºæ¸¸æˆ\")\n",
    "    print(\"\\\\nğŸ’¡ å…³é”®æ”¹è¿›ï¼š\")\n",
    "    print(\"   âœ… éå†æ‰€æœ‰300ä¸ªè¯æ±‡ï¼Œè€Œééšæœºé€‰æ‹©\")\n",
    "    print(\"   âœ… æŒ‰hinteræ¨¡å‹åˆ†ç»„æ‰§è¡Œå’Œä¿å­˜\")\n",
    "    print(\"   âœ… ç»Ÿä¸€çš„å®éªŒæ¶æ„ï¼Œæµ‹è¯•å’Œå…¨é‡å…±äº«ä»£ç \")\n",
    "    print(\"   âœ… ä¸¥æ ¼çš„taboo wordsè¿è§„æ£€æŸ¥\")\n",
    "    print(\"   âœ… æ‰¹æ¬¡ä¿å­˜æœºåˆ¶ï¼Œæ¯300ä¸ªæ¸¸æˆä¿å­˜ä¸€ä¸ªæ–‡ä»¶\")\n",
    "    print(\"   âœ… é˜²æ­¢å®éªŒä¸­æ–­æ•°æ®ä¸¢å¤±ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ \")\n",
    "else:\n",
    "    print(\"âŒ å…¨é‡å®éªŒå¤±è´¥\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 8. Quick80 WordNetæ•°æ®é›†å®éªŒ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª å¼€å§‹æ‰§è¡ŒQuick80 WordNetæ•°æ®é›†å®éªŒ...\n",
      "âœ… Quick80æ•°æ®é›†åŠ è½½æˆåŠŸ: 28 æ¡è®°å½•\n",
      "ğŸ“ æ•°æ®é›†è·¯å¾„: quick80_from_wordnet_only.json\n",
      "\n",
      "ğŸ“‹ Quick80æ•°æ®æ ·æœ¬:\n",
      "   ç›®æ ‡è¯: obtrusively\n",
      "   è¯æ€§: adv\n",
      "   ç¦ç”¨è¯: ['manner', 'obtrusive', 'unobtrusively', 'noticeably', 'intrusively']\n",
      "   ç±»åˆ«: general\n",
      "   å®šä¹‰: in an obtrusive manner\n",
      "\n",
      "ğŸ“Š Quick80æ•°æ®é›†ç»Ÿè®¡:\n",
      "ğŸ·ï¸ ç±»åˆ«åˆ†å¸ƒ:\n",
      "   general: 28 æ¡ (100.0%)\n",
      "\n",
      "ğŸ“ è¯æ€§åˆ†å¸ƒ:\n",
      "   adv: 20 æ¡ (71.4%)\n",
      "   verb: 8 æ¡ (28.6%)\n",
      "\n",
      "ğŸš« ç¦ç”¨è¯ç»Ÿè®¡:\n",
      "   å¹³å‡æ•°é‡: 5.0\n",
      "   èŒƒå›´: 5 - 5\n",
      "\n",
      "ğŸ² è®¾ç½®éšæœºç§å­ä¸º 42ï¼Œç¡®ä¿å®éªŒå¯å¤ç°\n"
     ]
    }
   ],
   "source": [
    "# æ‰§è¡ŒQuick80 WordNetæ•°æ®é›†å®éªŒ\n",
    "print(\"ğŸ§ª å¼€å§‹æ‰§è¡ŒQuick80 WordNetæ•°æ®é›†å®éªŒ...\")\n",
    "\n",
    "# åŠ è½½Quick80æ•°æ®é›†\n",
    "QUICK80_DATASET_PATH = \"quick80_from_wordnet_only.json\"\n",
    "\n",
    "def load_quick80_dataset(dataset_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"åŠ è½½Quick80 WordNetæ•°æ®é›†\"\"\"\n",
    "    with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "        dataset = json.load(f)\n",
    "    return dataset\n",
    "\n",
    "# åŠ è½½Quick80æ•°æ®é›†\n",
    "quick80_dataset = load_quick80_dataset(QUICK80_DATASET_PATH)\n",
    "print(f\"âœ… Quick80æ•°æ®é›†åŠ è½½æˆåŠŸ: {len(quick80_dataset)} æ¡è®°å½•\")\n",
    "print(f\"ğŸ“ æ•°æ®é›†è·¯å¾„: {QUICK80_DATASET_PATH}\")\n",
    "\n",
    "# æ˜¾ç¤ºæ•°æ®é›†æ ·æœ¬\n",
    "if quick80_dataset:\n",
    "    sample = quick80_dataset[0]\n",
    "    print(f\"\\nğŸ“‹ Quick80æ•°æ®æ ·æœ¬:\")\n",
    "    print(f\"   ç›®æ ‡è¯: {sample['target']}\")\n",
    "    print(f\"   è¯æ€§: {sample['part_of_speech']}\")\n",
    "    print(f\"   ç¦ç”¨è¯: {sample['taboo']}\")\n",
    "    print(f\"   ç±»åˆ«: {sample.get('category', 'N/A')}\")\n",
    "    if sample.get('senses'):\n",
    "        print(f\"   å®šä¹‰: {sample['senses'][0].get('definition', 'N/A')}\")\n",
    "\n",
    "# ç»Ÿè®¡Quick80æ•°æ®é›†ä¿¡æ¯\n",
    "print(f\"\\nğŸ“Š Quick80æ•°æ®é›†ç»Ÿè®¡:\")\n",
    "categories = {}\n",
    "pos_counts = {}\n",
    "taboo_counts = []\n",
    "\n",
    "for item in quick80_dataset:\n",
    "    # ç»Ÿè®¡ç±»åˆ«\n",
    "    category = item.get('category', 'unknown')\n",
    "    categories[category] = categories.get(category, 0) + 1\n",
    "    \n",
    "    # ç»Ÿè®¡è¯æ€§\n",
    "    pos = item.get('part_of_speech', 'unknown')\n",
    "    pos_counts[pos] = pos_counts.get(pos, 0) + 1\n",
    "    \n",
    "    # ç»Ÿè®¡ç¦ç”¨è¯æ•°é‡\n",
    "    taboo_counts.append(len(item.get('taboo', [])))\n",
    "\n",
    "print(f\"ğŸ·ï¸ ç±»åˆ«åˆ†å¸ƒ:\")\n",
    "for category, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):\n",
    "    percentage = count / len(quick80_dataset) * 100\n",
    "    print(f\"   {category}: {count} æ¡ ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nğŸ“ è¯æ€§åˆ†å¸ƒ:\")\n",
    "for pos, count in sorted(pos_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    percentage = count / len(quick80_dataset) * 100\n",
    "    print(f\"   {pos}: {count} æ¡ ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nğŸš« ç¦ç”¨è¯ç»Ÿè®¡:\")\n",
    "print(f\"   å¹³å‡æ•°é‡: {sum(taboo_counts) / len(taboo_counts):.1f}\")\n",
    "print(f\"   èŒƒå›´: {min(taboo_counts)} - {max(taboo_counts)}\")\n",
    "\n",
    "print(f\"\\nğŸ² è®¾ç½®éšæœºç§å­ä¸º 42ï¼Œç¡®ä¿å®éªŒå¯å¤ç°\")\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ å‡†å¤‡æ‰§è¡ŒQuick80æ•°æ®é›†å…¨é‡å®éªŒ...\n",
      "ğŸ”„ å®éªŒæ¨¡å¼: å…¨é‡éå†æ‰€æœ‰è¯æ±‡\n",
      "\n",
      "ğŸ“ˆ å®éªŒè§„æ¨¡åˆ†æ:\n",
      "   â€¢ è¯æ±‡æ€»æ•°: 28 ä¸ª\n",
      "   â€¢ è¯æ€§åˆ†å¸ƒ: {'adv': 20, 'verb': 8}\n",
      "   â€¢ æ¨¡å‹æ•°é‡: 4 ä¸ª\n",
      "   â€¢ æ¯ä¸ªè¯æ±‡æ¸¸æˆæ•°: 16 åœº\n",
      "   â€¢ æ€»æ¸¸æˆæ•°: 448 åœº\n",
      "\n",
      "âœ… APIå®¢æˆ·ç«¯å·²å°±ç»ª\n",
      "ğŸ¤– å‚ä¸å®éªŒçš„æ¨¡å‹:\n",
      "   1. openai/gpt-4o\n",
      "   2. google/gemini-2.5-pro\n",
      "   3. deepseek/deepseek-chat-v3-0324\n",
      "   4. anthropic/claude-sonnet-4\n",
      "\n",
      "ğŸ® å®éªŒæ‰§è¡Œè®¡åˆ’:\n",
      "   â€¢ æŒ‰Hinteræ¨¡å‹åˆ†ç»„æ‰§è¡Œ\n",
      "   â€¢ æ¯ä¸ªHinteræ¨¡å‹: 4 Ã— 28 = 112 åœºæ¸¸æˆ\n",
      "   â€¢ æ‰¹æ¬¡ä¿å­˜: æ¯50åœºæ¸¸æˆä¿å­˜ä¸€ä¸ªæ–‡ä»¶\n",
      "   â€¢ é¢„è®¡æ‰¹æ¬¡æ•°: ~9 ä¸ªæ–‡ä»¶\n",
      "\n",
      "ğŸ“‹ æ ·æœ¬è¯æ±‡é¢„è§ˆ:\n",
      "   1. dispensed (verb) - ç¦ç”¨è¯: ['bestow', 'parcel', 'allot']...\n",
      "   2. past (adv) - ç¦ç”¨è¯: ['given', 'point', 'pass']...\n",
      "   3. obtrusively (adv) - ç¦ç”¨è¯: ['manner', 'obtrusive', 'unobtrusively']...\n"
     ]
    }
   ],
   "source": [
    "# Quick80å…¨é‡å®éªŒé¢„å¤„ç†\n",
    "print(\"ğŸš€ å‡†å¤‡æ‰§è¡ŒQuick80æ•°æ®é›†å…¨é‡å®éªŒ...\")\n",
    "print(\"ğŸ”„ å®éªŒæ¨¡å¼: å…¨é‡éå†æ‰€æœ‰è¯æ±‡\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ å®éªŒè§„æ¨¡åˆ†æ:\")\n",
    "print(f\"   â€¢ è¯æ±‡æ€»æ•°: {len(quick80_dataset)} ä¸ª\")\n",
    "print(f\"   â€¢ è¯æ€§åˆ†å¸ƒ: {dict(sorted(pos_counts.items(), key=lambda x: x[1], reverse=True))}\")\n",
    "print(f\"   â€¢ æ¨¡å‹æ•°é‡: {len(TEST_MODELS)} ä¸ª\")\n",
    "print(f\"   â€¢ æ¯ä¸ªè¯æ±‡æ¸¸æˆæ•°: {len(TEST_MODELS)**2} åœº\")\n",
    "print(f\"   â€¢ æ€»æ¸¸æˆæ•°: {len(quick80_dataset) * len(TEST_MODELS)**2:,} åœº\")\n",
    "\n",
    "# æ£€æŸ¥APIå®¢æˆ·ç«¯æ˜¯å¦å¯ç”¨\n",
    "if client is None:\n",
    "    print(\"âŒ APIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ‰§è¡Œå®éªŒ\")\n",
    "else:\n",
    "    print(f\"\\nâœ… APIå®¢æˆ·ç«¯å·²å°±ç»ª\")\n",
    "    print(f\"ğŸ¤– å‚ä¸å®éªŒçš„æ¨¡å‹:\")\n",
    "    for i, model in enumerate(TEST_MODELS, 1):\n",
    "        print(f\"   {i}. {model}\")\n",
    "    \n",
    "    print(f\"\\nğŸ® å®éªŒæ‰§è¡Œè®¡åˆ’:\")\n",
    "    print(f\"   â€¢ æŒ‰Hinteræ¨¡å‹åˆ†ç»„æ‰§è¡Œ\")\n",
    "    print(f\"   â€¢ æ¯ä¸ªHinteræ¨¡å‹: {len(TEST_MODELS)} Ã— {len(quick80_dataset)} = {len(TEST_MODELS) * len(quick80_dataset)} åœºæ¸¸æˆ\")\n",
    "    print(f\"   â€¢ æ‰¹æ¬¡ä¿å­˜: æ¯50åœºæ¸¸æˆä¿å­˜ä¸€ä¸ªæ–‡ä»¶\")\n",
    "    print(f\"   â€¢ é¢„è®¡æ‰¹æ¬¡æ•°: ~{(len(quick80_dataset) * len(TEST_MODELS)**2) // 50 + 1} ä¸ªæ–‡ä»¶\")\n",
    "    \n",
    "    # æ˜¾ç¤ºä¸€äº›æ ·æœ¬è¯æ±‡\n",
    "    print(f\"\\nğŸ“‹ æ ·æœ¬è¯æ±‡é¢„è§ˆ:\")\n",
    "    sample_words = random.sample(quick80_dataset, min(3, len(quick80_dataset)))\n",
    "    for i, word in enumerate(sample_words, 1):\n",
    "        print(f\"   {i}. {word['target']} ({word['part_of_speech']}) - ç¦ç”¨è¯: {word['taboo'][:3]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ å¼€å§‹æ‰§è¡ŒQuick80å…¨é‡å®éªŒ...\n",
      "ğŸ’¡ å®éªŒè§„æ¨¡:\n",
      "   â€¢ æ•°æ®é›†è§„æ¨¡: 28 ä¸ªè¯æ±‡\n",
      "   â€¢ æ¨¡å‹ç»„åˆ: 4Ã—4 = 16\n",
      "   â€¢ æ€»æ¸¸æˆæ•°: 448 åœº\n",
      "   â€¢ é¢„è®¡æ—¶é—´: ~3.7 åˆ†é’Ÿ\n",
      "\n",
      "ğŸ“‹ å…¨é‡å®éªŒé…ç½®:\n",
      "   å®éªŒç±»å‹: quick80_full\n",
      "   å®éªŒæ¨¡å¼: grouped_by_hinter\n",
      "   æœ€å¤§è½®æ•°: 5\n",
      "   æ‰¹æ¬¡å¤§å°: 50 æ¸¸æˆ/æ‰¹æ¬¡\n",
      "   è¾“å‡ºç›®å½•: results\n",
      "ğŸ“ ä¸»å®éªŒç›®å½•: results/taboo_experiment_zengliang28_20250717_130855\n",
      "ğŸ“Š æ•°æ®é›†è¯æ±‡æ•°: 28\n",
      "ğŸ¤– æ¨¡å‹ç»„åˆæ•°: 4Ã—4 = 16\n",
      "ğŸ® æ€»æ¸¸æˆæ•°: 448\n",
      "ğŸ’¾ æ‰¹æ¬¡å¤§å°: æ¯50ä¸ªæ¸¸æˆä¿å­˜ä¸€ä¸ªæ–‡ä»¶\n",
      "\\nğŸ¯ ç¬¬1/4ç»„: Hinter = gpt-4o\n",
      "   ğŸ”„ è¿è¡Œç»„åˆ: gpt-4oâ†’gpt-4o\n",
      "   ğŸ”„ è¿è¡Œç»„åˆ: gpt-4oâ†’gemini-2.5-pro\n",
      "      ğŸ’¾ æ‰¹æ¬¡001: 50åœºæ¸¸æˆå·²ä¿å­˜\n",
      "      ğŸ“ˆ è¿›åº¦: 50/112 (44.6%)\n",
      "      ğŸ“Š æ‰¹æ¬¡æˆåŠŸç‡: 52.0%\n",
      "   ğŸ”„ è¿è¡Œç»„åˆ: gpt-4oâ†’deepseek-chat-v3-0324\n",
      "   ğŸ”„ è¿è¡Œç»„åˆ: gpt-4oâ†’claude-sonnet-4\n",
      "      ğŸ’¾ æ‰¹æ¬¡002: 50åœºæ¸¸æˆå·²ä¿å­˜\n",
      "      ğŸ“ˆ è¿›åº¦: 100/112 (89.3%)\n",
      "      ğŸ“Š æ‰¹æ¬¡æˆåŠŸç‡: 60.0%\n",
      "      ğŸ’¾ æœ€åæ‰¹æ¬¡003: 12åœºæ¸¸æˆå·²ä¿å­˜\n",
      "      ğŸ“Š æ‰¹æ¬¡æˆåŠŸç‡: 83.3%\n",
      "   âœ… gpt-4oç»„å®Œæˆ: 112åœºæ¸¸æˆ, æˆåŠŸç‡: 58.9%\n",
      "   ğŸ’¾ æ±‡æ€»ç»“æœå·²ä¿å­˜: results/taboo_experiment_zengliang28_20250717_130855/gpt-4o_as_hinter/gpt-4o_summary.csv\n",
      "   ğŸ“ æ‰¹æ¬¡æ–‡ä»¶æ•°: 3ä¸ª\n",
      "\\nğŸ“‰ å¤±è´¥åŸå› ç»Ÿè®¡:\n",
      "   â±ï¸ è½®æ•°è€—å°½: 31 åœº (67.4%)\n",
      "   ğŸ”¤ æ ¼å¼é”™è¯¯è¶…é™: 9 åœº (19.6%)\n",
      "   ğŸš« è¿åç¦ç”¨è¯è§„åˆ™: 6 åœº (13.0%)\n",
      "\\nğŸ¯ ç¬¬2/4ç»„: Hinter = gemini-2.5-pro\n",
      "   ğŸ”„ è¿è¡Œç»„åˆ: gemini-2.5-proâ†’gpt-4o\n",
      "   ğŸ”„ è¿è¡Œç»„åˆ: gemini-2.5-proâ†’gemini-2.5-pro\n",
      "      ğŸ’¾ æ‰¹æ¬¡001: 50åœºæ¸¸æˆå·²ä¿å­˜\n",
      "      ğŸ“ˆ è¿›åº¦: 50/112 (44.6%)\n",
      "      ğŸ“Š æ‰¹æ¬¡æˆåŠŸç‡: 94.0%\n",
      "   ğŸ”„ è¿è¡Œç»„åˆ: gemini-2.5-proâ†’deepseek-chat-v3-0324\n",
      "   ğŸ”„ è¿è¡Œç»„åˆ: gemini-2.5-proâ†’claude-sonnet-4\n",
      "      ğŸ’¾ æ‰¹æ¬¡002: 50åœºæ¸¸æˆå·²ä¿å­˜\n",
      "      ğŸ“ˆ è¿›åº¦: 100/112 (89.3%)\n",
      "      ğŸ“Š æ‰¹æ¬¡æˆåŠŸç‡: 86.0%\n",
      "      ğŸ’¾ æœ€åæ‰¹æ¬¡003: 12åœºæ¸¸æˆå·²ä¿å­˜\n",
      "      ğŸ“Š æ‰¹æ¬¡æˆåŠŸç‡: 100.0%\n",
      "   âœ… gemini-2.5-proç»„å®Œæˆ: 112åœºæ¸¸æˆ, æˆåŠŸç‡: 91.1%\n",
      "   ğŸ’¾ æ±‡æ€»ç»“æœå·²ä¿å­˜: results/taboo_experiment_zengliang28_20250717_130855/gemini-2.5-pro_as_hinter/gemini-2.5-pro_summary.csv\n",
      "   ğŸ“ æ‰¹æ¬¡æ–‡ä»¶æ•°: 3ä¸ª\n",
      "\\nğŸ“‰ å¤±è´¥åŸå› ç»Ÿè®¡:\n",
      "   â±ï¸ è½®æ•°è€—å°½: 6 åœº (60.0%)\n",
      "   ğŸ”¤ æ ¼å¼é”™è¯¯è¶…é™: 3 åœº (30.0%)\n",
      "   ğŸš« è¿åç¦ç”¨è¯è§„åˆ™: 1 åœº (10.0%)\n",
      "\\nğŸ¯ ç¬¬3/4ç»„: Hinter = deepseek-chat-v3-0324\n",
      "   ğŸ”„ è¿è¡Œç»„åˆ: deepseek-chat-v3-0324â†’gpt-4o\n",
      "   ğŸ”„ è¿è¡Œç»„åˆ: deepseek-chat-v3-0324â†’gemini-2.5-pro\n",
      "      ğŸ’¾ æ‰¹æ¬¡001: 50åœºæ¸¸æˆå·²ä¿å­˜\n",
      "      ğŸ“ˆ è¿›åº¦: 50/112 (44.6%)\n",
      "      ğŸ“Š æ‰¹æ¬¡æˆåŠŸç‡: 68.0%\n",
      "   ğŸ”„ è¿è¡Œç»„åˆ: deepseek-chat-v3-0324â†’deepseek-chat-v3-0324\n",
      "   ğŸ”„ è¿è¡Œç»„åˆ: deepseek-chat-v3-0324â†’claude-sonnet-4\n",
      "      ğŸ’¾ æ‰¹æ¬¡002: 50åœºæ¸¸æˆå·²ä¿å­˜\n",
      "      ğŸ“ˆ è¿›åº¦: 100/112 (89.3%)\n",
      "      ğŸ“Š æ‰¹æ¬¡æˆåŠŸç‡: 60.0%\n",
      "      ğŸ’¾ æœ€åæ‰¹æ¬¡003: 12åœºæ¸¸æˆå·²ä¿å­˜\n",
      "      ğŸ“Š æ‰¹æ¬¡æˆåŠŸç‡: 91.7%\n",
      "   âœ… deepseek-chat-v3-0324ç»„å®Œæˆ: 112åœºæ¸¸æˆ, æˆåŠŸç‡: 67.0%\n",
      "   ğŸ’¾ æ±‡æ€»ç»“æœå·²ä¿å­˜: results/taboo_experiment_zengliang28_20250717_130855/deepseek-chat-v3-0324_as_hinter/deepseek-chat-v3-0324_summary.csv\n",
      "   ğŸ“ æ‰¹æ¬¡æ–‡ä»¶æ•°: 3ä¸ª\n",
      "\\nğŸ“‰ å¤±è´¥åŸå› ç»Ÿè®¡:\n",
      "   â±ï¸ è½®æ•°è€—å°½: 31 åœº (83.8%)\n",
      "   ğŸš« è¿åç¦ç”¨è¯è§„åˆ™: 5 åœº (13.5%)\n",
      "   ğŸ”¤ æ ¼å¼é”™è¯¯è¶…é™: 1 åœº (2.7%)\n",
      "\\nğŸ¯ ç¬¬4/4ç»„: Hinter = claude-sonnet-4\n",
      "   ğŸ”„ è¿è¡Œç»„åˆ: claude-sonnet-4â†’gpt-4o\n",
      "   ğŸ”„ è¿è¡Œç»„åˆ: claude-sonnet-4â†’gemini-2.5-pro\n",
      "      ğŸ’¾ æ‰¹æ¬¡001: 50åœºæ¸¸æˆå·²ä¿å­˜\n",
      "      ğŸ“ˆ è¿›åº¦: 50/112 (44.6%)\n",
      "      ğŸ“Š æ‰¹æ¬¡æˆåŠŸç‡: 86.0%\n",
      "   ğŸ”„ è¿è¡Œç»„åˆ: claude-sonnet-4â†’deepseek-chat-v3-0324\n",
      "   ğŸ”„ è¿è¡Œç»„åˆ: claude-sonnet-4â†’claude-sonnet-4\n",
      "      ğŸ’¾ æ‰¹æ¬¡002: 50åœºæ¸¸æˆå·²ä¿å­˜\n",
      "      ğŸ“ˆ è¿›åº¦: 100/112 (89.3%)\n",
      "      ğŸ“Š æ‰¹æ¬¡æˆåŠŸç‡: 92.0%\n",
      "      ğŸ’¾ æœ€åæ‰¹æ¬¡003: 12åœºæ¸¸æˆå·²ä¿å­˜\n",
      "      ğŸ“Š æ‰¹æ¬¡æˆåŠŸç‡: 91.7%\n",
      "   âœ… claude-sonnet-4ç»„å®Œæˆ: 112åœºæ¸¸æˆ, æˆåŠŸç‡: 89.3%\n",
      "   ğŸ’¾ æ±‡æ€»ç»“æœå·²ä¿å­˜: results/taboo_experiment_zengliang28_20250717_130855/claude-sonnet-4_as_hinter/claude-sonnet-4_summary.csv\n",
      "   ğŸ“ æ‰¹æ¬¡æ–‡ä»¶æ•°: 3ä¸ª\n",
      "\\nğŸ“‰ å¤±è´¥åŸå› ç»Ÿè®¡:\n",
      "   ğŸš« è¿åç¦ç”¨è¯è§„åˆ™: 7 åœº (58.3%)\n",
      "   â±ï¸ è½®æ•°è€—å°½: 4 åœº (33.3%)\n",
      "   ğŸ”¤ æ ¼å¼é”™è¯¯è¶…é™: 1 åœº (8.3%)\n",
      "\n",
      "ğŸ”„ å¼€å§‹ç”Ÿæˆæœ€ç»ˆæ±‡æ€»æ–‡ä»¶...\n",
      "ğŸ“Š æ€»æ‰¹æ¬¡æ–‡ä»¶æ•°: 12\n",
      "\\nğŸ‰ å…¨é‡å®éªŒå®Œæˆï¼\n",
      "ğŸ“ æœ€ç»ˆæ±‡æ€»æ–‡ä»¶: results/taboo_experiment_zengliang28_20250717_130855/complete_experiment_results.csv\n",
      "ğŸ“Š æ€»æ¸¸æˆæ•°: 448åœº\n",
      "ğŸ“ˆ æ•´ä½“æˆåŠŸç‡: 76.6%\n",
      "ğŸ“¦ æ‰¹æ¬¡æ–‡ä»¶æ•°: 12ä¸ª\n",
      "ğŸ’¾ å¹³å‡æ¯æ‰¹æ¬¡: 37.3åœºæ¸¸æˆ\n",
      "\\nğŸ“Š å„Hinteræ¨¡å‹æˆåŠŸç‡:\n",
      "   gpt-4o: 66/112 (58.9%)\n",
      "   gemini-2.5-pro: 102/112 (91.1%)\n",
      "   deepseek-chat-v3-0324: 75/112 (67.0%)\n",
      "   claude-sonnet-4: 100/112 (89.3%)\n",
      "\\nğŸ“‰ æ•´ä½“å¤±è´¥åŸå› ç»Ÿè®¡:\n",
      "   â±ï¸ è½®æ•°è€—å°½: 72 åœº (68.6%)\n",
      "   ğŸš« è¿åç¦ç”¨è¯è§„åˆ™: 19 åœº (18.1%)\n",
      "   ğŸ”¤ æ ¼å¼é”™è¯¯è¶…é™: 14 åœº (13.3%)\n",
      "\\nğŸ’¾ æ‰€æœ‰æ•°æ®å·²ä¿å­˜è‡³ç›®å½•: results/taboo_experiment_zengliang28_20250717_130855\n",
      "\\nğŸ“‚ æ‰¹æ¬¡æ–‡ä»¶è¯¦æƒ…:\n",
      "   ğŸ“„ batch_001.csv\n",
      "   ğŸ“„ batch_002.csv\n",
      "   ğŸ“„ batch_003.csv\n",
      "   ğŸ“„ batch_001.csv\n",
      "   ğŸ“„ batch_002.csv\n",
      "   ğŸ“„ batch_003.csv\n",
      "   ğŸ“„ batch_001.csv\n",
      "   ğŸ“„ batch_002.csv\n",
      "   ğŸ“„ batch_003.csv\n",
      "   ğŸ“„ batch_001.csv\n",
      "   ğŸ“„ batch_002.csv\n",
      "   ğŸ“„ batch_003.csv\n",
      "\n",
      "ğŸ‰ Quick80å…¨é‡å®éªŒå®Œæˆï¼\n",
      "ğŸ“Š å®éªŒè§„æ¨¡æ€»ç»“: 448 åœºæ¸¸æˆ\n",
      "ğŸ“ˆ æ€»ä½“æˆåŠŸç‡: 343/448 (76.6%)\n",
      "\n",
      "ğŸ­ å„Hinteræ¨¡å‹è¡¨ç°:\n",
      "   gpt-4o: 66/112 (58.9%)\n",
      "   gemini-2.5-pro: 102/112 (91.1%)\n",
      "   deepseek-chat-v3-0324: 75/112 (67.0%)\n",
      "   claude-sonnet-4: 100/112 (89.3%)\n",
      "\n",
      "ğŸ” å„Guesseræ¨¡å‹è¡¨ç°:\n",
      "   gpt-4o: 85/112 (75.9%)\n",
      "   gemini-2.5-pro: 89/112 (79.5%)\n",
      "   deepseek-chat-v3-0324: 80/112 (71.4%)\n",
      "   claude-sonnet-4: 89/112 (79.5%)\n",
      "\n",
      "ğŸ“ æŒ‰è¯æ€§åˆ†ææˆåŠŸç‡:\n",
      "   adv: 219/320 (68.4%)\n",
      "   verb: 124/128 (96.9%)\n",
      "\n",
      "âŒ å¤±è´¥åŸå› åˆ†æ (105 åœºå¤±è´¥):\n",
      "   â±ï¸ è½®æ•°è€—å°½: 72 åœº (68.6%)\n",
      "   ğŸš« è¿åç¦ç”¨è¯è§„åˆ™: 19 åœº (18.1%)\n",
      "   ğŸ”¤ æ ¼å¼é”™è¯¯è¶…é™: 14 åœº (13.3%)\n",
      "\n",
      "ğŸ”„ æ¸¸æˆè½®æ•°æ•ˆç‡åˆ†æ:\n",
      "   å¹³å‡è½®æ•°: 1.95 è½®\n",
      "   è½®æ•°åˆ†å¸ƒ:\n",
      "     1è½®: 155 åœº (45.2%)\n",
      "     2è½®: 102 åœº (29.7%)\n",
      "     3è½®: 47 åœº (13.7%)\n",
      "     4è½®: 27 åœº (7.9%)\n",
      "     5è½®: 12 åœº (3.5%)\n",
      "\n",
      "ğŸ’¾ å®éªŒæ•°æ®ä¿å­˜ä¿¡æ¯:\n",
      "   ğŸ“ ä¸»ç›®å½•: results/taboo_experiment_[timestamp]/\n",
      "   ğŸ“„ æŒ‰Hinteræ¨¡å‹åˆ†ç»„çš„æ‰¹æ¬¡æ–‡ä»¶\n",
      "   ğŸ“‹ å®Œæ•´æ±‡æ€»æ–‡ä»¶: complete_experiment_results.csv\n",
      "   ğŸ” å»ºè®®æŸ¥çœ‹å„Hinteræ¨¡å‹çš„å­ç›®å½•è·å–è¯¦ç»†ç»“æœ\n"
     ]
    }
   ],
   "source": [
    "# æ‰§è¡ŒQuick80å…¨é‡å®éªŒ\n",
    "if client is not None:\n",
    "    print(\"ğŸš€ å¼€å§‹æ‰§è¡ŒQuick80å…¨é‡å®éªŒ...\")\n",
    "    print(\"ğŸ’¡ å®éªŒè§„æ¨¡:\")\n",
    "    print(f\"   â€¢ æ•°æ®é›†è§„æ¨¡: {len(quick80_dataset)} ä¸ªè¯æ±‡\")\n",
    "    print(f\"   â€¢ æ¨¡å‹ç»„åˆ: {len(TEST_MODELS)}Ã—{len(TEST_MODELS)} = {len(TEST_MODELS)**2}\")\n",
    "    print(f\"   â€¢ æ€»æ¸¸æˆæ•°: {len(quick80_dataset) * len(TEST_MODELS)**2:,} åœº\")\n",
    "    print(f\"   â€¢ é¢„è®¡æ—¶é—´: ~{len(quick80_dataset) * len(TEST_MODELS)**2 * 0.5 / 60:.1f} åˆ†é’Ÿ\")\n",
    "    \n",
    "    # é…ç½®Quick80å…¨é‡å®éªŒå‚æ•°\n",
    "    quick80_full_config = {\n",
    "        'experiment_type': 'quick80_full',\n",
    "        'experiment_mode': 'grouped_by_hinter',  # ä½¿ç”¨åˆ†ç»„æ¨¡å¼è¿›è¡Œå…¨é‡å®éªŒ\n",
    "        'max_turns': 5,\n",
    "        'output_dir': 'results',\n",
    "        'batch_size': 50  # æ¯50ä¸ªæ¸¸æˆä¿å­˜ä¸€ä¸ªæ‰¹æ¬¡æ–‡ä»¶\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ å…¨é‡å®éªŒé…ç½®:\")\n",
    "    print(f\"   å®éªŒç±»å‹: {quick80_full_config['experiment_type']}\")\n",
    "    print(f\"   å®éªŒæ¨¡å¼: {quick80_full_config['experiment_mode']}\")\n",
    "    print(f\"   æœ€å¤§è½®æ•°: {quick80_full_config['max_turns']}\")\n",
    "    print(f\"   æ‰¹æ¬¡å¤§å°: {quick80_full_config['batch_size']} æ¸¸æˆ/æ‰¹æ¬¡\")\n",
    "    print(f\"   è¾“å‡ºç›®å½•: {quick80_full_config['output_dir']}\")\n",
    "    \n",
    "    # è¿è¡ŒQuick80å…¨é‡å®éªŒï¼Œå¤ç”¨ç°æœ‰çš„å®éªŒæ¡†æ¶\n",
    "    quick80_results = run_taboo_experiment(client, TEST_MODELS, quick80_dataset, quick80_full_config)\n",
    "    \n",
    "    if quick80_results is not None:\n",
    "        print(f\"\\nğŸ‰ Quick80å…¨é‡å®éªŒå®Œæˆï¼\")\n",
    "        print(f\"ğŸ“Š å®éªŒè§„æ¨¡æ€»ç»“: {len(quick80_results):,} åœºæ¸¸æˆ\")\n",
    "        \n",
    "        # æ€»ä½“æˆåŠŸç‡ç»Ÿè®¡\n",
    "        total_success = sum(quick80_results['success'])\n",
    "        success_rate = total_success / len(quick80_results) * 100\n",
    "        print(f\"ğŸ“ˆ æ€»ä½“æˆåŠŸç‡: {total_success:,}/{len(quick80_results):,} ({success_rate:.1f}%)\")\n",
    "        \n",
    "        # æŒ‰Hinteræ¨¡å‹ç»Ÿè®¡æˆåŠŸç‡\n",
    "        print(f\"\\nğŸ­ å„Hinteræ¨¡å‹è¡¨ç°:\")\n",
    "        for model in TEST_MODELS:\n",
    "            model_name = model.split('/')[-1]\n",
    "            model_games = quick80_results[quick80_results['hinter_model'] == model]\n",
    "            model_success = sum(model_games['success'])\n",
    "            model_rate = (model_success / len(model_games) * 100) if len(model_games) > 0 else 0\n",
    "            print(f\"   {model_name}: {model_success:,}/{len(model_games):,} ({model_rate:.1f}%)\")\n",
    "        \n",
    "        # æŒ‰Guesseræ¨¡å‹ç»Ÿè®¡æˆåŠŸç‡\n",
    "        print(f\"\\nğŸ” å„Guesseræ¨¡å‹è¡¨ç°:\")\n",
    "        for model in TEST_MODELS:\n",
    "            model_name = model.split('/')[-1]\n",
    "            model_games = quick80_results[quick80_results['guesser_model'] == model]\n",
    "            model_success = sum(model_games['success'])\n",
    "            model_rate = (model_success / len(model_games) * 100) if len(model_games) > 0 else 0\n",
    "            print(f\"   {model_name}: {model_success:,}/{len(model_games):,} ({model_rate:.1f}%)\")\n",
    "        \n",
    "        # æŒ‰è¯æ€§åˆ†ææˆåŠŸç‡\n",
    "        if 'part_of_speech' in quick80_results.columns or any('part_of_speech' in word for word in quick80_dataset):\n",
    "            print(f\"\\nğŸ“ æŒ‰è¯æ€§åˆ†ææˆåŠŸç‡:\")\n",
    "            # éœ€è¦ä»åŸå§‹æ•°æ®é›†åŒ¹é…è¯æ€§\n",
    "            word_pos_map = {word['target']: word['part_of_speech'] for word in quick80_dataset}\n",
    "            quick80_results['word_pos'] = quick80_results['target_word'].map(word_pos_map)\n",
    "            \n",
    "            for pos in quick80_results['word_pos'].unique():\n",
    "                pos_games = quick80_results[quick80_results['word_pos'] == pos]\n",
    "                pos_success = sum(pos_games['success'])\n",
    "                pos_rate = (pos_success / len(pos_games) * 100) if len(pos_games) > 0 else 0\n",
    "                print(f\"   {pos}: {pos_success:,}/{len(pos_games):,} ({pos_rate:.1f}%)\")\n",
    "        \n",
    "        # å¤±è´¥åŸå› åˆ†æ\n",
    "        failed_games = quick80_results[quick80_results['success'] == False]\n",
    "        if len(failed_games) > 0:\n",
    "            print(f\"\\nâŒ å¤±è´¥åŸå› åˆ†æ ({len(failed_games):,} åœºå¤±è´¥):\")\n",
    "            failure_reasons = failed_games['failure_reason'].value_counts()\n",
    "            for reason, count in failure_reasons.items():\n",
    "                percentage = count / len(failed_games) * 100\n",
    "                if reason == 'TABOO_VIOLATION':\n",
    "                    print(f\"   ğŸš« è¿åç¦ç”¨è¯è§„åˆ™: {count:,} åœº ({percentage:.1f}%)\")\n",
    "                elif reason == 'FORMAT_FAILURE':\n",
    "                    print(f\"   ğŸ”¤ æ ¼å¼é”™è¯¯è¶…é™: {count:,} åœº ({percentage:.1f}%)\")\n",
    "                elif reason == 'API_FAILURE':\n",
    "                    print(f\"   ğŸŒ APIè°ƒç”¨å¤±è´¥: {count:,} åœº ({percentage:.1f}%)\")\n",
    "                elif reason == 'MAX_TURNS_EXCEEDED':\n",
    "                    print(f\"   â±ï¸ è½®æ•°è€—å°½: {count:,} åœº ({percentage:.1f}%)\")\n",
    "                else:\n",
    "                    print(f\"   â“ {reason}: {count:,} åœº ({percentage:.1f}%)\")\n",
    "        else:\n",
    "            print(f\"\\nğŸ‰ æ‰€æœ‰æ¸¸æˆéƒ½æˆåŠŸäº†ï¼æ²¡æœ‰å¤±è´¥æ¡ˆä¾‹ã€‚\")\n",
    "        \n",
    "        # è½®æ•°æ•ˆç‡åˆ†æ\n",
    "        successful_games = quick80_results[quick80_results['success'] == True]\n",
    "        if len(successful_games) > 0:\n",
    "            print(f\"\\nğŸ”„ æ¸¸æˆè½®æ•°æ•ˆç‡åˆ†æ:\")\n",
    "            avg_turns = successful_games['turns_used'].mean()\n",
    "            print(f\"   å¹³å‡è½®æ•°: {avg_turns:.2f} è½®\")\n",
    "            print(f\"   è½®æ•°åˆ†å¸ƒ:\")\n",
    "            turn_counts = successful_games['turns_used'].value_counts().sort_index()\n",
    "            for turns, count in turn_counts.items():\n",
    "                percentage = count / len(successful_games) * 100\n",
    "                print(f\"     {turns}è½®: {count:,} åœº ({percentage:.1f}%)\")\n",
    "        \n",
    "        # ä¿å­˜ä¿¡æ¯\n",
    "        print(f\"\\nğŸ’¾ å®éªŒæ•°æ®ä¿å­˜ä¿¡æ¯:\")\n",
    "        print(f\"   ğŸ“ ä¸»ç›®å½•: results/taboo_experiment_[timestamp]/\")\n",
    "        print(f\"   ğŸ“„ æŒ‰Hinteræ¨¡å‹åˆ†ç»„çš„æ‰¹æ¬¡æ–‡ä»¶\")\n",
    "        print(f\"   ğŸ“‹ å®Œæ•´æ±‡æ€»æ–‡ä»¶: complete_experiment_results.csv\")\n",
    "        print(f\"   ğŸ” å»ºè®®æŸ¥çœ‹å„Hinteræ¨¡å‹çš„å­ç›®å½•è·å–è¯¦ç»†ç»“æœ\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ Quick80å…¨é‡å®éªŒå¤±è´¥\")\n",
    "else:\n",
    "    print(\"âŒ æ— æ³•æ‰§è¡ŒQuick80å…¨é‡å®éªŒï¼šAPIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
