{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 1. 导入依赖和数据库\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SciencePlots in /opt/homebrew/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: matplotlib in /opt/homebrew/lib/python3.11/site-packages (from SciencePlots) (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->SciencePlots) (1.17.0)\n",
      "Requirement already satisfied: SciencePlots in /opt/homebrew/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: matplotlib in /opt/homebrew/lib/python3.11/site-packages (from SciencePlots) (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->SciencePlots) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->SciencePlots) (1.17.0)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "'science' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/matplotlib/style/core.py:129\u001b[39m, in \u001b[36muse\u001b[39m\u001b[34m(style)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     style = \u001b[43m_rc_params_in_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/matplotlib/__init__.py:903\u001b[39m, in \u001b[36m_rc_params_in_file\u001b[39m\u001b[34m(fname, transform, fail_on_error)\u001b[39m\n\u001b[32m    902\u001b[39m rc_temp = {}\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_open_file_or_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfd\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.gen)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/matplotlib/__init__.py:880\u001b[39m, in \u001b[36m_open_file_or_url\u001b[39m\u001b[34m(fname)\u001b[39m\n\u001b[32m    879\u001b[39m fname = os.path.expanduser(fname)\n\u001b[32m--> \u001b[39m\u001b[32m880\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fname, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    881\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'science'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 用法示例\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m.\u001b[49m\u001b[43muse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mscience\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mno-latex\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      9\u001b[39m plt.style.use([\u001b[33m'\u001b[39m\u001b[33mscience\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mgrid\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/matplotlib/style/core.py:131\u001b[39m, in \u001b[36muse\u001b[39m\u001b[34m(style)\u001b[39m\n\u001b[32m    129\u001b[39m         style = _rc_params_in_file(style)\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    132\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstyle\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m is not a valid package style, path of style \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    133\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfile, URL of style file, or library style name (library \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    134\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mstyles are listed in `style.available`)\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    135\u001b[39m filtered = {}\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m style:  \u001b[38;5;66;03m# don't trigger RcParams.__getitem__('backend')\u001b[39;00m\n",
      "\u001b[31mOSError\u001b[39m: 'science' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)"
     ]
    }
   ],
   "source": [
    "!pip install SciencePlots\n",
    "!pip3 install SciencePlots\n",
    "\n",
    "# 用法示例\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(['science', 'no-latex'])\n",
    "import numpy as np\n",
    "\n",
    "plt.style.use(['science', 'grid'])\n",
    "\n",
    "x = np.linspace(0, 10, 100)\n",
    "y1 = np.sin(x)\n",
    "y2 = np.cos(x)\n",
    "\n",
    "plt.plot(x, y1, label='sin(x)')\n",
    "plt.plot(x, y2, label='cos(x)')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.title('A beautiful scientific plot')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 正在加载数据集...\n",
      "✅ 数据集加载完成，共300条记录\n",
      "\n",
      "📋 数据集样本:\n",
      "   目标词: recovery\n",
      "   类别: chemistry\n",
      "   禁用词: ['forest', 'return', 'advance', 'rapid', 'state']\n",
      "   词义数: 3\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "from typing import Dict, List, Any\n",
    "from datetime import datetime\n",
    "\n",
    "# 加载数据集\n",
    "def load_dataset(dataset_path: str = \"data/dataset.json\") -> List[Dict]:\n",
    "    \"\"\"加载Taboo数据集\"\"\"\n",
    "    with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# 加载数据集\n",
    "print(\"📚 正在加载数据集...\")\n",
    "dataset = load_dataset()\n",
    "print(f\"✅ 数据集加载完成，共{len(dataset)}条记录\")\n",
    "\n",
    "# 显示数据集样本\n",
    "print(\"\\n📋 数据集样本:\")\n",
    "sample = random.choice(dataset)\n",
    "print(f\"   目标词: {sample['target']}\")\n",
    "print(f\"   类别: {sample.get('category', 'unknown')}\")\n",
    "print(f\"   禁用词: {sample['taboo']}\")\n",
    "print(f\"   词义数: {len(sample.get('senses', []))}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 2. 数据集统计分析\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 数据集基本统计:\n",
      "========================================\n",
      "\n",
      "🏷️ 类别分布 (Top 5):\n",
      "   1. general: 100 条 (33.3%)\n",
      "   2. chemistry: 50 条 (16.7%)\n",
      "   3. cs: 50 条 (16.7%)\n",
      "   4. finance: 50 条 (16.7%)\n",
      "   5. philosophy: 50 条 (16.7%)\n",
      "\n",
      "🚫 禁用词统计:\n",
      "   平均数量: 5.0\n",
      "   范围: 5 - 5\n",
      "\n",
      "💭 词义统计:\n",
      "   平均数量: 3.1\n",
      "   范围: 1 - 23\n",
      "\n",
      "✅ 数据集统计完成，质量良好，可用于实验\n",
      "\n",
      "🎲 随机种子已设置为 240，确保实验可复现\n"
     ]
    }
   ],
   "source": [
    "# 数据集统计信息\n",
    "print(\"📊 数据集基本统计:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# 类别分布统计\n",
    "categories = {}\n",
    "taboo_counts = []\n",
    "sense_counts = []\n",
    "\n",
    "for item in dataset:\n",
    "    # 统计类别\n",
    "    category = item.get('category', 'unknown')\n",
    "    categories[category] = categories.get(category, 0) + 1\n",
    "    \n",
    "    # 统计禁用词数量\n",
    "    taboo_counts.append(len(item.get('taboo', [])))\n",
    "    \n",
    "    # 统计词义数量\n",
    "    sense_counts.append(len(item.get('senses', [])))\n",
    "\n",
    "print(f\"\\n🏷️ 类别分布 (Top 5):\")\n",
    "sorted_categories = sorted(categories.items(), key=lambda x: x[1], reverse=True)\n",
    "for i, (category, count) in enumerate(sorted_categories[:5], 1):\n",
    "    percentage = count / len(dataset) * 100\n",
    "    print(f\"   {i}. {category}: {count} 条 ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\n🚫 禁用词统计:\")\n",
    "print(f\"   平均数量: {sum(taboo_counts) / len(taboo_counts):.1f}\")\n",
    "print(f\"   范围: {min(taboo_counts)} - {max(taboo_counts)}\")\n",
    "\n",
    "print(f\"\\n💭 词义统计:\")\n",
    "print(f\"   平均数量: {sum(sense_counts) / len(sense_counts):.1f}\")\n",
    "print(f\"   范围: {min(sense_counts)} - {max(sense_counts)}\")\n",
    "\n",
    "print(f\"\\n✅ 数据集统计完成，质量良好，可用于实验\")\n",
    "\n",
    "# 设置随机种子用于实验\n",
    "random.seed(240)\n",
    "print(\"\\n🎲 随机种子已设置为 240，确保实验可复现\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 3. API客户端设置\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API客户端初始化成功\n",
      "🤖 实验模型: 4 个\n",
      "   1. openai/gpt-4o\n",
      "   2. google/gemini-2.5-pro\n",
      "   3. deepseek/deepseek-chat-v3-0324\n",
      "   4. anthropic/claude-sonnet-4\n"
     ]
    }
   ],
   "source": [
    "# 设置API客户端\n",
    "def load_api_keys(keys_path: str = \"api_keys.json\") -> Dict[str, str]:\n",
    "    \"\"\"加载API密钥\"\"\"\n",
    "    with open(keys_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "class OpenRouterClient:\n",
    "    \"\"\"OpenRouter API客户端\"\"\"\n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "        self.headers = {\n",
    "            \"Authorization\": f\"Bearer {api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "    \n",
    "    def call_model(self, model: str, messages: List[Dict[str, str]], temperature: float = 0.3) -> str:\n",
    "        \"\"\"调用模型API\"\"\"\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": temperature,\n",
    "            \"max_tokens\": 2000\n",
    "        }\n",
    "        response = requests.post(self.base_url, headers=self.headers, json=payload, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        content = result['choices'][0]['message']['content'].strip()\n",
    "        \n",
    "        # 防止乱码：只保留ASCII可打印字符\n",
    "        import re\n",
    "        content = re.sub(r'[^\\x20-\\x7E]', '', content)\n",
    "        return content\n",
    "\n",
    "# 初始化API客户端\n",
    "try:\n",
    "    api_keys = load_api_keys()\n",
    "    client = OpenRouterClient(api_keys[\"OPENROUTER_API_KEY\"])\n",
    "    print(\"✅ API客户端初始化成功\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ API客户端初始化失败: {e}\")\n",
    "    client = None\n",
    "\n",
    "# 定义测试模型\n",
    "TEST_MODELS = [\n",
    "    \"openai/gpt-4o\",\n",
    "    \"google/gemini-2.5-pro\", \n",
    "    \"deepseek/deepseek-chat-v3-0324\",\n",
    "    \"anthropic/claude-sonnet-4\"\n",
    "]\n",
    "\n",
    "print(f\"🤖 实验模型: {len(TEST_MODELS)} 个\")\n",
    "for i, model in enumerate(TEST_MODELS, 1):\n",
    "    print(f\"   {i}. {model}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 4. 通用实验方法\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 数据集加载成功: 300 条记录\n",
      "📁 数据集路径: data/dataset.json\n",
      "\n",
      "📋 数据样本:\n",
      "   目标词: crotonbug\n",
      "   禁用词: ['common', 'croton', 'europe', 'german', 'states']\n",
      "   类别: general\n",
      "   定义: small light-brown cockroach brought to United States from Europe; a common household pest...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Any\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# 加载数据集\n",
    "def load_dataset(dataset_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"加载Taboo游戏数据集\"\"\"\n",
    "    with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "        dataset = json.load(f)\n",
    "    return dataset\n",
    "\n",
    "# 加载预生成的数据集\n",
    "DATASET_PATH = \"data/dataset.json\"\n",
    "dataset = load_dataset(DATASET_PATH)\n",
    "print(f\"✅ 数据集加载成功: {len(dataset)} 条记录\")\n",
    "print(f\"📁 数据集路径: {DATASET_PATH}\")\n",
    "\n",
    "# 显示第一个样本\n",
    "if dataset:\n",
    "    sample = dataset[0]\n",
    "    print(f\"\\n📋 数据样本:\")\n",
    "    print(f\"   目标词: {sample['target']}\")\n",
    "    print(f\"   禁用词: {sample['taboo']}\")\n",
    "    print(f\"   类别: {sample.get('category', 'N/A')}\")\n",
    "    if sample.get('senses'):\n",
    "        print(f\"   定义: {sample['senses'][0].get('definition', 'N/A')[:100]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 核心工具函数已定义\n"
     ]
    }
   ],
   "source": [
    "# 通用实验方法 - 核心函数\n",
    "\n",
    "def safe_text_cleanup(text: str, max_length: int = 200) -> str:\n",
    "    \"\"\"安全清理文本，防止乱码和超长内容\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    import re\n",
    "    cleaned = re.sub(r'[^\\x20-\\x7E\\n\\r\\t]', '', str(text))\n",
    "    if len(cleaned) > max_length:\n",
    "        cleaned = cleaned[:max_length] + \"...\"\n",
    "    return cleaned\n",
    "\n",
    "def robust_api_call(client, model: str, base_prompt: str, expected_prefix: str, max_retries: int = 3):\n",
    "    \"\"\"健壮的API调用，包含重试机制和格式验证\"\"\"\n",
    "    failed_outputs = []\n",
    "    \n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            if attempt == 1:\n",
    "                prompt = base_prompt\n",
    "            else:\n",
    "                prev_output = failed_outputs[-1] if failed_outputs else \"Unknown\"\n",
    "                format_reminder = f\"\"\"\n",
    "\n",
    "⚠️ FORMAT ERROR DETECTED ⚠️\n",
    "Your previous response was: \"{prev_output}\"\n",
    "\n",
    "REQUIRED FORMAT:\n",
    "- You MUST start with exactly '{expected_prefix}' (including square brackets)\n",
    "- Do NOT add any text before {expected_prefix}\n",
    "\n",
    "Try again with the exact format:\"\"\"\n",
    "                prompt = base_prompt + format_reminder\n",
    "            \n",
    "            response = client.call_model(model, [{\"role\": \"user\", \"content\": prompt}])\n",
    "            \n",
    "            if response.strip().upper().startswith(expected_prefix.upper()):\n",
    "                return {\n",
    "                    'success': True,\n",
    "                    'response': response,\n",
    "                    'attempts': attempt,\n",
    "                    'error': None,\n",
    "                    'failed_outputs': failed_outputs\n",
    "                }\n",
    "            else:\n",
    "                safe_response = safe_text_cleanup(response, max_length=150)\n",
    "                failed_outputs.append(safe_response)\n",
    "                \n",
    "                if attempt == max_retries:\n",
    "                    all_failed = \" | \".join(failed_outputs)\n",
    "                    return {\n",
    "                        'success': False,\n",
    "                        'response': f\"FORMAT_ERROR_EXCEEDED: {safe_response}\",\n",
    "                        'attempts': attempt,\n",
    "                        'error': f\"Failed after {max_retries} attempts. Expected '{expected_prefix}'. All failed outputs: {all_failed}\",\n",
    "                        'failed_outputs': failed_outputs\n",
    "                    }\n",
    "                time.sleep(0.5)\n",
    "                \n",
    "        except Exception as e:\n",
    "            safe_error = safe_text_cleanup(str(e), max_length=150)\n",
    "            error_msg = f\"API error (attempt {attempt}/{max_retries}): {safe_error}\"\n",
    "            \n",
    "            if attempt == max_retries:\n",
    "                return {\n",
    "                    'success': False,\n",
    "                    'response': None,\n",
    "                    'attempts': attempt,\n",
    "                    'error': error_msg,\n",
    "                    'failed_outputs': failed_outputs\n",
    "                }\n",
    "            time.sleep(1.0)\n",
    "    \n",
    "    return {\n",
    "        'success': False,\n",
    "        'response': None,\n",
    "        'attempts': max_retries,\n",
    "        'error': \"Max retries exceeded\",\n",
    "        'failed_outputs': failed_outputs\n",
    "    }\n",
    "\n",
    "def extract_guess_word(response: str) -> str:\n",
    "    \"\"\"从响应中提取猜测词\"\"\"\n",
    "    if response.startswith(\"FORMAT_ERROR_EXCEEDED\"):\n",
    "        return \"FORMAT_ERROR\"\n",
    "    \n",
    "    if '[GUESS]' in response.upper():\n",
    "        import re\n",
    "        match = re.search(r'\\[GUESS\\]\\s*(.+)', response, re.IGNORECASE)\n",
    "        if match:\n",
    "            guess_part = match.group(1).strip()\n",
    "            guess = guess_part.split()[0] if guess_part.split() else \"\"\n",
    "            return guess.strip('.,!?;:\"\\'()[]{}')\n",
    "    \n",
    "    if 'Guess:' in response:\n",
    "        guess_part = response.split('Guess:')[1].strip()\n",
    "        guess = guess_part.split()[0] if guess_part.split() else \"\"\n",
    "        return guess.strip('.,!?;:\"\\'()[]{}')\n",
    "    \n",
    "    return \"INVALID_FORMAT\"\n",
    "\n",
    "def extract_clue_text(response: str) -> str:\n",
    "    \"\"\"从响应中提取线索文本\"\"\"\n",
    "    if response.startswith(\"FORMAT_ERROR_EXCEEDED\"):\n",
    "        return \"FORMAT_ERROR\"\n",
    "    \n",
    "    if '[CLUE]' in response.upper():\n",
    "        import re\n",
    "        match = re.search(r'\\[CLUE\\]\\s*(.+)', response, re.IGNORECASE | re.DOTALL)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "    \n",
    "    if 'Clue:' in response:\n",
    "        return response.split('Clue:')[1].strip()\n",
    "    \n",
    "    return \"INVALID_FORMAT\"\n",
    "\n",
    "def check_taboo_violation(hint, taboo_words):\n",
    "    \"\"\"检查hinter的线索是否违反了禁用词规则\"\"\"\n",
    "    import re\n",
    "    hint_lower = hint.lower()\n",
    "    \n",
    "    for taboo in taboo_words:\n",
    "        taboo_lower = taboo.lower()\n",
    "        # 检查完整单词匹配\n",
    "        if re.search(r'\\b' + re.escape(taboo_lower) + r'\\b', hint_lower):\n",
    "            return True\n",
    "        # 检查部分拼写（至少3个字符）\n",
    "        if len(taboo_lower) >= 3 and taboo_lower in hint_lower:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "print(\"✅ 核心工具函数已定义\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 增强版游戏函数已定义（包含严格的taboo violation检查）\n"
     ]
    }
   ],
   "source": [
    "# 核心游戏逻辑和通用实验运行器\n",
    "\n",
    "def enhanced_play_taboo_game(client, hinter_model, guesser_model, target_word, taboo_words, max_turns=5):\n",
    "    \"\"\"增强版Taboo游戏，包含taboo violation检查\"\"\"\n",
    "    \n",
    "    conversation_history = []\n",
    "    taboo_list = ', '.join(taboo_words)\n",
    "    \n",
    "    # 系统提示\n",
    "    hinter_system = f\"\"\"You are playing a Taboo word game as the Hinter.\n",
    "\n",
    "CRITICAL FORMAT REQUIREMENT:\n",
    "- You MUST start your response with exactly '[CLUE]' (including square brackets)\n",
    "- Do NOT add any text before [CLUE]\n",
    "- Example: [CLUE] This is a large mammal with a trunk\n",
    "\n",
    "GAME RULES:\n",
    "1. NEVER use any of these taboo words: {taboo_list}\n",
    "2. Give helpful clues to help the guesser find the target word\n",
    "3. You can see the conversation history and build on previous clues\n",
    "4. Be creative but follow the format exactly\n",
    "5. Use BRITISH ENGLISH spelling (e.g., colour not color, centre not center)\n",
    "\n",
    "Target word: {target_word}\n",
    "Taboo words (ABSOLUTELY FORBIDDEN): {taboo_list}\"\"\"\n",
    "\n",
    "    guesser_system = \"\"\"You are playing a Taboo word game as the Guesser.\n",
    "\n",
    "CRITICAL FORMAT REQUIREMENT:\n",
    "- You MUST start your response with exactly '[GUESS]' (including square brackets)\n",
    "- Do NOT add any text before [GUESS]\n",
    "- Example: [GUESS] elephant\n",
    "\n",
    "GAME RULES:\n",
    "1. Make your best guess based on all the clues you've received\n",
    "2. You can see the conversation history\n",
    "3. Give only ONE word as your guess after [GUESS]\n",
    "4. Use BRITISH ENGLISH spelling (e.g., colour not color, centre not center)\"\"\"\n",
    "\n",
    "    # 记录统计信息\n",
    "    total_hinter_attempts = 0\n",
    "    total_guesser_attempts = 0\n",
    "    format_errors = []\n",
    "    hinter_failed_outputs = []\n",
    "    guesser_failed_outputs = []\n",
    "\n",
    "    for turn in range(1, max_turns + 1):\n",
    "        # 构建Hinter提示\n",
    "        if turn == 1:\n",
    "            hinter_prompt = f\"{hinter_system}\\n\\nProvide your first clue:\"\n",
    "        else:\n",
    "            history_text = \"\\n\".join([f\"Turn {i}: {msg}\" for i, msg in enumerate(conversation_history, 1)])\n",
    "            hinter_prompt = f\"{hinter_system}\\n\\nConversation so far:\\n{history_text}\\n\\nThe guesser hasn't found the word yet. Provide your next clue:\"\n",
    "        \n",
    "        # Hinter给出线索（带重试）\n",
    "        hinter_result = robust_api_call(client, hinter_model, hinter_prompt, \"[CLUE]\", max_retries=3)\n",
    "        total_hinter_attempts += hinter_result['attempts']\n",
    "        \n",
    "        if hinter_result.get('failed_outputs'):\n",
    "            hinter_failed_outputs.extend(hinter_result['failed_outputs'])\n",
    "        \n",
    "        if not hinter_result['success']:\n",
    "            error_type = \"FORMAT_FAILURE\" if \"FORMAT_ERROR_EXCEEDED\" in str(hinter_result.get('response', '')) else \"API_FAILURE\"\n",
    "            format_errors.append(f\"Turn {turn} Hinter: {hinter_result['error']}\")\n",
    "            \n",
    "            return {\n",
    "                'success': False,\n",
    "                'turns': turn,\n",
    "                'conversation': conversation_history,\n",
    "                'final_guess': f\"HINTER_{error_type}\",\n",
    "                'error': f\"{error_type}: {hinter_result['error']}\",\n",
    "                'failure_reason': error_type,\n",
    "                'total_hinter_attempts': total_hinter_attempts,\n",
    "                'total_guesser_attempts': total_guesser_attempts,\n",
    "                'format_errors': format_errors,\n",
    "                'hinter_failed_outputs': hinter_failed_outputs,\n",
    "                'guesser_failed_outputs': guesser_failed_outputs,\n",
    "                'all_hints': [msg for msg in conversation_history if msg.startswith('Hinter:')],\n",
    "                'all_guesses': [msg for msg in conversation_history if msg.startswith('Guesser:')]\n",
    "            }\n",
    "        \n",
    "        # 提取线索并检查taboo violation\n",
    "        hint_text = extract_clue_text(hinter_result['response'])\n",
    "        \n",
    "        # 🚨 关键：检查是否违反taboo words规则\n",
    "        taboo_violated = check_taboo_violation(hint_text, taboo_words)\n",
    "        if taboo_violated:\n",
    "            # 违规立即失败！\n",
    "            return {\n",
    "                'success': False,\n",
    "                'turns': turn,\n",
    "                'conversation': conversation_history,\n",
    "                'final_guess': 'TABOO_VIOLATION: Hinter违反规则',\n",
    "                'error': f'TABOO_VIOLATION: Hinter在第{turn}轮违反规则，说了禁用词: {hint_text}',\n",
    "                'failure_reason': 'TABOO_VIOLATION',\n",
    "                'taboo_violation_turn': turn,\n",
    "                'taboo_violation_hint': hint_text,\n",
    "                'total_hinter_attempts': total_hinter_attempts,\n",
    "                'total_guesser_attempts': total_guesser_attempts,\n",
    "                'format_errors': format_errors,\n",
    "                'hinter_failed_outputs': hinter_failed_outputs,\n",
    "                'guesser_failed_outputs': guesser_failed_outputs,\n",
    "                'all_hints': [msg for msg in conversation_history if msg.startswith('Hinter:')],\n",
    "                'all_guesses': [msg for msg in conversation_history if msg.startswith('Guesser:')]\n",
    "            }\n",
    "        \n",
    "        conversation_history.append(f\"Hinter: {hinter_result['response']}\")\n",
    "        \n",
    "        # 构建Guesser提示\n",
    "        history_text = \"\\n\".join([f\"Turn {i}: {msg}\" for i, msg in enumerate(conversation_history, 1)])\n",
    "        guesser_prompt = f\"{guesser_system}\\n\\nConversation so far:\\n{history_text}\\n\\nWhat is your guess?\"\n",
    "        \n",
    "        # Guesser进行猜测（带重试）\n",
    "        guesser_result = robust_api_call(client, guesser_model, guesser_prompt, \"[GUESS]\", max_retries=3)\n",
    "        total_guesser_attempts += guesser_result['attempts']\n",
    "        \n",
    "        if guesser_result.get('failed_outputs'):\n",
    "            guesser_failed_outputs.extend(guesser_result['failed_outputs'])\n",
    "        \n",
    "        if not guesser_result['success']:\n",
    "            error_type = \"FORMAT_FAILURE\" if \"FORMAT_ERROR_EXCEEDED\" in str(guesser_result.get('response', '')) else \"API_FAILURE\"\n",
    "            format_errors.append(f\"Turn {turn} Guesser: {guesser_result['error']}\")\n",
    "            \n",
    "            return {\n",
    "                'success': False,\n",
    "                'turns': turn,\n",
    "                'conversation': conversation_history,\n",
    "                'final_guess': f\"GUESSER_{error_type}\",\n",
    "                'error': f\"{error_type}: {guesser_result['error']}\",\n",
    "                'failure_reason': error_type,\n",
    "                'total_hinter_attempts': total_hinter_attempts,\n",
    "                'total_guesser_attempts': total_guesser_attempts,\n",
    "                'format_errors': format_errors,\n",
    "                'hinter_failed_outputs': hinter_failed_outputs,\n",
    "                'guesser_failed_outputs': guesser_failed_outputs,\n",
    "                'all_hints': [msg for msg in conversation_history if msg.startswith('Hinter:')],\n",
    "                'all_guesses': [msg for msg in conversation_history if msg.startswith('Guesser:')]\n",
    "            }\n",
    "        \n",
    "        conversation_history.append(f\"Guesser: {guesser_result['response']}\")\n",
    "        guess = extract_guess_word(guesser_result['response'])\n",
    "        \n",
    "        # 检查是否成功\n",
    "        if guess.lower() == target_word.lower():\n",
    "            return {\n",
    "                'success': True,\n",
    "                'turns': turn,\n",
    "                'conversation': conversation_history,\n",
    "                'final_guess': guess,\n",
    "                'failure_reason': None,\n",
    "                'total_hinter_attempts': total_hinter_attempts,\n",
    "                'total_guesser_attempts': total_guesser_attempts,\n",
    "                'format_errors': format_errors,\n",
    "                'hinter_failed_outputs': hinter_failed_outputs,\n",
    "                'guesser_failed_outputs': guesser_failed_outputs,\n",
    "                'all_hints': [msg for msg in conversation_history if msg.startswith('Hinter:')],\n",
    "                'all_guesses': [msg for msg in conversation_history if msg.startswith('Guesser:')]\n",
    "            }\n",
    "        \n",
    "        # 如果不是最后一轮，添加反馈\n",
    "        if turn < max_turns:\n",
    "            conversation_history.append(f\"System: '{guess}' is not correct. Try again!\")\n",
    "    \n",
    "    # 达到最大轮数仍未成功\n",
    "    return {\n",
    "        'success': False,\n",
    "        'turns': max_turns,\n",
    "        'conversation': conversation_history,\n",
    "        'final_guess': guess if 'guess' in locals() else 'N/A',\n",
    "        'failure_reason': 'MAX_TURNS_EXCEEDED',\n",
    "        'total_hinter_attempts': total_hinter_attempts,\n",
    "        'total_guesser_attempts': total_guesser_attempts,\n",
    "        'format_errors': format_errors,\n",
    "        'hinter_failed_outputs': hinter_failed_outputs,\n",
    "        'guesser_failed_outputs': guesser_failed_outputs,\n",
    "        'all_hints': [msg for msg in conversation_history if msg.startswith('Hinter:')],\n",
    "        'all_guesses': [msg for msg in conversation_history if msg.startswith('Guesser:')]\n",
    "    }\n",
    "\n",
    "print(\"✅ 增强版游戏函数已定义（包含严格的taboo violation检查）\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 统一实验运行器已定义\n"
     ]
    }
   ],
   "source": [
    "# 统一的Taboo实验运行器\n",
    "def run_taboo_experiment(client, models, dataset, config):\n",
    "    \"\"\"统一的Taboo实验运行器，支持测试和全量模式\"\"\"\n",
    "    \n",
    "    # 配置参数\n",
    "    experiment_type = config.get('experiment_type', 'test')\n",
    "    experiment_mode = config.get('experiment_mode', 'simple')  # 'simple' 或 'grouped_by_hinter'\n",
    "    max_turns = config.get('max_turns', 5)\n",
    "    output_dir = config.get('output_dir', 'results')\n",
    "    fixed_word = config.get('fixed_word', None)\n",
    "    \n",
    "    # 创建输出目录\n",
    "    from datetime import datetime\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    if experiment_mode == 'grouped_by_hinter':\n",
    "        return run_grouped_experiment(client, models, dataset, config, timestamp)\n",
    "    else:\n",
    "        return run_simple_experiment(client, models, dataset, config, timestamp)\n",
    "\n",
    "def run_simple_experiment(client, models, dataset, config, timestamp):\n",
    "    \"\"\"简单模式：测试实验，使用固定词汇\"\"\"\n",
    "    experiment_type = config.get('experiment_type', 'test')\n",
    "    output_dir = config.get('output_dir', 'results')\n",
    "    fixed_word = config.get('fixed_word', None)\n",
    "    max_turns = config.get('max_turns', 5)\n",
    "    \n",
    "    # 输出设置\n",
    "    output_path = f\"{output_dir}/test_results_{timestamp}.csv\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"🚀 开始执行{experiment_type}实验...\")\n",
    "    print(f\"📁 输出路径: {output_path}\")\n",
    "    \n",
    "    # 使用固定词汇\n",
    "    if not fixed_word:\n",
    "        fixed_word = random.choice(dataset)\n",
    "    \n",
    "    target_word = fixed_word['target']\n",
    "    taboo_words = fixed_word['taboo']\n",
    "    print(f\"🎯 测试词: {target_word}\")\n",
    "    print(f\"🚫 禁用词: {taboo_words}\")\n",
    "    \n",
    "    total_games = len(models) ** 2  # 每个模型对组合1场游戏\n",
    "    print(f\"📊 总游戏数: {total_games}\")\n",
    "    \n",
    "    all_results = []\n",
    "    game_counter = 0\n",
    "    \n",
    "    # 运行所有模型组合\n",
    "    for hinter_model in models:\n",
    "        for guesser_model in models:\n",
    "            game_counter += 1\n",
    "            pair_name = f\"{hinter_model.split('/')[-1]}→{guesser_model.split('/')[-1]}\"\n",
    "            \n",
    "            print(f\"🔄 游戏 {game_counter}/{total_games} ({game_counter/total_games*100:.1f}%): {pair_name}\")\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            # 执行游戏\n",
    "            game_result = enhanced_play_taboo_game(client, hinter_model, guesser_model, \n",
    "                                                 target_word, taboo_words, max_turns)\n",
    "            \n",
    "            duration = round(time.time() - start_time, 2)\n",
    "            \n",
    "            # 记录结果\n",
    "            result = {\n",
    "                'game_id': game_counter,\n",
    "                'hinter_model': hinter_model,\n",
    "                'guesser_model': guesser_model,\n",
    "                'target_word': target_word,\n",
    "                'category': fixed_word.get('category', 'unknown'),\n",
    "                'taboo_words': '|'.join(taboo_words),\n",
    "                'success': game_result['success'],\n",
    "                'turns_used': game_result['turns'],\n",
    "                'final_guess': game_result['final_guess'],\n",
    "                'failure_reason': game_result.get('failure_reason', None),\n",
    "                'taboo_violation_turn': game_result.get('taboo_violation_turn', None),\n",
    "                'taboo_violation_hint': game_result.get('taboo_violation_hint', None),\n",
    "                'has_taboo_violation': game_result.get('failure_reason') == 'TABOO_VIOLATION',\n",
    "                'all_hints': ' | '.join(game_result['all_hints']),\n",
    "                'all_guesses': ' | '.join(game_result['all_guesses']),\n",
    "                'conversation': ' | '.join(game_result['conversation']),\n",
    "                'total_api_attempts': game_result.get('total_hinter_attempts', 0) + game_result.get('total_guesser_attempts', 0),\n",
    "                'format_errors': ' | '.join(game_result.get('format_errors', [])),\n",
    "                'has_format_errors': len(game_result.get('format_errors', [])) > 0,\n",
    "                'duration_seconds': duration,\n",
    "                'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "            \n",
    "            if 'error' in game_result:\n",
    "                result['error'] = game_result['error']\n",
    "            \n",
    "            all_results.append(result)\n",
    "            \n",
    "            # 显示结果\n",
    "            status = \"✅ 成功\" if game_result['success'] else \"❌ 失败\"\n",
    "            failure_info = \"\"\n",
    "            if not game_result['success'] and game_result.get('failure_reason'):\n",
    "                failure_reason = game_result['failure_reason']\n",
    "                if failure_reason == 'TABOO_VIOLATION':\n",
    "                    failure_info = \" (违反禁用词规则)\"\n",
    "                elif failure_reason == 'FORMAT_FAILURE':\n",
    "                    failure_info = \" (格式错误超3次)\"\n",
    "                elif failure_reason == 'API_FAILURE':\n",
    "                    failure_info = \" (API调用失败)\"\n",
    "                elif failure_reason == 'MAX_TURNS_EXCEEDED':\n",
    "                    failure_info = \" (达到最大轮数)\"\n",
    "            \n",
    "            print(f\"   {status}{failure_info} | {game_result['turns']}轮 | 最终猜测: {game_result['final_guess']}\")\n",
    "            time.sleep(0.5)\n",
    "    \n",
    "    return save_and_analyze_results(all_results, output_path, experiment_type)\n",
    "\n",
    "print(\"✅ 统一实验运行器已定义\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 支持函数已定义\n"
     ]
    }
   ],
   "source": [
    "# 支持函数 - 全量实验和结果分析\n",
    "def run_grouped_experiment(client, models, dataset, config, timestamp):\n",
    "    \"\"\"分组模式：全量实验，按hinter模型分组，遍历所有词汇，每50个游戏保存一个批次文件\"\"\"\n",
    "    experiment_type = config.get('experiment_type', 'formal')\n",
    "    output_dir = config.get('output_dir', 'results')\n",
    "    max_turns = config.get('max_turns', 5)\n",
    "    batch_size = config.get('batch_size', 50)  # 每批次保存的游戏数\n",
    "    \n",
    "    main_exp_dir = f\"{output_dir}/taboo_experiment_zengliang28_20250717_130855\"\n",
    "    os.makedirs(main_exp_dir, exist_ok=True)\n",
    "    print(f\"📁 主实验目录: {main_exp_dir}\")\n",
    "    \n",
    "    # 全量实验配置：每个模型对遍历所有300个词\n",
    "    print(f\"📊 数据集词汇数: {len(dataset)}\")\n",
    "    print(f\"🤖 模型组合数: {len(models)}×{len(models)} = {len(models)**2}\")\n",
    "    print(f\"🎮 总游戏数: {len(dataset) * len(models)**2:,}\")\n",
    "    print(f\"💾 批次大小: 每{batch_size}个游戏保存一个文件\")\n",
    "    \n",
    "    all_experiment_results = []\n",
    "    batch_files = []  # 记录所有批次文件路径\n",
    "    \n",
    "    # 按hinter模型分组执行\n",
    "    for i, hinter_model in enumerate(models, 1):\n",
    "        hinter_name = hinter_model.split('/')[-1]\n",
    "        print(f\"\\\\n🎯 第{i}/{len(models)}组: Hinter = {hinter_name}\")\n",
    "        \n",
    "        # 为每个hinter模型创建子目录\n",
    "        hinter_dir = f\"{main_exp_dir}/{hinter_name}_as_hinter\"\n",
    "        os.makedirs(hinter_dir, exist_ok=True)\n",
    "        \n",
    "        # 运行当前hinter模型与所有guesser模型的组合\n",
    "        hinter_results = []\n",
    "        current_batch = []\n",
    "        total_games_for_hinter = len(models) * len(dataset)\n",
    "        game_counter = 0\n",
    "        batch_counter = 0\n",
    "        \n",
    "        for guesser_model in models:\n",
    "            guesser_name = guesser_model.split('/')[-1]\n",
    "            pair_name = f\"{hinter_name}→{guesser_name}\"\n",
    "            \n",
    "            print(f\"   🔄 运行组合: {pair_name}\")\n",
    "            \n",
    "            # 遍历所有词汇\n",
    "            for word_idx, word_data in enumerate(dataset):\n",
    "                game_counter += 1\n",
    "                \n",
    "                target_word = word_data['target']\n",
    "                taboo_words = word_data['taboo']\n",
    "                \n",
    "                start_time = time.time()\n",
    "                \n",
    "                # 执行游戏\n",
    "                game_result = enhanced_play_taboo_game(client, hinter_model, guesser_model, \n",
    "                                                     target_word, taboo_words, max_turns)\n",
    "                \n",
    "                duration = round(time.time() - start_time, 2)\n",
    "                \n",
    "                # 记录结果\n",
    "                result = {\n",
    "                    'game_id': f\"{hinter_name}_{game_counter}\",\n",
    "                    'word_index': word_idx,\n",
    "                    'hinter_model': hinter_model,\n",
    "                    'guesser_model': guesser_model,\n",
    "                    'target_word': target_word,\n",
    "                    'category': word_data.get('category', 'unknown'),\n",
    "                    'taboo_words': '|'.join(taboo_words),\n",
    "                    'success': game_result['success'],\n",
    "                    'turns_used': game_result['turns'],\n",
    "                    'final_guess': game_result['final_guess'],\n",
    "                    'failure_reason': game_result.get('failure_reason', None),\n",
    "                    'taboo_violation_turn': game_result.get('taboo_violation_turn', None),\n",
    "                    'taboo_violation_hint': game_result.get('taboo_violation_hint', None),\n",
    "                    'has_taboo_violation': game_result.get('failure_reason') == 'TABOO_VIOLATION',\n",
    "                    'all_hints': ' | '.join(game_result['all_hints']),\n",
    "                    'all_guesses': ' | '.join(game_result['all_guesses']),\n",
    "                    'conversation': ' | '.join(game_result['conversation']),\n",
    "                    'total_api_attempts': game_result.get('total_hinter_attempts', 0) + game_result.get('total_guesser_attempts', 0),\n",
    "                    'format_errors': ' | '.join(game_result.get('format_errors', [])),\n",
    "                    'has_format_errors': len(game_result.get('format_errors', [])) > 0,\n",
    "                    'duration_seconds': duration,\n",
    "                    'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                }\n",
    "                \n",
    "                if 'error' in game_result:\n",
    "                    result['error'] = game_result['error']\n",
    "                \n",
    "                hinter_results.append(result)\n",
    "                current_batch.append(result)\n",
    "                all_experiment_results.append(result)\n",
    "                \n",
    "                # 每batch_size个游戏保存一个批次文件\n",
    "                if len(current_batch) >= batch_size:\n",
    "                    batch_counter += 1\n",
    "                    batch_file_path = f\"{hinter_dir}/batch_{batch_counter:03d}.csv\"\n",
    "                    batch_df = pd.DataFrame(current_batch)\n",
    "                    batch_df.to_csv(batch_file_path, index=False, encoding='utf-8')\n",
    "                    batch_files.append(batch_file_path)\n",
    "                    \n",
    "                    # 进度显示\n",
    "                    progress = (game_counter / total_games_for_hinter) * 100\n",
    "                    success_in_batch = sum(r['success'] for r in current_batch)\n",
    "                    batch_success_rate = success_in_batch / len(current_batch) * 100\n",
    "                    \n",
    "                    print(f\"      💾 批次{batch_counter:03d}: {len(current_batch)}场游戏已保存\")\n",
    "                    print(f\"      📈 进度: {game_counter}/{total_games_for_hinter} ({progress:.1f}%)\")\n",
    "                    print(f\"      📊 批次成功率: {batch_success_rate:.1f}%\")\n",
    "                    \n",
    "                    # 清空当前批次\n",
    "                    current_batch = []\n",
    "                \n",
    "                time.sleep(0.3)  # API调用间隔\n",
    "        \n",
    "        # 保存剩余的游戏（如果有）\n",
    "        if current_batch:\n",
    "            batch_counter += 1\n",
    "            batch_file_path = f\"{hinter_dir}/batch_{batch_counter:03d}.csv\"\n",
    "            batch_df = pd.DataFrame(current_batch)\n",
    "            batch_df.to_csv(batch_file_path, index=False, encoding='utf-8')\n",
    "            batch_files.append(batch_file_path)\n",
    "            \n",
    "            success_in_batch = sum(r['success'] for r in current_batch)\n",
    "            batch_success_rate = success_in_batch / len(current_batch) * 100\n",
    "            print(f\"      💾 最后批次{batch_counter:03d}: {len(current_batch)}场游戏已保存\")\n",
    "            print(f\"      📊 批次成功率: {batch_success_rate:.1f}%\")\n",
    "        \n",
    "        # 保存当前hinter模型的汇总结果\n",
    "        hinter_df = pd.DataFrame(hinter_results)\n",
    "        hinter_csv_path = f\"{hinter_dir}/{hinter_name}_summary.csv\"\n",
    "        hinter_df.to_csv(hinter_csv_path, index=False, encoding='utf-8')\n",
    "        \n",
    "        # 统计当前hinter模型的结果\n",
    "        success_count = sum(r['success'] for r in hinter_results)\n",
    "        success_rate = success_count / len(hinter_results) * 100\n",
    "        \n",
    "        print(f\"   ✅ {hinter_name}组完成: {len(hinter_results)}场游戏, 成功率: {success_rate:.1f}%\")\n",
    "        print(f\"   💾 汇总结果已保存: {hinter_csv_path}\")\n",
    "        print(f\"   📁 批次文件数: {batch_counter}个\")\n",
    "        \n",
    "        # 失败原因统计\n",
    "        print_failure_summary(hinter_df)\n",
    "    \n",
    "    # 保存全量实验的最终汇总结果\n",
    "    final_csv_path = f\"{main_exp_dir}/complete_experiment_results.csv\"\n",
    "    print(f\"\\n🔄 开始生成最终汇总文件...\")\n",
    "    print(f\"📊 总批次文件数: {len(batch_files)}\")\n",
    "    \n",
    "    return save_and_analyze_grouped_results(all_experiment_results, final_csv_path, main_exp_dir, models, batch_files)\n",
    "\n",
    "def save_and_analyze_results(all_results, output_path, experiment_type):\n",
    "    \"\"\"保存并分析实验结果\"\"\"\n",
    "    if all_results:\n",
    "        df = pd.DataFrame(all_results)\n",
    "        df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "        \n",
    "        # 统计分析\n",
    "        total_success = sum(r['success'] for r in all_results)\n",
    "        success_rate = total_success / len(all_results) * 100\n",
    "        \n",
    "        print(f\"\\\\n✅ {experiment_type}实验完成！\")\n",
    "        print(f\"📁 结果文件: {output_path}\")\n",
    "        print(f\"📊 总游戏数: {len(all_results):,}\")\n",
    "        print(f\"📈 成功率: {success_rate:.1f}%\")\n",
    "        \n",
    "        print_failure_summary(df)\n",
    "        return df\n",
    "    else:\n",
    "        print(\"❌ 没有成功的实验记录\")\n",
    "        return None\n",
    "\n",
    "def save_and_analyze_grouped_results(all_experiment_results, final_csv_path, main_exp_dir, models, batch_files=None):\n",
    "    \"\"\"保存并分析分组实验结果\"\"\"\n",
    "    if all_experiment_results:\n",
    "        final_df = pd.DataFrame(all_experiment_results)\n",
    "        final_df.to_csv(final_csv_path, index=False, encoding='utf-8')\n",
    "        \n",
    "        # 全量实验统计\n",
    "        total_success = sum(r['success'] for r in all_experiment_results)\n",
    "        total_games = len(all_experiment_results)\n",
    "        overall_success_rate = total_success / total_games * 100\n",
    "        \n",
    "        print(f\"\\\\n🎉 全量实验完成！\")\n",
    "        print(f\"📁 最终汇总文件: {final_csv_path}\")\n",
    "        print(f\"📊 总游戏数: {total_games:,}场\")\n",
    "        print(f\"📈 整体成功率: {overall_success_rate:.1f}%\")\n",
    "        \n",
    "        if batch_files:\n",
    "            print(f\"📦 批次文件数: {len(batch_files)}个\")\n",
    "            print(f\"💾 平均每批次: {total_games / len(batch_files):.1f}场游戏\")\n",
    "        \n",
    "        # 按hinter模型的成功率统计\n",
    "        print(f\"\\\\n📊 各Hinter模型成功率:\")\n",
    "        for model in models:\n",
    "            model_name = model.split('/')[-1]\n",
    "            model_games = final_df[final_df['hinter_model'] == model]\n",
    "            model_success = sum(model_games['success'])\n",
    "            model_rate = model_success / len(model_games) * 100 if len(model_games) > 0 else 0\n",
    "            print(f\"   {model_name}: {model_success}/{len(model_games)} ({model_rate:.1f}%)\")\n",
    "        \n",
    "        print_failure_summary(final_df, prefix=\"整体\")\n",
    "        print(f\"\\\\n💾 所有数据已保存至目录: {main_exp_dir}\")\n",
    "        \n",
    "        # 批次文件总结\n",
    "        if batch_files:\n",
    "            print(f\"\\\\n📂 批次文件详情:\")\n",
    "            for batch_file in batch_files:\n",
    "                file_name = os.path.basename(batch_file)\n",
    "                print(f\"   📄 {file_name}\")\n",
    "        \n",
    "        return final_df\n",
    "    else:\n",
    "        print(\"❌ 全量实验失败，没有成功的游戏记录\")\n",
    "        return None\n",
    "\n",
    "def print_failure_summary(df, prefix=\"\"):\n",
    "    \"\"\"打印失败原因统计\"\"\"\n",
    "    failed_games = df[df['success'] == False]\n",
    "    if len(failed_games) > 0:\n",
    "        title = f\"{prefix}失败原因统计:\" if prefix else \"失败原因统计:\"\n",
    "        print(f\"\\\\n📉 {title}\")\n",
    "        failure_counts = failed_games['failure_reason'].value_counts()\n",
    "        for reason, count in failure_counts.items():\n",
    "            percentage = count / len(failed_games) * 100\n",
    "            if reason == 'TABOO_VIOLATION':\n",
    "                print(f\"   🚫 违反禁用词规则: {count} 场 ({percentage:.1f}%)\")\n",
    "            elif reason == 'FORMAT_FAILURE':\n",
    "                print(f\"   🔤 格式错误超限: {count} 场 ({percentage:.1f}%)\")\n",
    "            elif reason == 'API_FAILURE':\n",
    "                print(f\"   🌐 API调用失败: {count} 场 ({percentage:.1f}%)\")\n",
    "            elif reason == 'MAX_TURNS_EXCEEDED':\n",
    "                print(f\"   ⏱️ 轮数耗尽: {count} 场 ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"✅ 支持函数已定义\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 5. 全量实验控制器 - 批次保存机制\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 开始执行测试实验...\n",
      "🚀 开始执行test实验...\n",
      "📁 输出路径: results/test_results_20250711_232922.csv\n",
      "🎯 测试词: colouration\n",
      "🚫 禁用词: ['colour', 'timber', 'timbre', 'capture', 'color']\n",
      "📊 总游戏数: 16\n",
      "🔄 游戏 1/16 (6.2%): gpt-4o→gpt-4o\n",
      "   ✅ 成功 | 4轮 | 最终猜测: colouration\n",
      "🔄 游戏 2/16 (12.5%): gpt-4o→gemini-2.5-pro\n",
      "   ✅ 成功 | 2轮 | 最终猜测: colouration\n",
      "🔄 游戏 3/16 (18.8%): gpt-4o→deepseek-chat-v3-0324\n",
      "   ✅ 成功 | 2轮 | 最终猜测: colouration\n",
      "🔄 游戏 4/16 (25.0%): gpt-4o→claude-sonnet-4\n",
      "   ✅ 成功 | 2轮 | 最终猜测: colouration\n",
      "🔄 游戏 5/16 (31.2%): gemini-2.5-pro→gpt-4o\n",
      "   ✅ 成功 | 2轮 | 最终猜测: colouration\n",
      "🔄 游戏 6/16 (37.5%): gemini-2.5-pro→gemini-2.5-pro\n",
      "   ✅ 成功 | 1轮 | 最终猜测: colouration\n",
      "🔄 游戏 7/16 (43.8%): gemini-2.5-pro→deepseek-chat-v3-0324\n",
      "   ✅ 成功 | 2轮 | 最终猜测: colouration\n",
      "🔄 游戏 8/16 (50.0%): gemini-2.5-pro→claude-sonnet-4\n",
      "   ✅ 成功 | 1轮 | 最终猜测: colouration\n",
      "🔄 游戏 9/16 (56.2%): deepseek-chat-v3-0324→gpt-4o\n",
      "   ✅ 成功 | 4轮 | 最终猜测: colouration\n",
      "🔄 游戏 10/16 (62.5%): deepseek-chat-v3-0324→gemini-2.5-pro\n",
      "   ✅ 成功 | 2轮 | 最终猜测: colouration\n",
      "🔄 游戏 11/16 (68.8%): deepseek-chat-v3-0324→deepseek-chat-v3-0324\n",
      "   ✅ 成功 | 3轮 | 最终猜测: colouration\n",
      "🔄 游戏 12/16 (75.0%): deepseek-chat-v3-0324→claude-sonnet-4\n",
      "   ✅ 成功 | 1轮 | 最终猜测: colouration\n",
      "🔄 游戏 13/16 (81.2%): claude-sonnet-4→gpt-4o\n",
      "   ✅ 成功 | 1轮 | 最终猜测: colouration\n",
      "🔄 游戏 14/16 (87.5%): claude-sonnet-4→gemini-2.5-pro\n",
      "   ✅ 成功 | 1轮 | 最终猜测: colouration\n",
      "🔄 游戏 15/16 (93.8%): claude-sonnet-4→deepseek-chat-v3-0324\n",
      "   ✅ 成功 | 5轮 | 最终猜测: colouration\n",
      "🔄 游戏 16/16 (100.0%): claude-sonnet-4→claude-sonnet-4\n",
      "   ✅ 成功 | 3轮 | 最终猜测: colouration\n",
      "\\n✅ test实验完成！\n",
      "📁 结果文件: results/test_results_20250711_232922.csv\n",
      "📊 总游戏数: 16\n",
      "📈 成功率: 100.0%\n",
      "✅ 测试实验完成，共16场游戏\n",
      "\n",
      "📊 测试结果统计:\n",
      "   gpt-4o: Hinter 4/4, Guesser 4/4\n",
      "   gemini-2.5-pro: Hinter 4/4, Guesser 4/4\n",
      "   deepseek-chat-v3-0324: Hinter 4/4, Guesser 4/4\n",
      "   claude-sonnet-4: Hinter 4/4, Guesser 4/4\n"
     ]
    }
   ],
   "source": [
    "# 执行测试实验\n",
    "print(\"🧪 开始执行测试实验...\")\n",
    "\n",
    "# 选择一个测试词\n",
    "test_word_data = random.choice(dataset)\n",
    "\n",
    "config = {\n",
    "    'experiment_type': 'test',\n",
    "    'experiment_mode': 'simple',  # 简单模式\n",
    "    'max_turns': 5,\n",
    "    'output_dir': 'results',\n",
    "    'fixed_word': test_word_data\n",
    "}\n",
    "\n",
    "# 运行测试实验\n",
    "test_results = run_taboo_experiment(client, TEST_MODELS, dataset, config)\n",
    "\n",
    "if test_results is not None:\n",
    "    print(f\"✅ 测试实验完成，共{len(test_results)}场游戏\")\n",
    "    \n",
    "    # 显示测试结果统计\n",
    "    print(\"\\n📊 测试结果统计:\")\n",
    "    for model in TEST_MODELS:\n",
    "        model_name = model.split('/')[-1]\n",
    "        model_as_hinter = test_results[test_results['hinter_model'] == model]\n",
    "        model_as_guesser = test_results[test_results['guesser_model'] == model]\n",
    "        \n",
    "        hinter_success = sum(model_as_hinter['success']) if len(model_as_hinter) > 0 else 0\n",
    "        guesser_success = sum(model_as_guesser['success']) if len(model_as_guesser) > 0 else 0\n",
    "        \n",
    "        print(f\"   {model_name}: Hinter {hinter_success}/4, Guesser {guesser_success}/4\")\n",
    "else:\n",
    "    print(\"❌ 测试实验失败\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 7. 全量实验（按hinter模型分组，批次保存）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 执行全量实验（按hinter模型分组，批次保存）\n",
    "print(\"🚀 开始执行全量实验...\")\n",
    "print(\"💡 新功能：批次保存机制\")\n",
    "print(\"   • 每300个游戏自动保存一个批次文件\")\n",
    "print(\"   • 即使实验中断，已完成的批次数据也会保留\")\n",
    "print(\"   • 方便监控实验进度和调试问题\")\n",
    "\n",
    "config = {\n",
    "    'experiment_type': 'formal',\n",
    "    'experiment_mode': 'grouped_by_hinter',  # 分组模式\n",
    "    'max_turns': 5,\n",
    "    'output_dir': 'results',\n",
    "    'batch_size': 300  # 每300个游戏保存一个批次文件\n",
    "}\n",
    "\n",
    "# 运行全量实验\n",
    "formal_results = run_taboo_experiment(client, TEST_MODELS, dataset, config)\n",
    "\n",
    "if formal_results is not None:\n",
    "    print(f\"\\\\n🎉 全量实验完成！共{len(formal_results):,}场游戏\")\n",
    "    print(\"\\\\n💡 关键改进：\")\n",
    "    print(\"   ✅ 遍历所有300个词汇，而非随机选择\")\n",
    "    print(\"   ✅ 按hinter模型分组执行和保存\")\n",
    "    print(\"   ✅ 统一的实验架构，测试和全量共享代码\")\n",
    "    print(\"   ✅ 严格的taboo words违规检查\")\n",
    "    print(\"   ✅ 批次保存机制，每300个游戏保存一个文件\")\n",
    "    print(\"   ✅ 防止实验中断数据丢失，支持断点续传\")\n",
    "else:\n",
    "    print(\"❌ 全量实验失败\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 8. Quick80 WordNet数据集实验\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 开始执行Quick80 WordNet数据集实验...\n",
      "✅ Quick80数据集加载成功: 28 条记录\n",
      "📁 数据集路径: quick80_from_wordnet_only.json\n",
      "\n",
      "📋 Quick80数据样本:\n",
      "   目标词: obtrusively\n",
      "   词性: adv\n",
      "   禁用词: ['manner', 'obtrusive', 'unobtrusively', 'noticeably', 'intrusively']\n",
      "   类别: general\n",
      "   定义: in an obtrusive manner\n",
      "\n",
      "📊 Quick80数据集统计:\n",
      "🏷️ 类别分布:\n",
      "   general: 28 条 (100.0%)\n",
      "\n",
      "📝 词性分布:\n",
      "   adv: 20 条 (71.4%)\n",
      "   verb: 8 条 (28.6%)\n",
      "\n",
      "🚫 禁用词统计:\n",
      "   平均数量: 5.0\n",
      "   范围: 5 - 5\n",
      "\n",
      "🎲 设置随机种子为 42，确保实验可复现\n"
     ]
    }
   ],
   "source": [
    "# 执行Quick80 WordNet数据集实验\n",
    "print(\"🧪 开始执行Quick80 WordNet数据集实验...\")\n",
    "\n",
    "# 加载Quick80数据集\n",
    "QUICK80_DATASET_PATH = \"quick80_from_wordnet_only.json\"\n",
    "\n",
    "def load_quick80_dataset(dataset_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"加载Quick80 WordNet数据集\"\"\"\n",
    "    with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "        dataset = json.load(f)\n",
    "    return dataset\n",
    "\n",
    "# 加载Quick80数据集\n",
    "quick80_dataset = load_quick80_dataset(QUICK80_DATASET_PATH)\n",
    "print(f\"✅ Quick80数据集加载成功: {len(quick80_dataset)} 条记录\")\n",
    "print(f\"📁 数据集路径: {QUICK80_DATASET_PATH}\")\n",
    "\n",
    "# 显示数据集样本\n",
    "if quick80_dataset:\n",
    "    sample = quick80_dataset[0]\n",
    "    print(f\"\\n📋 Quick80数据样本:\")\n",
    "    print(f\"   目标词: {sample['target']}\")\n",
    "    print(f\"   词性: {sample['part_of_speech']}\")\n",
    "    print(f\"   禁用词: {sample['taboo']}\")\n",
    "    print(f\"   类别: {sample.get('category', 'N/A')}\")\n",
    "    if sample.get('senses'):\n",
    "        print(f\"   定义: {sample['senses'][0].get('definition', 'N/A')}\")\n",
    "\n",
    "# 统计Quick80数据集信息\n",
    "print(f\"\\n📊 Quick80数据集统计:\")\n",
    "categories = {}\n",
    "pos_counts = {}\n",
    "taboo_counts = []\n",
    "\n",
    "for item in quick80_dataset:\n",
    "    # 统计类别\n",
    "    category = item.get('category', 'unknown')\n",
    "    categories[category] = categories.get(category, 0) + 1\n",
    "    \n",
    "    # 统计词性\n",
    "    pos = item.get('part_of_speech', 'unknown')\n",
    "    pos_counts[pos] = pos_counts.get(pos, 0) + 1\n",
    "    \n",
    "    # 统计禁用词数量\n",
    "    taboo_counts.append(len(item.get('taboo', [])))\n",
    "\n",
    "print(f\"🏷️ 类别分布:\")\n",
    "for category, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):\n",
    "    percentage = count / len(quick80_dataset) * 100\n",
    "    print(f\"   {category}: {count} 条 ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\n📝 词性分布:\")\n",
    "for pos, count in sorted(pos_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    percentage = count / len(quick80_dataset) * 100\n",
    "    print(f\"   {pos}: {count} 条 ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\n🚫 禁用词统计:\")\n",
    "print(f\"   平均数量: {sum(taboo_counts) / len(taboo_counts):.1f}\")\n",
    "print(f\"   范围: {min(taboo_counts)} - {max(taboo_counts)}\")\n",
    "\n",
    "print(f\"\\n🎲 设置随机种子为 42，确保实验可复现\")\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 准备执行Quick80数据集全量实验...\n",
      "🔄 实验模式: 全量遍历所有词汇\n",
      "\n",
      "📈 实验规模分析:\n",
      "   • 词汇总数: 28 个\n",
      "   • 词性分布: {'adv': 20, 'verb': 8}\n",
      "   • 模型数量: 4 个\n",
      "   • 每个词汇游戏数: 16 场\n",
      "   • 总游戏数: 448 场\n",
      "\n",
      "✅ API客户端已就绪\n",
      "🤖 参与实验的模型:\n",
      "   1. openai/gpt-4o\n",
      "   2. google/gemini-2.5-pro\n",
      "   3. deepseek/deepseek-chat-v3-0324\n",
      "   4. anthropic/claude-sonnet-4\n",
      "\n",
      "🎮 实验执行计划:\n",
      "   • 按Hinter模型分组执行\n",
      "   • 每个Hinter模型: 4 × 28 = 112 场游戏\n",
      "   • 批次保存: 每50场游戏保存一个文件\n",
      "   • 预计批次数: ~9 个文件\n",
      "\n",
      "📋 样本词汇预览:\n",
      "   1. dispensed (verb) - 禁用词: ['bestow', 'parcel', 'allot']...\n",
      "   2. past (adv) - 禁用词: ['given', 'point', 'pass']...\n",
      "   3. obtrusively (adv) - 禁用词: ['manner', 'obtrusive', 'unobtrusively']...\n"
     ]
    }
   ],
   "source": [
    "# Quick80全量实验预处理\n",
    "print(\"🚀 准备执行Quick80数据集全量实验...\")\n",
    "print(\"🔄 实验模式: 全量遍历所有词汇\")\n",
    "\n",
    "print(f\"\\n📈 实验规模分析:\")\n",
    "print(f\"   • 词汇总数: {len(quick80_dataset)} 个\")\n",
    "print(f\"   • 词性分布: {dict(sorted(pos_counts.items(), key=lambda x: x[1], reverse=True))}\")\n",
    "print(f\"   • 模型数量: {len(TEST_MODELS)} 个\")\n",
    "print(f\"   • 每个词汇游戏数: {len(TEST_MODELS)**2} 场\")\n",
    "print(f\"   • 总游戏数: {len(quick80_dataset) * len(TEST_MODELS)**2:,} 场\")\n",
    "\n",
    "# 检查API客户端是否可用\n",
    "if client is None:\n",
    "    print(\"❌ API客户端未初始化，无法执行实验\")\n",
    "else:\n",
    "    print(f\"\\n✅ API客户端已就绪\")\n",
    "    print(f\"🤖 参与实验的模型:\")\n",
    "    for i, model in enumerate(TEST_MODELS, 1):\n",
    "        print(f\"   {i}. {model}\")\n",
    "    \n",
    "    print(f\"\\n🎮 实验执行计划:\")\n",
    "    print(f\"   • 按Hinter模型分组执行\")\n",
    "    print(f\"   • 每个Hinter模型: {len(TEST_MODELS)} × {len(quick80_dataset)} = {len(TEST_MODELS) * len(quick80_dataset)} 场游戏\")\n",
    "    print(f\"   • 批次保存: 每50场游戏保存一个文件\")\n",
    "    print(f\"   • 预计批次数: ~{(len(quick80_dataset) * len(TEST_MODELS)**2) // 50 + 1} 个文件\")\n",
    "    \n",
    "    # 显示一些样本词汇\n",
    "    print(f\"\\n📋 样本词汇预览:\")\n",
    "    sample_words = random.sample(quick80_dataset, min(3, len(quick80_dataset)))\n",
    "    for i, word in enumerate(sample_words, 1):\n",
    "        print(f\"   {i}. {word['target']} ({word['part_of_speech']}) - 禁用词: {word['taboo'][:3]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 开始执行Quick80全量实验...\n",
      "💡 实验规模:\n",
      "   • 数据集规模: 28 个词汇\n",
      "   • 模型组合: 4×4 = 16\n",
      "   • 总游戏数: 448 场\n",
      "   • 预计时间: ~3.7 分钟\n",
      "\n",
      "📋 全量实验配置:\n",
      "   实验类型: quick80_full\n",
      "   实验模式: grouped_by_hinter\n",
      "   最大轮数: 5\n",
      "   批次大小: 50 游戏/批次\n",
      "   输出目录: results\n",
      "📁 主实验目录: results/taboo_experiment_zengliang28_20250717_130855\n",
      "📊 数据集词汇数: 28\n",
      "🤖 模型组合数: 4×4 = 16\n",
      "🎮 总游戏数: 448\n",
      "💾 批次大小: 每50个游戏保存一个文件\n",
      "\\n🎯 第1/4组: Hinter = gpt-4o\n",
      "   🔄 运行组合: gpt-4o→gpt-4o\n",
      "   🔄 运行组合: gpt-4o→gemini-2.5-pro\n",
      "      💾 批次001: 50场游戏已保存\n",
      "      📈 进度: 50/112 (44.6%)\n",
      "      📊 批次成功率: 52.0%\n",
      "   🔄 运行组合: gpt-4o→deepseek-chat-v3-0324\n",
      "   🔄 运行组合: gpt-4o→claude-sonnet-4\n",
      "      💾 批次002: 50场游戏已保存\n",
      "      📈 进度: 100/112 (89.3%)\n",
      "      📊 批次成功率: 60.0%\n",
      "      💾 最后批次003: 12场游戏已保存\n",
      "      📊 批次成功率: 83.3%\n",
      "   ✅ gpt-4o组完成: 112场游戏, 成功率: 58.9%\n",
      "   💾 汇总结果已保存: results/taboo_experiment_zengliang28_20250717_130855/gpt-4o_as_hinter/gpt-4o_summary.csv\n",
      "   📁 批次文件数: 3个\n",
      "\\n📉 失败原因统计:\n",
      "   ⏱️ 轮数耗尽: 31 场 (67.4%)\n",
      "   🔤 格式错误超限: 9 场 (19.6%)\n",
      "   🚫 违反禁用词规则: 6 场 (13.0%)\n",
      "\\n🎯 第2/4组: Hinter = gemini-2.5-pro\n",
      "   🔄 运行组合: gemini-2.5-pro→gpt-4o\n",
      "   🔄 运行组合: gemini-2.5-pro→gemini-2.5-pro\n",
      "      💾 批次001: 50场游戏已保存\n",
      "      📈 进度: 50/112 (44.6%)\n",
      "      📊 批次成功率: 94.0%\n",
      "   🔄 运行组合: gemini-2.5-pro→deepseek-chat-v3-0324\n",
      "   🔄 运行组合: gemini-2.5-pro→claude-sonnet-4\n",
      "      💾 批次002: 50场游戏已保存\n",
      "      📈 进度: 100/112 (89.3%)\n",
      "      📊 批次成功率: 86.0%\n",
      "      💾 最后批次003: 12场游戏已保存\n",
      "      📊 批次成功率: 100.0%\n",
      "   ✅ gemini-2.5-pro组完成: 112场游戏, 成功率: 91.1%\n",
      "   💾 汇总结果已保存: results/taboo_experiment_zengliang28_20250717_130855/gemini-2.5-pro_as_hinter/gemini-2.5-pro_summary.csv\n",
      "   📁 批次文件数: 3个\n",
      "\\n📉 失败原因统计:\n",
      "   ⏱️ 轮数耗尽: 6 场 (60.0%)\n",
      "   🔤 格式错误超限: 3 场 (30.0%)\n",
      "   🚫 违反禁用词规则: 1 场 (10.0%)\n",
      "\\n🎯 第3/4组: Hinter = deepseek-chat-v3-0324\n",
      "   🔄 运行组合: deepseek-chat-v3-0324→gpt-4o\n",
      "   🔄 运行组合: deepseek-chat-v3-0324→gemini-2.5-pro\n",
      "      💾 批次001: 50场游戏已保存\n",
      "      📈 进度: 50/112 (44.6%)\n",
      "      📊 批次成功率: 68.0%\n",
      "   🔄 运行组合: deepseek-chat-v3-0324→deepseek-chat-v3-0324\n",
      "   🔄 运行组合: deepseek-chat-v3-0324→claude-sonnet-4\n",
      "      💾 批次002: 50场游戏已保存\n",
      "      📈 进度: 100/112 (89.3%)\n",
      "      📊 批次成功率: 60.0%\n",
      "      💾 最后批次003: 12场游戏已保存\n",
      "      📊 批次成功率: 91.7%\n",
      "   ✅ deepseek-chat-v3-0324组完成: 112场游戏, 成功率: 67.0%\n",
      "   💾 汇总结果已保存: results/taboo_experiment_zengliang28_20250717_130855/deepseek-chat-v3-0324_as_hinter/deepseek-chat-v3-0324_summary.csv\n",
      "   📁 批次文件数: 3个\n",
      "\\n📉 失败原因统计:\n",
      "   ⏱️ 轮数耗尽: 31 场 (83.8%)\n",
      "   🚫 违反禁用词规则: 5 场 (13.5%)\n",
      "   🔤 格式错误超限: 1 场 (2.7%)\n",
      "\\n🎯 第4/4组: Hinter = claude-sonnet-4\n",
      "   🔄 运行组合: claude-sonnet-4→gpt-4o\n",
      "   🔄 运行组合: claude-sonnet-4→gemini-2.5-pro\n",
      "      💾 批次001: 50场游戏已保存\n",
      "      📈 进度: 50/112 (44.6%)\n",
      "      📊 批次成功率: 86.0%\n",
      "   🔄 运行组合: claude-sonnet-4→deepseek-chat-v3-0324\n",
      "   🔄 运行组合: claude-sonnet-4→claude-sonnet-4\n",
      "      💾 批次002: 50场游戏已保存\n",
      "      📈 进度: 100/112 (89.3%)\n",
      "      📊 批次成功率: 92.0%\n",
      "      💾 最后批次003: 12场游戏已保存\n",
      "      📊 批次成功率: 91.7%\n",
      "   ✅ claude-sonnet-4组完成: 112场游戏, 成功率: 89.3%\n",
      "   💾 汇总结果已保存: results/taboo_experiment_zengliang28_20250717_130855/claude-sonnet-4_as_hinter/claude-sonnet-4_summary.csv\n",
      "   📁 批次文件数: 3个\n",
      "\\n📉 失败原因统计:\n",
      "   🚫 违反禁用词规则: 7 场 (58.3%)\n",
      "   ⏱️ 轮数耗尽: 4 场 (33.3%)\n",
      "   🔤 格式错误超限: 1 场 (8.3%)\n",
      "\n",
      "🔄 开始生成最终汇总文件...\n",
      "📊 总批次文件数: 12\n",
      "\\n🎉 全量实验完成！\n",
      "📁 最终汇总文件: results/taboo_experiment_zengliang28_20250717_130855/complete_experiment_results.csv\n",
      "📊 总游戏数: 448场\n",
      "📈 整体成功率: 76.6%\n",
      "📦 批次文件数: 12个\n",
      "💾 平均每批次: 37.3场游戏\n",
      "\\n📊 各Hinter模型成功率:\n",
      "   gpt-4o: 66/112 (58.9%)\n",
      "   gemini-2.5-pro: 102/112 (91.1%)\n",
      "   deepseek-chat-v3-0324: 75/112 (67.0%)\n",
      "   claude-sonnet-4: 100/112 (89.3%)\n",
      "\\n📉 整体失败原因统计:\n",
      "   ⏱️ 轮数耗尽: 72 场 (68.6%)\n",
      "   🚫 违反禁用词规则: 19 场 (18.1%)\n",
      "   🔤 格式错误超限: 14 场 (13.3%)\n",
      "\\n💾 所有数据已保存至目录: results/taboo_experiment_zengliang28_20250717_130855\n",
      "\\n📂 批次文件详情:\n",
      "   📄 batch_001.csv\n",
      "   📄 batch_002.csv\n",
      "   📄 batch_003.csv\n",
      "   📄 batch_001.csv\n",
      "   📄 batch_002.csv\n",
      "   📄 batch_003.csv\n",
      "   📄 batch_001.csv\n",
      "   📄 batch_002.csv\n",
      "   📄 batch_003.csv\n",
      "   📄 batch_001.csv\n",
      "   📄 batch_002.csv\n",
      "   📄 batch_003.csv\n",
      "\n",
      "🎉 Quick80全量实验完成！\n",
      "📊 实验规模总结: 448 场游戏\n",
      "📈 总体成功率: 343/448 (76.6%)\n",
      "\n",
      "🎭 各Hinter模型表现:\n",
      "   gpt-4o: 66/112 (58.9%)\n",
      "   gemini-2.5-pro: 102/112 (91.1%)\n",
      "   deepseek-chat-v3-0324: 75/112 (67.0%)\n",
      "   claude-sonnet-4: 100/112 (89.3%)\n",
      "\n",
      "🔍 各Guesser模型表现:\n",
      "   gpt-4o: 85/112 (75.9%)\n",
      "   gemini-2.5-pro: 89/112 (79.5%)\n",
      "   deepseek-chat-v3-0324: 80/112 (71.4%)\n",
      "   claude-sonnet-4: 89/112 (79.5%)\n",
      "\n",
      "📝 按词性分析成功率:\n",
      "   adv: 219/320 (68.4%)\n",
      "   verb: 124/128 (96.9%)\n",
      "\n",
      "❌ 失败原因分析 (105 场失败):\n",
      "   ⏱️ 轮数耗尽: 72 场 (68.6%)\n",
      "   🚫 违反禁用词规则: 19 场 (18.1%)\n",
      "   🔤 格式错误超限: 14 场 (13.3%)\n",
      "\n",
      "🔄 游戏轮数效率分析:\n",
      "   平均轮数: 1.95 轮\n",
      "   轮数分布:\n",
      "     1轮: 155 场 (45.2%)\n",
      "     2轮: 102 场 (29.7%)\n",
      "     3轮: 47 场 (13.7%)\n",
      "     4轮: 27 场 (7.9%)\n",
      "     5轮: 12 场 (3.5%)\n",
      "\n",
      "💾 实验数据保存信息:\n",
      "   📁 主目录: results/taboo_experiment_[timestamp]/\n",
      "   📄 按Hinter模型分组的批次文件\n",
      "   📋 完整汇总文件: complete_experiment_results.csv\n",
      "   🔍 建议查看各Hinter模型的子目录获取详细结果\n"
     ]
    }
   ],
   "source": [
    "# 执行Quick80全量实验\n",
    "if client is not None:\n",
    "    print(\"🚀 开始执行Quick80全量实验...\")\n",
    "    print(\"💡 实验规模:\")\n",
    "    print(f\"   • 数据集规模: {len(quick80_dataset)} 个词汇\")\n",
    "    print(f\"   • 模型组合: {len(TEST_MODELS)}×{len(TEST_MODELS)} = {len(TEST_MODELS)**2}\")\n",
    "    print(f\"   • 总游戏数: {len(quick80_dataset) * len(TEST_MODELS)**2:,} 场\")\n",
    "    print(f\"   • 预计时间: ~{len(quick80_dataset) * len(TEST_MODELS)**2 * 0.5 / 60:.1f} 分钟\")\n",
    "    \n",
    "    # 配置Quick80全量实验参数\n",
    "    quick80_full_config = {\n",
    "        'experiment_type': 'quick80_full',\n",
    "        'experiment_mode': 'grouped_by_hinter',  # 使用分组模式进行全量实验\n",
    "        'max_turns': 5,\n",
    "        'output_dir': 'results',\n",
    "        'batch_size': 50  # 每50个游戏保存一个批次文件\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n📋 全量实验配置:\")\n",
    "    print(f\"   实验类型: {quick80_full_config['experiment_type']}\")\n",
    "    print(f\"   实验模式: {quick80_full_config['experiment_mode']}\")\n",
    "    print(f\"   最大轮数: {quick80_full_config['max_turns']}\")\n",
    "    print(f\"   批次大小: {quick80_full_config['batch_size']} 游戏/批次\")\n",
    "    print(f\"   输出目录: {quick80_full_config['output_dir']}\")\n",
    "    \n",
    "    # 运行Quick80全量实验，复用现有的实验框架\n",
    "    quick80_results = run_taboo_experiment(client, TEST_MODELS, quick80_dataset, quick80_full_config)\n",
    "    \n",
    "    if quick80_results is not None:\n",
    "        print(f\"\\n🎉 Quick80全量实验完成！\")\n",
    "        print(f\"📊 实验规模总结: {len(quick80_results):,} 场游戏\")\n",
    "        \n",
    "        # 总体成功率统计\n",
    "        total_success = sum(quick80_results['success'])\n",
    "        success_rate = total_success / len(quick80_results) * 100\n",
    "        print(f\"📈 总体成功率: {total_success:,}/{len(quick80_results):,} ({success_rate:.1f}%)\")\n",
    "        \n",
    "        # 按Hinter模型统计成功率\n",
    "        print(f\"\\n🎭 各Hinter模型表现:\")\n",
    "        for model in TEST_MODELS:\n",
    "            model_name = model.split('/')[-1]\n",
    "            model_games = quick80_results[quick80_results['hinter_model'] == model]\n",
    "            model_success = sum(model_games['success'])\n",
    "            model_rate = (model_success / len(model_games) * 100) if len(model_games) > 0 else 0\n",
    "            print(f\"   {model_name}: {model_success:,}/{len(model_games):,} ({model_rate:.1f}%)\")\n",
    "        \n",
    "        # 按Guesser模型统计成功率\n",
    "        print(f\"\\n🔍 各Guesser模型表现:\")\n",
    "        for model in TEST_MODELS:\n",
    "            model_name = model.split('/')[-1]\n",
    "            model_games = quick80_results[quick80_results['guesser_model'] == model]\n",
    "            model_success = sum(model_games['success'])\n",
    "            model_rate = (model_success / len(model_games) * 100) if len(model_games) > 0 else 0\n",
    "            print(f\"   {model_name}: {model_success:,}/{len(model_games):,} ({model_rate:.1f}%)\")\n",
    "        \n",
    "        # 按词性分析成功率\n",
    "        if 'part_of_speech' in quick80_results.columns or any('part_of_speech' in word for word in quick80_dataset):\n",
    "            print(f\"\\n📝 按词性分析成功率:\")\n",
    "            # 需要从原始数据集匹配词性\n",
    "            word_pos_map = {word['target']: word['part_of_speech'] for word in quick80_dataset}\n",
    "            quick80_results['word_pos'] = quick80_results['target_word'].map(word_pos_map)\n",
    "            \n",
    "            for pos in quick80_results['word_pos'].unique():\n",
    "                pos_games = quick80_results[quick80_results['word_pos'] == pos]\n",
    "                pos_success = sum(pos_games['success'])\n",
    "                pos_rate = (pos_success / len(pos_games) * 100) if len(pos_games) > 0 else 0\n",
    "                print(f\"   {pos}: {pos_success:,}/{len(pos_games):,} ({pos_rate:.1f}%)\")\n",
    "        \n",
    "        # 失败原因分析\n",
    "        failed_games = quick80_results[quick80_results['success'] == False]\n",
    "        if len(failed_games) > 0:\n",
    "            print(f\"\\n❌ 失败原因分析 ({len(failed_games):,} 场失败):\")\n",
    "            failure_reasons = failed_games['failure_reason'].value_counts()\n",
    "            for reason, count in failure_reasons.items():\n",
    "                percentage = count / len(failed_games) * 100\n",
    "                if reason == 'TABOO_VIOLATION':\n",
    "                    print(f\"   🚫 违反禁用词规则: {count:,} 场 ({percentage:.1f}%)\")\n",
    "                elif reason == 'FORMAT_FAILURE':\n",
    "                    print(f\"   🔤 格式错误超限: {count:,} 场 ({percentage:.1f}%)\")\n",
    "                elif reason == 'API_FAILURE':\n",
    "                    print(f\"   🌐 API调用失败: {count:,} 场 ({percentage:.1f}%)\")\n",
    "                elif reason == 'MAX_TURNS_EXCEEDED':\n",
    "                    print(f\"   ⏱️ 轮数耗尽: {count:,} 场 ({percentage:.1f}%)\")\n",
    "                else:\n",
    "                    print(f\"   ❓ {reason}: {count:,} 场 ({percentage:.1f}%)\")\n",
    "        else:\n",
    "            print(f\"\\n🎉 所有游戏都成功了！没有失败案例。\")\n",
    "        \n",
    "        # 轮数效率分析\n",
    "        successful_games = quick80_results[quick80_results['success'] == True]\n",
    "        if len(successful_games) > 0:\n",
    "            print(f\"\\n🔄 游戏轮数效率分析:\")\n",
    "            avg_turns = successful_games['turns_used'].mean()\n",
    "            print(f\"   平均轮数: {avg_turns:.2f} 轮\")\n",
    "            print(f\"   轮数分布:\")\n",
    "            turn_counts = successful_games['turns_used'].value_counts().sort_index()\n",
    "            for turns, count in turn_counts.items():\n",
    "                percentage = count / len(successful_games) * 100\n",
    "                print(f\"     {turns}轮: {count:,} 场 ({percentage:.1f}%)\")\n",
    "        \n",
    "        # 保存信息\n",
    "        print(f\"\\n💾 实验数据保存信息:\")\n",
    "        print(f\"   📁 主目录: results/taboo_experiment_[timestamp]/\")\n",
    "        print(f\"   📄 按Hinter模型分组的批次文件\")\n",
    "        print(f\"   📋 完整汇总文件: complete_experiment_results.csv\")\n",
    "        print(f\"   🔍 建议查看各Hinter模型的子目录获取详细结果\")\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ Quick80全量实验失败\")\n",
    "else:\n",
    "    print(\"❌ 无法执行Quick80全量实验：API客户端未初始化\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
