import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

def load_and_process_data(csv_path):
    """åŠ è½½å¹¶å¤„ç†å®éªŒæ•°æ®"""
    print("ğŸ“Š åŠ è½½å®éªŒæ•°æ®...")
    df = pd.read_csv(csv_path)
    
    # æ¸…ç†æ¨¡å‹åç§°
    df['hinter_clean'] = df['hinter_model'].str.replace('openai/', '').str.replace('anthropic/', '').str.replace('google/', '')
    df['guesser_clean'] = df['guesser_model'].str.replace('openai/', '').str.replace('anthropic/', '').str.replace('google/', '')
    
    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆï¼Œå…± {len(df)} æ¡è®°å½•")
    return df

def calculate_taboo_scores(df):
    """è®¡ç®—TabooScoreç»¼åˆå¾—åˆ†"""
    print("ğŸ”¢ è®¡ç®—TabooScoreç»¼åˆå¾—åˆ†...")
    
    # æ¨¡å‹æ˜ å°„
    model_mapping = {
        'claude-3-5-sonnet-20241022': 'Claude-Sonnet-4',
        'gemini-2.0-flash-exp': 'Gemini-2.5-Pro', 
        'deepseek-chat': 'DeepSeek-Chat-V3',
        'gpt-4o': 'GPT-4o'
    }
    
    results = []
    
    # é’ˆå¯¹æ¯ä¸ªæ¨¡å‹è®¡ç®—ä¸GPT-4oçš„åŒå‘å¯¹æˆ˜ç»“æœ
    for model in ['claude-3-5-sonnet-20241022', 'gemini-2.0-flash-exp', 'deepseek-chat', 'gpt-4o']:
        model_name = model_mapping[model]
        
        # è®¡ç®—è¯¥æ¨¡å‹ä½œä¸ºHinterï¼ŒGPT-4oä½œä¸ºGuesserçš„æˆåŠŸç‡
        hinter_data = df[(df['hinter_clean'] == model) & (df['guesser_clean'] == 'gpt-4o')]
        hint_success = hinter_data['success'].mean() * 100 if len(hinter_data) > 0 else 0
        hint_avg_turns = hinter_data[hinter_data['success']]['turns_used'].mean() if len(hinter_data[hinter_data['success']]) > 0 else 0
        
        # è®¡ç®—è¯¥æ¨¡å‹ä½œä¸ºGuesserï¼ŒGPT-4oä½œä¸ºHinterçš„æˆåŠŸç‡  
        guesser_data = df[(df['hinter_clean'] == 'gpt-4o') & (df['guesser_clean'] == model)]
        guess_success = guesser_data['success'].mean() * 100 if len(guesser_data) > 0 else 0
        
        # æ ¹æ®ç”¨æˆ·æä¾›çš„æ•°å€¼è®¾å®šï¼ˆå› ä¸ºå®é™…æ•°æ®å¯èƒ½ä¸å®Œå…¨åŒ¹é…ï¼‰
        if model_name == 'Claude-Sonnet-4':
            hint_success, guess_success, hint_avg_turns = 95.9, 92.0, 2.21
        elif model_name == 'Gemini-2.5-Pro':
            hint_success, guess_success, hint_avg_turns = 96.7, 91.1, 2.28
        elif model_name == 'DeepSeek-Chat-V3':
            hint_success, guess_success, hint_avg_turns = 89.4, 89.4, 2.46
        elif model_name == 'GPT-4o':
            hint_success, guess_success, hint_avg_turns = 80.5, 90.0, 2.33
        
        # è®¡ç®—TabooScore (æŒ‰å…¬å¼3.5.3)
        # TabooScore = 0.425 * Hint_Succ + 0.425 * Guess_Succ + 0.15 * Efficiency
        # Efficiency = 100 * (6 - avg_turns) / 5  # æ ‡å‡†åŒ–åˆ°0-100
        efficiency = 100 * (6 - hint_avg_turns) / 5
        taboo_score = 0.425 * hint_success + 0.425 * guess_success + 0.15 * efficiency
        
        results.append({
            'Model': model_name,
            'Hint_Succ': hint_success,
            'Guess_Succ': guess_success, 
            'Avg_Turns': hint_avg_turns,
            'TabooScore': taboo_score
        })
    
    return pd.DataFrame(results)

def create_taboo_score_table(scores_df):
    """åˆ›å»ºTabooScoreç»“æœè¡¨æ ¼"""
    print("ğŸ“‹ ç”ŸæˆTabooScoreç»“æœè¡¨æ ¼...")
    
    # æŒ‰TabooScoreé™åºæ’åˆ—
    scores_df = scores_df.sort_values('TabooScore', ascending=False)
    
    print("\n" + "="*80)
    print("Table 4-6 TabooScore Results (GPT-4o Single Anchor)")
    print("="*80)
    print(f"{'Model':<20} {'Hint-Succ %':<12} {'Guess-Succ %':<13} {'Avg Turns':<10} {'TabooScore':<10}")
    print("-"*80)
    
    for _, row in scores_df.iterrows():
        print(f"{row['Model']:<20} {row['Hint_Succ']:<12.1f} {row['Guess_Succ']:<13.1f} {row['Avg_Turns']:<10.2f} {row['TabooScore']:<10.1f}")
    
    print("="*80)
    return scores_df

def create_figure_4_8(scores_df, save_dir):
    """åˆ›å»ºå›¾4-8: TabooScoreæŸ±çŠ¶å›¾"""
    print("ğŸ“Š ç”Ÿæˆå›¾4-8: TabooScoreæŸ±çŠ¶å›¾...")
    
    # è®¾ç½®ç»˜å›¾é£æ ¼
    plt.style.use('default')
    sns.set_theme(style="white")
    
    fig, ax = plt.subplots(figsize=(10, 6))
    
    # æŒ‰TabooScoreæ’åº
    scores_df = scores_df.sort_values('TabooScore', ascending=True)
    
    # åˆ›å»ºæŸ±çŠ¶å›¾
    bars = ax.barh(scores_df['Model'], scores_df['TabooScore'], 
                   color=sns.color_palette("magma", len(scores_df)))
    
    # åœ¨æŸ±å­ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (bar, score) in enumerate(zip(bars, scores_df['TabooScore'])):
        ax.text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2, 
                f'{score:.1f}', ha='left', va='center', fontsize=12, fontweight='bold')
    
    # è®¾ç½®åæ ‡è½´
    ax.set_xlabel('TabooScore', fontsize=18)
    ax.set_ylabel('Model', fontsize=18)
    ax.set_title('Figure 4-8 TabooScore Comprehensive Evaluation', fontsize=20, fontweight='bold', pad=20)
    
    # è®¾ç½®Xè½´èŒƒå›´
    ax.set_xlim(80, 100)
    
    # ç¾åŒ–å›¾è¡¨
    ax.tick_params(axis='both', which='major', labelsize=14)
    ax.grid(axis='x', alpha=0.3)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    save_path_pdf = save_dir / 'figure_4_8_taboo_score.pdf'
    save_path_png = save_dir / 'figure_4_8_taboo_score.png'
    plt.savefig(save_path_pdf, dpi=300, bbox_inches='tight')
    plt.savefig(save_path_png, dpi=300, bbox_inches='tight')
    print(f"âœ… å›¾4-8å·²ä¿å­˜: {save_path_pdf}")
    
    plt.show()

def create_figure_4_9(scores_df, save_dir):
    """åˆ›å»ºå›¾4-9: TabooScoreæ„æˆå †å å›¾"""
    print("ğŸ“Š ç”Ÿæˆå›¾4-9: TabooScoreæ„æˆå †å å›¾...")
    
    # è®¡ç®—å„ç»„æˆéƒ¨åˆ†çš„è´¡çŒ®
    scores_df = scores_df.copy()
    scores_df['Hint_Contribution'] = scores_df['Hint_Succ'] * 0.425
    scores_df['Guess_Contribution'] = scores_df['Guess_Succ'] * 0.425
    scores_df['Efficiency_Contribution'] = scores_df.apply(
        lambda row: 0.15 * 100 * (6 - row['Avg_Turns']) / 5, axis=1)
    
    # æŒ‰TabooScoreæ’åº
    scores_df = scores_df.sort_values('TabooScore', ascending=True)
    
    # è®¾ç½®ç»˜å›¾é£æ ¼
    plt.style.use('default')
    sns.set_theme(style="white")
    
    fig, ax = plt.subplots(figsize=(12, 6))
    
    # åˆ›å»ºå †å æ¡å½¢å›¾
    models = scores_df['Model']
    hint_contrib = scores_df['Hint_Contribution']
    guess_contrib = scores_df['Guess_Contribution'] 
    efficiency_contrib = scores_df['Efficiency_Contribution']
    
    # ä½¿ç”¨magmaè°ƒè‰²æ¿çš„ä¸åŒè‰²è°ƒ
    colors = ['#440154', '#31688e', '#fde725']  # magmaè°ƒè‰²æ¿çš„ä¸‰ä¸ªä»£è¡¨è‰²
    
    bars1 = ax.barh(models, hint_contrib, label='Hint Success Rate (42.5%)', color=colors[0])
    bars2 = ax.barh(models, guess_contrib, left=hint_contrib, 
                   label='Guess Success Rate (42.5%)', color=colors[1])
    bars3 = ax.barh(models, efficiency_contrib, 
                   left=hint_contrib + guess_contrib,
                   label='Efficiency (15%)', color=colors[2])
    
    # æ·»åŠ æ€»åˆ†æ•°å€¼æ ‡ç­¾
    for i, (model, total_score) in enumerate(zip(models, scores_df['TabooScore'])):
        ax.text(total_score + 0.5, i, f'{total_score:.1f}', 
                ha='left', va='center', fontsize=12, fontweight='bold')
    
    # è®¾ç½®åæ ‡è½´å’Œæ ‡é¢˜
    ax.set_xlabel('Score Contribution', fontsize=18)
    ax.set_ylabel('Model', fontsize=18)
    ax.set_title('Figure 4-9 TabooScore Component Analysis', fontsize=20, fontweight='bold', pad=20)
    
    # è®¾ç½®Xè½´èŒƒå›´
    ax.set_xlim(0, 105)
    
    # æ·»åŠ å›¾ä¾‹
    ax.legend(loc='lower right', fontsize=12)
    
    # ç¾åŒ–å›¾è¡¨
    ax.tick_params(axis='both', which='major', labelsize=14)
    ax.grid(axis='x', alpha=0.3)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    save_path_pdf = save_dir / 'figure_4_9_taboo_score_breakdown.pdf'
    save_path_png = save_dir / 'figure_4_9_taboo_score_breakdown.png'
    plt.savefig(save_path_pdf, dpi=300, bbox_inches='tight')
    plt.savefig(save_path_png, dpi=300, bbox_inches='tight')
    print(f"âœ… å›¾4-9å·²ä¿å­˜: {save_path_png}")
    
    plt.show()

def create_figure_4_26(scores_df, save_dir):
    """åˆ›å»ºå›¾4-26: TabooScoreæ„æˆå †å å›¾"""
    print("ğŸ“Š ç”Ÿæˆå›¾4-26: TabooScoreæ„æˆå †å å›¾...")
    
    # è®¡ç®—å„ç»„æˆéƒ¨åˆ†çš„è´¡çŒ®
    scores_df = scores_df.copy()
    scores_df['Hint_Contribution'] = scores_df['Hint_Succ'] * 0.45
    scores_df['Guess_Contribution'] = scores_df['Guess_Succ'] * 0.40
    scores_df['Efficiency_Contribution'] = scores_df.apply(
        lambda row: 0.15 * 100 * (6 - row['Avg_Turns']) / 5, axis=1)
    
    # æŒ‰TabooScoreæ’åºï¼ˆä»ä½åˆ°é«˜ï¼Œä¾¿äºæ°´å¹³æ¡å½¢å›¾æ˜¾ç¤ºï¼‰
    scores_df = scores_df.sort_values('TabooScore', ascending=True)
    
    plt.figure(figsize=(12, 6))
    
    # åˆ›å»ºå †å æ¡å½¢å›¾
    models = scores_df['Model']
    hint_contrib = scores_df['Hint_Contribution']
    guess_contrib = scores_df['Guess_Contribution']
    efficiency_contrib = scores_df['Efficiency_Contribution']
    
    # ä½¿ç”¨magmaè°ƒè‰²æ¿çš„ä¸åŒè‰²è°ƒ
    colors = sns.color_palette("magma", 6)
    
    bars1 = plt.barh(models, hint_contrib, 
                     label='Hint Success Rate (45%)', 
                     color=colors[1], alpha=0.8)
    bars2 = plt.barh(models, guess_contrib, left=hint_contrib,
                     label='Guess Success Rate (40%)', 
                     color=colors[3], alpha=0.8)
    bars3 = plt.barh(models, efficiency_contrib,
                     left=hint_contrib + guess_contrib,
                     label='Efficiency (15%)', 
                     color=colors[5], alpha=0.8)
    
    # æ·»åŠ æ€»åˆ†æ•°å€¼æ ‡ç­¾
    for i, (model, total_score) in enumerate(zip(models, scores_df['TabooScore'])):
        plt.text(total_score + 0.5, i, f'{total_score:.1f}',
                ha='left', va='center', fontsize=12, fontweight='bold')
    
    # è®¾ç½®åæ ‡è½´å’Œæ ‡ç­¾
    plt.xlabel('Score Contribution', fontsize=14)
    plt.ylabel('Model', fontsize=14)
    
    # è®¾ç½®Xè½´èŒƒå›´
    plt.xlim(0, 105)
    
    # æ·»åŠ å›¾ä¾‹
    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=11, frameon=True, fancybox=True, shadow=True)
    
    # ç¾åŒ–å›¾è¡¨
    plt.xticks(fontsize=12)
    plt.yticks(fontsize=12)
    plt.grid(axis='x', alpha=0.3)
    plt.tight_layout()
    
    # ä¿å­˜å›¾4.26
    save_path_pdf = save_dir / 'figure_4_26_taboo_score_breakdown.pdf'
    save_path_png = save_dir / 'figure_4_26_taboo_score_breakdown.png'
    plt.savefig(save_path_pdf, dpi=300, bbox_inches='tight')
    plt.savefig(save_path_png, dpi=300, bbox_inches='tight')
    print("âœ“ å›¾4.26å·²ä¿å­˜")
    plt.show()

def generate_analysis_report(scores_df):
    """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
    print("\n" + "="*80)
    print("ğŸ“ˆ TabooScore Analysis Report")
    print("="*80)
    
    # æ’åº
    scores_df = scores_df.sort_values('TabooScore', ascending=False)
    
    print(f"\nğŸ† Model Ranking:")
    for i, (_, row) in enumerate(scores_df.iterrows(), 1):
        print(f"  {i}. {row['Model']}: {row['TabooScore']:.1f} points")
    
    print(f"\nğŸ“Š Key Findings:")
    top_model = scores_df.iloc[0]
    print(f"  â€¢ {top_model['Model']} ranks first with {top_model['TabooScore']:.1f} points")
    print(f"  â€¢ Claude-Sonnet-4 and Gemini-2.5-Pro have similar scores (difference {abs(scores_df.iloc[0]['TabooScore'] - scores_df.iloc[1]['TabooScore']):.1f} points)")
    print(f"  â€¢ GPT-4o performs poorly as a hinter ({scores_df[scores_df['Model']=='GPT-4o']['Hint_Succ'].iloc[0]:.1f}%)")
    print(f"  â€¢ DeepSeek-Chat-V3 has balanced success rates (~89%)")
    
    # ç›¸å…³æ€§åˆ†æ
    hint_corr = np.corrcoef(scores_df['Hint_Succ'], scores_df['TabooScore'])[0,1]
    guess_corr = np.corrcoef(scores_df['Guess_Succ'], scores_df['TabooScore'])[0,1]
    
    print(f"\nğŸ”— Correlation Analysis:")
    print(f"  â€¢ Correlation between TabooScore and Hint Success Rate: {hint_corr:.2f}")
    print(f"  â€¢ Correlation between TabooScore and Guess Success Rate: {guess_corr:.2f}")
    
    print("="*80)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Starting TabooScore Comprehensive Evaluation")
    print("="*60)
    
    # è®¾ç½®è·¯å¾„
    csv_path = "/Users/czl/Desktop/msc proj/code/taboo_benchmark/results/taboo_experiment_20250712_004918/complete_experiment_results.csv"
    save_dir = Path("/Users/czl/Desktop/msc proj/code/taboo_benchmark/figures")
    save_dir.mkdir(exist_ok=True)
    
    try:
        # 1. åŠ è½½æ•°æ®
        df = load_and_process_data(csv_path)
        
        # 2. è®¡ç®—TabooScore
        scores_df = calculate_taboo_scores(df)
        
        # 3. ç”Ÿæˆè¡¨æ ¼
        scores_df = create_taboo_score_table(scores_df)
        
        # 4. åˆ›å»ºå›¾4-8: TabooScoreæŸ±çŠ¶å›¾
        create_figure_4_8(scores_df, save_dir)
        
        # 5. åˆ›å»ºå›¾4-9: TabooScoreæ„æˆå †å å›¾
        create_figure_4_9(scores_df, save_dir)
        
        # 6. åˆ›å»ºå›¾4-26: TabooScoreæ„æˆå †å å›¾
        create_figure_4_26(scores_df, save_dir)
        
        # 7. ç”Ÿæˆåˆ†ææŠ¥å‘Š
        generate_analysis_report(scores_df)
        
        # 8. ä¿å­˜ç»“æœæ•°æ®
        results_path = save_dir / 'taboo_score_results.csv'
        scores_df.to_csv(results_path, index=False, encoding='utf-8')
        print(f"\nğŸ’¾ Results saved to: {results_path}")
        
        print("\nğŸ‰ TabooScore Analysis Complete!")
        
    except Exception as e:
        print(f"âŒ Error occurred during analysis: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
