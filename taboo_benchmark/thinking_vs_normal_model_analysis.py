import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import json
from collections import defaultdict

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# åŠ è½½å®éªŒç»“æœæ•°æ®
print("ğŸ” åŠ è½½å®éªŒç»“æœæ•°æ®...")
results_df = pd.read_csv('results/taboo_experiment_20250712_004918/complete_experiment_results.csv')

# æ¨¡å‹åˆ†ç±»
print("\nğŸ“Š æ¨¡å‹åˆ†ç±»:")
print("="*50)

# æ ¹æ®ç”¨æˆ·æŒ‡å®šçš„åˆ†ç±»
normal_models = {
    'deepseek/deepseek-chat-v3-0324': 'DeepSeek Chat V3',
    'openai/gpt-4o': 'GPT-4o'
}

thinking_models = {
    'anthropic/claude-sonnet-4': 'Claude Sonnet 4',
    'google/gemini-2.5-pro': 'Gemini 2.5 Pro'
}

print("æ™®é€šæ¨¡å‹ (Normal Models):")
for model_id, model_name in normal_models.items():
    print(f"  â€¢ {model_name} ({model_id})")

print("\nThinkingæ¨¡å‹ (Thinking Models):")
for model_id, model_name in thinking_models.items():
    print(f"  â€¢ {model_name} ({model_id})")

# æ·»åŠ æ¨¡å‹ç±»å‹æ ‡ç­¾
def get_model_type(model_id):
    if model_id in normal_models:
        return 'æ™®é€šæ¨¡å‹'
    elif model_id in thinking_models:
        return 'Thinkingæ¨¡å‹'
    else:
        return 'æœªçŸ¥'

def get_model_clean_name(model_id):
    if model_id in normal_models:
        return normal_models[model_id]
    elif model_id in thinking_models:
        return thinking_models[model_id]
    else:
        return model_id

results_df['model_type'] = results_df['hinter_model'].apply(get_model_type)
results_df['model_name'] = results_df['hinter_model'].apply(get_model_clean_name)

print(f"\nğŸ“ˆ æ•°æ®æ¦‚è§ˆ:")
print(f"  â€¢ æ€»æ¸¸æˆæ•°: {len(results_df):,}")
print(f"  â€¢ æ™®é€šæ¨¡å‹æ¸¸æˆæ•°: {len(results_df[results_df['model_type'] == 'æ™®é€šæ¨¡å‹']):,}")
print(f"  â€¢ Thinkingæ¨¡å‹æ¸¸æˆæ•°: {len(results_df[results_df['model_type'] == 'Thinkingæ¨¡å‹']):,}")

# 1. åŸºç¡€æ€§èƒ½å¯¹æ¯”
print("\n" + "="*60)
print("1. åŸºç¡€æ€§èƒ½å¯¹æ¯”åˆ†æ")
print("="*60)

# æŒ‰æ¨¡å‹ç±»å‹åˆ†ç»„ç»Ÿè®¡
type_stats = results_df.groupby('model_type').agg({
    'success': ['count', 'sum', 'mean'],
    'turns_used': lambda x: x[results_df.loc[x.index, 'success']].mean(),
    'has_taboo_violation': 'mean',
    'duration_seconds': 'mean'
}).round(3)

type_stats.columns = ['æ€»æ¸¸æˆæ•°', 'æˆåŠŸæ¸¸æˆæ•°', 'æˆåŠŸç‡', 'å¹³å‡è½®æ•°', 'è¿è§„ç‡', 'å¹³å‡ç”¨æ—¶(ç§’)']

print("ğŸ“Š æŒ‰æ¨¡å‹ç±»å‹ç»Ÿè®¡:")
print(type_stats)

# ä¸ªåˆ«æ¨¡å‹è¯¦ç»†ç»Ÿè®¡
individual_stats = results_df.groupby('model_name').agg({
    'success': ['count', 'sum', 'mean'],
    'turns_used': lambda x: x[results_df.loc[x.index, 'success']].mean(),
    'has_taboo_violation': 'mean',
    'duration_seconds': 'mean'
}).round(3)

individual_stats.columns = ['æ€»æ¸¸æˆæ•°', 'æˆåŠŸæ¸¸æˆæ•°', 'æˆåŠŸç‡', 'å¹³å‡è½®æ•°', 'è¿è§„ç‡', 'å¹³å‡ç”¨æ—¶(ç§’)']

print("\nğŸ“‹ å„æ¨¡å‹è¯¦ç»†ç»Ÿè®¡:")
print(individual_stats)

# 2. æ•ˆç‡åˆ†æ
print("\n" + "="*60)
print("2. æ•ˆç‡åˆ†æ")
print("="*60)

# ç¬¬1è½®æˆåŠŸç‡åˆ†æ
successful_games = results_df[results_df['success'] == True]
first_turn_success = successful_games.groupby(['model_type', 'model_name']).apply(
    lambda x: (x['turns_used'] == 1).sum() / len(x)
).reset_index()
first_turn_success.columns = ['æ¨¡å‹ç±»å‹', 'æ¨¡å‹åç§°', 'ç¬¬1è½®æˆåŠŸç‡']

print("âš¡ ç¬¬1è½®æˆåŠŸç‡å¯¹æ¯”:")
for model_type in ['æ™®é€šæ¨¡å‹', 'Thinkingæ¨¡å‹']:
    print(f"\n{model_type}:")
    type_data = first_turn_success[first_turn_success['æ¨¡å‹ç±»å‹'] == model_type]
    for _, row in type_data.iterrows():
        print(f"  â€¢ {row['æ¨¡å‹åç§°']}: {row['ç¬¬1è½®æˆåŠŸç‡']:.1%}")

# ç´¯ç§¯æˆåŠŸç‡åˆ†æ
cumulative_success = {}
for turn in range(1, 6):
    cumulative_rates = successful_games.groupby(['model_type', 'model_name']).apply(
        lambda x: (x['turns_used'] <= turn).sum() / len(x)
    ).reset_index()
    cumulative_rates.columns = ['æ¨¡å‹ç±»å‹', 'æ¨¡å‹åç§°', f'å‰{turn}è½®ç´¯ç§¯æˆåŠŸç‡']
    cumulative_success[turn] = cumulative_rates

print(f"\nğŸ¯ å‰3è½®ç´¯ç§¯æˆåŠŸç‡å¯¹æ¯”:")
for model_type in ['æ™®é€šæ¨¡å‹', 'Thinkingæ¨¡å‹']:
    print(f"\n{model_type}:")
    type_data = cumulative_success[3][cumulative_success[3]['æ¨¡å‹ç±»å‹'] == model_type]
    for _, row in type_data.iterrows():
        print(f"  â€¢ {row['æ¨¡å‹åç§°']}: {row['å‰3è½®ç´¯ç§¯æˆåŠŸç‡']:.1%}")

# 3. ç¨³å®šæ€§åˆ†æ
print("\n" + "="*60)
print("3. ç¨³å®šæ€§åˆ†æ")
print("="*60)

# è®¡ç®—å„æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡ä¸Šçš„æ€§èƒ½æ ‡å‡†å·®
stability_stats = results_df.groupby(['model_type', 'model_name']).agg({
    'success': ['mean', 'std'],
    'turns_used': lambda x: x[results_df.loc[x.index, 'success']].std()
}).round(4)

stability_stats.columns = ['æˆåŠŸç‡å‡å€¼', 'æˆåŠŸç‡æ ‡å‡†å·®', 'è½®æ•°æ ‡å‡†å·®']

print("ğŸ² ç¨³å®šæ€§æŒ‡æ ‡ (æ ‡å‡†å·®è¶Šå°è¶Šç¨³å®š):")
print(stability_stats)

# 4. å¤±è´¥åŸå› åˆ†æ
print("\n" + "="*60)
print("4. å¤±è´¥åŸå› åˆ†æ")
print("="*60)

failed_games = results_df[results_df['success'] == False]
failure_analysis = failed_games.groupby(['model_type', 'failure_reason']).size().unstack(fill_value=0)

print("âŒ å¤±è´¥åŸå› åˆ†å¸ƒ:")
if not failure_analysis.empty:
    print(failure_analysis)
    
    # è®¡ç®—å¤±è´¥åŸå› æ¯”ä¾‹
    failure_pct = failure_analysis.div(failure_analysis.sum(axis=1), axis=0) * 100
    print(f"\nå¤±è´¥åŸå› æ¯”ä¾‹ (%):")
    print(failure_pct.round(1))

# 5. å¯è§†åŒ–å¯¹æ¯”
print("\n" + "="*60)
print("5. å¯è§†åŒ–å¯¹æ¯”åˆ†æ")
print("="*60)

# åˆ›å»ºç»¼åˆå¯¹æ¯”å›¾
fig, axes = plt.subplots(2, 3, figsize=(18, 12))
fig.suptitle('Thinkingæ¨¡å‹ vs æ™®é€šæ¨¡å‹ æ€§èƒ½å¯¹æ¯”', fontsize=16, fontweight='bold')

# 1. æˆåŠŸç‡å¯¹æ¯”
ax1 = axes[0, 0]
type_success = results_df.groupby('model_type')['success'].mean()
colors = ['#ff7f0e', '#1f77b4']  # æ©™è‰²ï¼šæ™®é€šæ¨¡å‹ï¼Œè“è‰²ï¼šThinkingæ¨¡å‹
bars1 = ax1.bar(type_success.index, type_success.values, color=colors)
ax1.set_title('æˆåŠŸç‡å¯¹æ¯”', fontweight='bold')
ax1.set_ylabel('æˆåŠŸç‡')
ax1.set_ylim(0, 1)

# æ·»åŠ æ•°å€¼æ ‡ç­¾
for bar in bars1:
    height = bar.get_height()
    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,
             f'{height:.1%}', ha='center', va='bottom', fontweight='bold')

# 2. å¹³å‡è½®æ•°å¯¹æ¯”
ax2 = axes[0, 1]
type_turns = results_df[results_df['success'] == True].groupby('model_type')['turns_used'].mean()
bars2 = ax2.bar(type_turns.index, type_turns.values, color=colors)
ax2.set_title('å¹³å‡è½®æ•°å¯¹æ¯” (æˆåŠŸæ¸¸æˆ)', fontweight='bold')
ax2.set_ylabel('å¹³å‡è½®æ•°')

for bar in bars2:
    height = bar.get_height()
    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.05,
             f'{height:.1f}', ha='center', va='bottom', fontweight='bold')

# 3. è¿è§„ç‡å¯¹æ¯”
ax3 = axes[0, 2]
type_violation = results_df.groupby('model_type')['has_taboo_violation'].mean()
bars3 = ax3.bar(type_violation.index, type_violation.values, color=colors)
ax3.set_title('è¿è§„ç‡å¯¹æ¯”', fontweight='bold')
ax3.set_ylabel('è¿è§„ç‡')

for bar in bars3:
    height = bar.get_height()
    ax3.text(bar.get_x() + bar.get_width()/2., height + 0.002,
             f'{height:.1%}', ha='center', va='bottom', fontweight='bold')

# 4. ä¸ªåˆ«æ¨¡å‹è¯¦ç»†å¯¹æ¯”
ax4 = axes[1, 0]
individual_success = results_df.groupby('model_name')['success'].mean().sort_values(ascending=False)
model_colors = ['#1f77b4' if name in thinking_models.values() else '#ff7f0e' 
                for name in individual_success.index]
bars4 = ax4.bar(range(len(individual_success)), individual_success.values, color=model_colors)
ax4.set_title('å„æ¨¡å‹æˆåŠŸç‡è¯¦ç»†å¯¹æ¯”', fontweight='bold')
ax4.set_ylabel('æˆåŠŸç‡')
ax4.set_xticks(range(len(individual_success)))
ax4.set_xticklabels(individual_success.index, rotation=45, ha='right')

for i, bar in enumerate(bars4):
    height = bar.get_height()
    ax4.text(bar.get_x() + bar.get_width()/2., height + 0.01,
             f'{height:.1%}', ha='center', va='bottom', fontweight='bold', fontsize=9)

# 5. ç¬¬1è½®æˆåŠŸç‡å¯¹æ¯”
ax5 = axes[1, 1]
type_first_turn = successful_games.groupby('model_type').apply(
    lambda x: (x['turns_used'] == 1).sum() / len(x)
)
bars5 = ax5.bar(type_first_turn.index, type_first_turn.values, color=colors)
ax5.set_title('ç¬¬1è½®æˆåŠŸç‡å¯¹æ¯”', fontweight='bold')
ax5.set_ylabel('ç¬¬1è½®æˆåŠŸç‡')

for bar in bars5:
    height = bar.get_height()
    ax5.text(bar.get_x() + bar.get_width()/2., height + 0.01,
             f'{height:.1%}', ha='center', va='bottom', fontweight='bold')

# 6. å¹³å‡ç”¨æ—¶å¯¹æ¯”
ax6 = axes[1, 2]
type_duration = results_df.groupby('model_type')['duration_seconds'].mean()
bars6 = ax6.bar(type_duration.index, type_duration.values, color=colors)
ax6.set_title('å¹³å‡ç”¨æ—¶å¯¹æ¯”', fontweight='bold')
ax6.set_ylabel('å¹³å‡ç”¨æ—¶ (ç§’)')

for bar in bars6:
    height = bar.get_height()
    ax6.text(bar.get_x() + bar.get_width()/2., height + 0.5,
             f'{height:.0f}s', ha='center', va='bottom', fontweight='bold')

plt.tight_layout()
plt.show()

# 6. æ€»ç»“æŠ¥å‘Š
print("\n" + "="*60)
print("6. æ€»ç»“æŠ¥å‘Š")
print("="*60)

# è®¡ç®—æ€§èƒ½å·®å¼‚
thinking_success = type_stats.loc['Thinkingæ¨¡å‹', 'æˆåŠŸç‡']
normal_success = type_stats.loc['æ™®é€šæ¨¡å‹', 'æˆåŠŸç‡']
success_gap = thinking_success - normal_success

thinking_turns = type_stats.loc['Thinkingæ¨¡å‹', 'å¹³å‡è½®æ•°']
normal_turns = type_stats.loc['æ™®é€šæ¨¡å‹', 'å¹³å‡è½®æ•°']
efficiency_gap = normal_turns - thinking_turns

thinking_violation = type_stats.loc['Thinkingæ¨¡å‹', 'è¿è§„ç‡']
normal_violation = type_stats.loc['æ™®é€šæ¨¡å‹', 'è¿è§„ç‡']
violation_gap = normal_violation - thinking_violation

print(f"ğŸ¯ æ ¸å¿ƒå‘ç°:")
print(f"  â€¢ æˆåŠŸç‡å·®å¼‚: Thinkingæ¨¡å‹æ¯”æ™®é€šæ¨¡å‹é«˜ {success_gap:.1%}")
print(f"  â€¢ æ•ˆç‡å·®å¼‚: Thinkingæ¨¡å‹æ¯”æ™®é€šæ¨¡å‹å°‘ç”¨ {efficiency_gap:.1f} è½®")
print(f"  â€¢ è§„åˆ™éµå®ˆ: Thinkingæ¨¡å‹è¿è§„ç‡æ¯”æ™®é€šæ¨¡å‹ä½ {violation_gap:.1%}")

print(f"\nğŸ† æœ€ä½³è¡¨ç°:")
best_overall = individual_stats.sort_values('æˆåŠŸç‡', ascending=False).index[0]
best_efficiency = individual_stats.sort_values('å¹³å‡è½®æ•°', ascending=True).index[0]
best_compliance = individual_stats.sort_values('è¿è§„ç‡', ascending=True).index[0]

print(f"  â€¢ æœ€é«˜æˆåŠŸç‡: {best_overall} ({individual_stats.loc[best_overall, 'æˆåŠŸç‡']:.1%})")
print(f"  â€¢ æœ€é«˜æ•ˆç‡: {best_efficiency} ({individual_stats.loc[best_efficiency, 'å¹³å‡è½®æ•°']:.1f}è½®)")
print(f"  â€¢ æœ€ä½³è§„åˆ™éµå®ˆ: {best_compliance} ({individual_stats.loc[best_compliance, 'è¿è§„ç‡']:.1%})")

print(f"\nğŸ“Š æ¨¡å‹ç±»å‹ä¼˜åŠ¿:")
if success_gap > 0.05:
    print(f"  â€¢ Thinkingæ¨¡å‹åœ¨æˆåŠŸç‡ä¸Šæœ‰æ˜æ˜¾ä¼˜åŠ¿")
else:
    print(f"  â€¢ ä¸¤ç±»æ¨¡å‹åœ¨æˆåŠŸç‡ä¸Šå·®å¼‚ä¸å¤§")

if efficiency_gap > 0.3:
    print(f"  â€¢ Thinkingæ¨¡å‹åœ¨æ•ˆç‡ä¸Šæœ‰æ˜æ˜¾ä¼˜åŠ¿")
else:
    print(f"  â€¢ ä¸¤ç±»æ¨¡å‹åœ¨æ•ˆç‡ä¸Šå·®å¼‚ä¸å¤§")

if violation_gap > 0.01:
    print(f"  â€¢ Thinkingæ¨¡å‹åœ¨è§„åˆ™éµå®ˆä¸Šæœ‰æ˜æ˜¾ä¼˜åŠ¿")
else:
    print(f"  â€¢ ä¸¤ç±»æ¨¡å‹åœ¨è§„åˆ™éµå®ˆä¸Šå·®å¼‚ä¸å¤§")

print(f"\nğŸ’¡ ç»“è®º:")
print(f"  â€¢ Thinkingæ¨¡å‹æ•´ä½“è¡¨ç°ä¼˜äºæ™®é€šæ¨¡å‹")
print(f"  â€¢ ä¸»è¦ä¼˜åŠ¿ä½“ç°åœ¨ï¼šæ›´é«˜çš„æˆåŠŸç‡ã€æ›´å°‘çš„è½®æ•°ã€æ›´ä½çš„è¿è§„ç‡")
print(f"  â€¢ è¿™å¯èƒ½ä¸Thinkingæ¨¡å‹çš„å†…éƒ¨æ¨ç†æœºåˆ¶æœ‰å…³")

print(f"\nâœ… åˆ†æå®Œæˆï¼") 