#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Kimiå®éªŒç»“æœåˆ†æè„šæœ¬
åˆ†æç°æœ‰çš„8ç»„æ¨¡å‹å¯¹å®éªŒç»“æœ
"""

import pandas as pd
import os
from datetime import datetime

def analyze_kimi_experiment():
    """åˆ†æKimiå®éªŒç»“æœ"""
    print("ğŸ“Š Kimiå®éªŒç»“æœåˆ†æ")
    print("=" * 50)
    
    results_dir = "results/kimi_experiment_20250717_125711"
    
    if not os.path.exists(results_dir):
        print("âŒ å®éªŒç»“æœç›®å½•ä¸å­˜åœ¨")
        return
    
    # æ”¶é›†æ‰€æœ‰CSVæ–‡ä»¶
    csv_files = [f for f in os.listdir(results_dir) if f.endswith('.csv')]
    print(f"ğŸ“ æ‰¾åˆ° {len(csv_files)} ä¸ªç»“æœæ–‡ä»¶")
    
    # åˆå¹¶æ‰€æœ‰ç»“æœ
    all_results = []
    
    for csv_file in sorted(csv_files):
        file_path = os.path.join(results_dir, csv_file)
        try:
            df = pd.read_csv(file_path, encoding='utf-8')
            all_results.extend(df.to_dict('records'))
            print(f"   âœ… {csv_file}: {len(df)} æ¡è®°å½•")
        except Exception as e:
            print(f"   âŒ {csv_file}: è¯»å–å¤±è´¥ - {e}")
    
    if not all_results:
        print("âŒ æ— æ³•è¯»å–ä»»ä½•ç»“æœæ•°æ®")
        return
    
    # åŸºæœ¬ç»Ÿè®¡
    print(f"\nğŸ“Š åŸºæœ¬ç»Ÿè®¡:")
    total_games = len(all_results)
    total_success = sum(1 for r in all_results if r['success'])
    overall_success_rate = total_success / total_games * 100
    
    print(f"   ğŸ® æ€»æ¸¸æˆæ•°: {total_games:,} åœº")
    print(f"   âœ… æ€»æˆåŠŸæ•°: {total_success:,} åœº")
    print(f"   ğŸ“ˆ æ€»æˆåŠŸç‡: {overall_success_rate:.1f}%")
    
    # åˆ›å»ºDataFrameç”¨äºåˆ†æ
    summary_df = pd.DataFrame(all_results)
    
    # æ£€æŸ¥ç¼ºå¤±çš„å®éªŒç»„
    print(f"\nğŸ” å®éªŒç»„æ£€æŸ¥:")
    expected_pairs = [
        "kimi-k2â†’kimi-k2", "kimi-k2â†’gpt-4o", "kimi-k2â†’gemini-2.5-flash", 
        "kimi-k2â†’deepseek-chat-v3-0324", "kimi-k2â†’claude-sonnet-4",
        "gpt-4oâ†’kimi-k2", "gemini-2.5-flashâ†’kimi-k2", 
        "deepseek-chat-v3-0324â†’kimi-k2", "claude-sonnet-4â†’kimi-k2"
    ]
    
    existing_pairs = summary_df['pair_name'].unique()
    missing_pairs = [pair for pair in expected_pairs if pair not in existing_pairs]
    
    print(f"   âœ… å·²å®Œæˆ: {len(existing_pairs)}/9 ç»„")
    print(f"   âŒ ç¼ºå¤±: {len(missing_pairs)} ç»„")
    
    if missing_pairs:
        print(f"   ğŸš§ ç¼ºå¤±ç»„åˆ: {', '.join(missing_pairs)}")
    
    # æŒ‰è§’è‰²åˆ†æ
    print(f"\nğŸ­ æŒ‰è§’è‰²åˆ†æ:")
    kimi_as_hinter = summary_df[summary_df['hinter_name'] == 'kimi-k2']
    kimi_as_guesser = summary_df[summary_df['guesser_name'] == 'kimi-k2']
    
    if len(kimi_as_hinter) > 0:
        hinter_success = sum(kimi_as_hinter['success'])
        hinter_rate = hinter_success / len(kimi_as_hinter) * 100
        print(f"   ğŸŒ™ Kimiä½œHinter: {hinter_success}/{len(kimi_as_hinter)} ({hinter_rate:.1f}%)")
    
    if len(kimi_as_guesser) > 0:
        guesser_success = sum(kimi_as_guesser['success'])
        guesser_rate = guesser_success / len(kimi_as_guesser) * 100
        print(f"   ğŸŒ™ Kimiä½œGuesser: {guesser_success}/{len(kimi_as_guesser)} ({guesser_rate:.1f}%)")
    
    # æŒ‰æ¨¡å‹å¯¹åˆ†æ
    print(f"\nğŸ‘¥ å„æ¨¡å‹å¯¹æˆåŠŸç‡:")
    pair_stats = summary_df.groupby('pair_name').agg({
        'success': ['count', 'sum'],
        'turns_used': 'mean'
    }).round(1)
    
    for pair_name in sorted(pair_stats.index):
        count = int(pair_stats.loc[pair_name, ('success', 'count')])
        success = int(pair_stats.loc[pair_name, ('success', 'sum')])
        rate = success / count * 100
        avg_turns = pair_stats.loc[pair_name, ('turns_used', 'mean')]
        
        # æ ‡è®°Kimiçš„è§’è‰²
        if 'kimi-k2â†’' in pair_name:
            role = "(ğŸŒ™H)"
        elif 'â†’kimi-k2' in pair_name:
            role = "(ğŸŒ™G)"
        else:
            role = ""
        
        print(f"   {pair_name:<35} {role:<5}: {success:2d}/{count} ({rate:5.1f}%) å¹³å‡{avg_turns:.1f}è½®")
    
    # å¤±è´¥åŸå› åˆ†æ
    failed_df = summary_df[summary_df['success'] == False]
    if len(failed_df) > 0:
        print(f"\nğŸ“‰ å¤±è´¥åŸå› åˆ†æ ({len(failed_df)}åœºå¤±è´¥):")
        failure_counts = failed_df['failure_reason'].value_counts()
        
        for reason, count in failure_counts.items():
            percentage = count / len(failed_df) * 100
            reason_map = {
                'TABOO_VIOLATION': 'ğŸš« è¿åç¦ç”¨è¯',
                'FORMAT_FAILURE': 'ğŸ”¤ æ ¼å¼é”™è¯¯',
                'API_FAILURE': 'ğŸŒ APIå¤±è´¥',
                'MAX_TURNS_EXCEEDED': 'â±ï¸ è½®æ•°è€—å°½',
                'EXECUTION_ERROR': 'ğŸ’¥ æ‰§è¡Œé”™è¯¯'
            }
            reason_name = reason_map.get(reason, reason)
            print(f"   {reason_name}: {count} åœº ({percentage:.1f}%)")
    
    # æŒ‰è¯æ±‡ç±»åˆ«åˆ†æ
    if 'category' in summary_df.columns:
        print(f"\nğŸ·ï¸ æŒ‰è¯æ±‡ç±»åˆ«æˆåŠŸç‡:")
        category_stats = summary_df.groupby('category').agg({
            'success': ['count', 'sum']
        }).round(1)
        
        for category in sorted(category_stats.index):
            count = int(category_stats.loc[category, ('success', 'count')])
            success = int(category_stats.loc[category, ('success', 'sum')])
            rate = success / count * 100
            print(f"   {category:<12}: {success:3d}/{count:3d} ({rate:5.1f}%)")
    
    # ä¿å­˜æ±‡æ€»æ–‡ä»¶
    summary_file = f"{results_dir}/kimi_experiment_summary_8groups_20250717_125711.csv"
    summary_df.to_csv(summary_file, index=False, encoding='utf-8')
    print(f"\nğŸ’¾ æ±‡æ€»æ–‡ä»¶å·²ä¿å­˜: {os.path.basename(summary_file)}")
    
    print(f"\nğŸ“ ç»“æœç›®å½•: {results_dir}")
    print(f"ğŸ“„ å½“å‰å·²å®Œæˆ {len(existing_pairs)}/9 ç»„å®éªŒ")
    
    if missing_pairs:
        print(f"\nâš ï¸  æ³¨æ„: è¿˜ç¼ºå°‘ {missing_pairs[0]} è¿™ä¸€ç»„å®éªŒ")
        print(f"ğŸ’¡ å»ºè®®: è¿è¡Œnotebookä¸­çš„æ¢å¤ä»£ç æ¥å®Œæˆæœ€åä¸€ç»„å®éªŒ")
    else:
        print(f"\nğŸ‰ æ‰€æœ‰å®éªŒç»„åˆå·²å®Œæˆï¼")

if __name__ == "__main__":
    analyze_kimi_experiment() 