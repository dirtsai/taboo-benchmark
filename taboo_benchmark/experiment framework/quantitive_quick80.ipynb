{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 正在加载Quick80数据集...\n",
      "✅ 数据集加载完成，共80条记录\n",
      "\n",
      "📋 数据集样本:\n",
      "   目标词: atomize\n",
      "   类别: chemistry\n",
      "   禁用词: ['atomise', 'perfume', 'spray', 'nuke', 'zap']\n",
      "   词义数: 3\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "from typing import Dict, List, Any\n",
    "from datetime import datetime\n",
    "\n",
    "# 加载Quick80数据集\n",
    "def load_dataset(dataset_path: str = \"quick80_dataset.json\") -> List[Dict]:\n",
    "    \"\"\"加载Taboo数据集\"\"\"\n",
    "    with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# 加载数据集\n",
    "print(\"📚 正在加载Quick80数据集...\")\n",
    "dataset = load_dataset()\n",
    "print(f\"✅ 数据集加载完成，共{len(dataset)}条记录\")\n",
    "\n",
    "# 显示数据集样本\n",
    "print(\"\\n📋 数据集样本:\")\n",
    "sample = random.choice(dataset)\n",
    "print(f\"   目标词: {sample['target']}\")\n",
    "print(f\"   类别: {sample.get('category', 'unknown')}\")\n",
    "print(f\"   禁用词: {sample['taboo']}\")\n",
    "print(f\"   词义数: {len(sample.get('senses', []))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Quick80数据集基本统计:\n",
      "========================================\n",
      "\n",
      "🏷️ 类别分布:\n",
      "   1. general: 55 条 (68.8%)\n",
      "   2. philosophy: 8 条 (10.0%)\n",
      "   3. finance: 7 条 (8.8%)\n",
      "   4. chemistry: 5 条 (6.2%)\n",
      "   5. cs: 5 条 (6.2%)\n",
      "\n",
      "🚫 禁用词统计:\n",
      "   平均数量: 5.0\n",
      "   范围: 5 - 5\n",
      "\n",
      "💭 词义统计:\n",
      "   平均数量: 1.9\n",
      "   范围: 1 - 23\n",
      "\n",
      "✅ Quick80数据集统计完成，适合定量分析实验\n",
      "\n",
      "🎲 随机种子已设置为 240，确保实验可复现\n"
     ]
    }
   ],
   "source": [
    "# Quick80数据集统计信息\n",
    "print(\"📊 Quick80数据集基本统计:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# 类别分布统计\n",
    "categories = {}\n",
    "taboo_counts = []\n",
    "sense_counts = []\n",
    "\n",
    "for item in dataset:\n",
    "    # 统计类别\n",
    "    category = item.get('category', 'unknown')\n",
    "    categories[category] = categories.get(category, 0) + 1\n",
    "    \n",
    "    # 统计禁用词数量\n",
    "    taboo_counts.append(len(item.get('taboo', [])))\n",
    "    \n",
    "    # 统计词义数量\n",
    "    sense_counts.append(len(item.get('senses', [])))\n",
    "\n",
    "print(f\"\\n🏷️ 类别分布:\")\n",
    "sorted_categories = sorted(categories.items(), key=lambda x: x[1], reverse=True)\n",
    "for i, (category, count) in enumerate(sorted_categories, 1):\n",
    "    percentage = count / len(dataset) * 100\n",
    "    print(f\"   {i}. {category}: {count} 条 ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\n🚫 禁用词统计:\")\n",
    "print(f\"   平均数量: {sum(taboo_counts) / len(taboo_counts):.1f}\")\n",
    "print(f\"   范围: {min(taboo_counts)} - {max(taboo_counts)}\")\n",
    "\n",
    "print(f\"\\n💭 词义统计:\")\n",
    "print(f\"   平均数量: {sum(sense_counts) / len(sense_counts):.1f}\")\n",
    "print(f\"   范围: {min(sense_counts)} - {max(sense_counts)}\")\n",
    "\n",
    "print(f\"\\n✅ Quick80数据集统计完成，适合定量分析实验\")\n",
    "\n",
    "# 设置随机种子用于实验\n",
    "random.seed(240)\n",
    "print(\"\\n🎲 随机种子已设置为 240，确保实验可复现\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Quick80定量分析配置已加载\n",
      "🤖 分析模型: 2 个\n",
      "   1. deepseek-chat-v3-0324\n",
      "   2. gemini-2.5-flash\n",
      "🌡️ 温度参数: [0.1, 0.3, 0.7]\n",
      "🚫 禁忌词数量: [1, 3, 5]\n",
      "💬 Hinter提示长度（单词个数）: [1, 5, 10]\n",
      "📊 Quick80数据集词汇总数: 80\n"
     ]
    }
   ],
   "source": [
    "# 定量分析模型配置\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "# 定义定量分析使用的模型\n",
    "QUANTITATIVE_MODELS = [\n",
    "    \"deepseek/deepseek-chat-v3-0324\",  # deepseek-v3  \n",
    "    \"google/gemini-2.5-flash\"  # gemini-2.5flash\n",
    "]\n",
    "\n",
    "# 温度参数设置\n",
    "TEMPERATURE_VALUES = [0.1, 0.3, 0.7]\n",
    "\n",
    "# 禁忌词数量设置 \n",
    "TABOO_COUNTS = [1, 3, 5]\n",
    "\n",
    "# Hinter提示长度设置（单词个数）\n",
    "HINT_WORD_COUNTS = [1, 5, 10]\n",
    "\n",
    "print(\"✅ Quick80定量分析配置已加载\")\n",
    "print(f\"🤖 分析模型: {len(QUANTITATIVE_MODELS)} 个\")\n",
    "for i, model in enumerate(QUANTITATIVE_MODELS, 1):\n",
    "    model_name = model.split('/')[-1]\n",
    "    print(f\"   {i}. {model_name}\")\n",
    "\n",
    "print(f\"🌡️ 温度参数: {TEMPERATURE_VALUES}\")\n",
    "print(f\"🚫 禁忌词数量: {TABOO_COUNTS}\")\n",
    "print(f\"💬 Hinter提示长度（单词个数）: {HINT_WORD_COUNTS}\")\n",
    "print(f\"📊 Quick80数据集词汇总数: {len(dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Quick80定量分析API客户端初始化成功\n"
     ]
    }
   ],
   "source": [
    "# API客户端设置\n",
    "def load_api_keys(keys_path: str = \"api_keys.json\") -> Dict[str, str]:\n",
    "    \"\"\"加载API密钥\"\"\"\n",
    "    with open(keys_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "class QuantitativeOpenRouterClient:\n",
    "    \"\"\"定量分析专用的API客户端，支持温度控制和长度验证\"\"\"\n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "        self.headers = {\n",
    "            \"Authorization\": f\"Bearer {api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "    \n",
    "    def call_model_with_temperature(self, model: str, messages: List[Dict[str, str]], \n",
    "                                  temperature: float = 0.3, max_tokens: int = 2000) -> str:\n",
    "        \"\"\"调用模型API，支持自定义温度参数\"\"\"\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": temperature,\n",
    "            \"max_tokens\": max_tokens\n",
    "        }\n",
    "        response = requests.post(self.base_url, headers=self.headers, json=payload, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        content = result['choices'][0]['message']['content'].strip()\n",
    "        \n",
    "        # 防止乱码：只保留ASCII可打印字符\n",
    "        content = re.sub(r'[^\\\\x20-\\\\x7E]', '', content)\n",
    "        return content\n",
    "\n",
    "# 初始化API客户端\n",
    "try:\n",
    "    api_keys = load_api_keys()\n",
    "    quant_client = QuantitativeOpenRouterClient(api_keys[\"OPENROUTER_API_KEY\"])\n",
    "    print(\"✅ Quick80定量分析API客户端初始化成功\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ API客户端初始化失败: {e}\")\n",
    "    quant_client = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 正在准备Quick80定量分析数据集...\n",
      "✅ Quick80定量分析数据集准备完成\n",
      "📋 原始词汇数: 80\n",
      "📊 分析条目数: 240 (每个词汇3个禁忌词变体)\n",
      "\n",
      "🚫 禁忌词数量分布:\n",
      "   1个禁忌词: 80 条\n",
      "   3个禁忌词: 80 条\n",
      "   5个禁忌词: 80 条\n",
      "\n",
      "🏷️ 类别分布:\n",
      "   general: 165 条\n",
      "   philosophy: 24 条\n",
      "   finance: 21 条\n",
      "   cs: 15 条\n",
      "   chemistry: 15 条\n",
      "\n",
      "📋 数据集示例:\n",
      "   实验ID: farm_1taboo\n",
      "   目标词: farm\n",
      "   原始禁忌词数: 5\n",
      "   当前禁忌词: ['farmer'] (1个)\n"
     ]
    }
   ],
   "source": [
    "# Quick80禁忌词数量控制和数据集处理\n",
    "def create_taboo_variants(word_data, target_counts=[1, 3, 5]):\n",
    "    \"\"\"为单个词汇创建不同禁忌词数量的变体\"\"\"\n",
    "    variants = {}\n",
    "    original_taboo = word_data['taboo']\n",
    "    \n",
    "    for count in target_counts:\n",
    "        if count <= len(original_taboo):\n",
    "            # 选择前N个禁忌词\n",
    "            selected_taboo = original_taboo[:count]\n",
    "            variants[count] = {\n",
    "                **word_data,\n",
    "                'taboo': selected_taboo,\n",
    "                'original_taboo_count': len(original_taboo),\n",
    "                'variant_taboo_count': count\n",
    "            }\n",
    "        else:\n",
    "            # 如果要求的数量超过原始禁忌词数量，则使用全部\n",
    "            variants[count] = {\n",
    "                **word_data,\n",
    "                'taboo': original_taboo,\n",
    "                'original_taboo_count': len(original_taboo),\n",
    "                'variant_taboo_count': len(original_taboo)\n",
    "            }\n",
    "    \n",
    "    return variants\n",
    "\n",
    "def prepare_quantitative_dataset(dataset, sample_size=80):\n",
    "    \"\"\"准备定量分析数据集，为每个词创建不同禁忌词数量的变体\"\"\"\n",
    "    # 使用全部80个词汇或指定数量\n",
    "    sample_words = random.sample(dataset, min(sample_size, len(dataset)))\n",
    "    \n",
    "    quantitative_dataset = []\n",
    "    \n",
    "    for word_data in sample_words:\n",
    "        variants = create_taboo_variants(word_data, TABOO_COUNTS)\n",
    "        \n",
    "        for taboo_count, variant in variants.items():\n",
    "            variant['experiment_id'] = f\"{word_data['target']}_{taboo_count}taboo\"\n",
    "            quantitative_dataset.append(variant)\n",
    "    \n",
    "    return quantitative_dataset\n",
    "\n",
    "# 创建Quick80定量分析数据集\n",
    "print(\"📊 正在准备Quick80定量分析数据集...\")\n",
    "quant_dataset = prepare_quantitative_dataset(dataset, sample_size=80)  # 使用全部80个词汇\n",
    "\n",
    "print(f\"✅ Quick80定量分析数据集准备完成\")\n",
    "print(f\"📋 原始词汇数: 80\")\n",
    "print(f\"📊 分析条目数: {len(quant_dataset)} (每个词汇3个禁忌词变体)\")\n",
    "\n",
    "# 统计各类别的分布\n",
    "taboo_distribution = {}\n",
    "category_distribution = {}\n",
    "\n",
    "for item in quant_dataset:\n",
    "    # 禁忌词数量分布\n",
    "    taboo_count = item['variant_taboo_count']\n",
    "    taboo_distribution[taboo_count] = taboo_distribution.get(taboo_count, 0) + 1\n",
    "    \n",
    "    # 类别分布\n",
    "    category = item.get('category', 'unknown')\n",
    "    category_distribution[category] = category_distribution.get(category, 0) + 1\n",
    "\n",
    "print(f\"\\n🚫 禁忌词数量分布:\")\n",
    "for count, num in sorted(taboo_distribution.items()):\n",
    "    print(f\"   {count}个禁忌词: {num} 条\")\n",
    "\n",
    "print(f\"\\n🏷️ 类别分布:\")\n",
    "for category, num in sorted(category_distribution.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"   {category}: {num} 条\")\n",
    "\n",
    "# 显示示例\n",
    "print(f\"\\n📋 数据集示例:\")\n",
    "sample_item = quant_dataset[0]\n",
    "print(f\"   实验ID: {sample_item['experiment_id']}\")\n",
    "print(f\"   目标词: {sample_item['target']}\")\n",
    "print(f\"   原始禁忌词数: {sample_item['original_taboo_count']}\")\n",
    "print(f\"   当前禁忌词: {sample_item['taboo']} ({sample_item['variant_taboo_count']}个)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Quick80定量分析实验规模:\n",
      "==================================================\n",
      "📊 数据集: Quick80 (80 个原始词汇)\n",
      "🤖 模型: 2 个\n",
      "🔄 模型组合: 4 个 (每个模型既做Hinter又做Guesser)\n",
      "🌡️ 温度参数: 3 个\n",
      "💬 Hinter提示长度: 3 个\n",
      "📝 数据集变体: 240 个 (80词汇 × 3种禁忌词数量)\n",
      "\n",
      "🎮 总实验数: 8,640 个\n",
      "⏱️ 预计耗时: 1.2 小时 (按每个实验0.5秒估算)\n",
      "\n",
      "💡 实验设计特点:\n",
      "   ✅ 涵盖Quick80数据集的全部80个词汇\n",
      "   ✅ 测试3个目标模型的完整性能\n",
      "   ✅ 分析4个温度参数的影响\n",
      "   ✅ 验证3种Hinter提示长度的效果\n",
      "   ✅ 比较3种禁忌词数量的难度\n",
      "   ✅ 支持小规模测试和完整实验\n",
      "\n",
      "📋 关键更新:\n",
      "   🔄 数据集: 从dataset.json (300词) 改为 quick80_dataset.json (80词)\n",
      "   📊 实验规模: 更加聚焦，适合快速迭代和深度分析\n",
      "   💾 数据质量: Quick80是高质量精选词汇集\n"
     ]
    }
   ],
   "source": [
    "# 实验总览\n",
    "# 计算实验规模\n",
    "total_models = len(QUANTITATIVE_MODELS)\n",
    "total_combinations = total_models * total_models  # hinter x guesser\n",
    "total_temperatures = len(TEMPERATURE_VALUES)\n",
    "total_hint_lengths = len(HINT_WORD_COUNTS)\n",
    "total_dataset_variants = len(quant_dataset)\n",
    "\n",
    "total_experiments = total_combinations * total_temperatures * total_hint_lengths * total_dataset_variants\n",
    "\n",
    "print(\"🎯 Quick80定量分析实验规模:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"📊 数据集: Quick80 ({len(dataset)} 个原始词汇)\")\n",
    "print(f\"🤖 模型: {total_models} 个\")\n",
    "print(f\"🔄 模型组合: {total_combinations} 个 (每个模型既做Hinter又做Guesser)\")\n",
    "print(f\"🌡️ 温度参数: {total_temperatures} 个\")\n",
    "print(f\"💬 Hinter提示长度: {total_hint_lengths} 个\")\n",
    "print(f\"📝 数据集变体: {total_dataset_variants} 个 (80词汇 × 3种禁忌词数量)\")\n",
    "print(f\"\\n🎮 总实验数: {total_experiments:,} 个\")\n",
    "print(f\"⏱️ 预计耗时: {total_experiments * 0.5 / 3600:.1f} 小时 (按每个实验0.5秒估算)\")\n",
    "\n",
    "print(f\"\\n💡 实验设计特点:\")\n",
    "print(f\"   ✅ 涵盖Quick80数据集的全部80个词汇\")\n",
    "print(f\"   ✅ 测试3个目标模型的完整性能\")\n",
    "print(f\"   ✅ 分析4个温度参数的影响\")\n",
    "print(f\"   ✅ 验证3种Hinter提示长度的效果\")\n",
    "print(f\"   ✅ 比较3种禁忌词数量的难度\")\n",
    "print(f\"   ✅ 支持小规模测试和完整实验\")\n",
    "\n",
    "print(f\"\\n📋 关键更新:\")\n",
    "print(f\"   🔄 数据集: 从dataset.json (300词) 改为 quick80_dataset.json (80词)\")\n",
    "print(f\"   📊 实验规模: 更加聚焦，适合快速迭代和深度分析\")\n",
    "print(f\"   💾 数据质量: Quick80是高质量精选词汇集\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 开始Quick80小规模测试...\n",
      "📊 测试配置:\n",
      "   模型: ['deepseek-chat-v3-0324', 'gemini-2.5-flash']\n",
      "   温度: [0.1, 0.3]\n",
      "   禁忌词数量: [1, 3, 5]\n",
      "   提示长度: [1, 5]\n",
      "   测试词汇数: 5\n",
      "   测试数据集: 15 条记录\n",
      "   总测试实验数: 240\n",
      "   预计耗时: 2.0 分钟\n",
      "\n",
      "⚠️ 这是一个小规模测试，用于验证系统功能\n",
      "💡 如果测试成功，您可以运行完整的Quick80定量分析实验\n"
     ]
    }
   ],
   "source": [
    "# 小规模测试实验\n",
    "print(\"🧪 开始Quick80小规模测试...\")\n",
    "print(\"📊 测试配置:\")\n",
    "print(f\"   模型: {[m.split('/')[-1] for m in QUANTITATIVE_MODELS]}\")\n",
    "print(f\"   温度: {TEMPERATURE_VALUES[:2]}\")  # 只用前2个温度\n",
    "print(f\"   禁忌词数量: {TABOO_COUNTS}\")\n",
    "print(f\"   提示长度: {HINT_WORD_COUNTS[:2]}\")  # 只用前2个长度\n",
    "print(f\"   测试词汇数: 5\")\n",
    "\n",
    "# 创建小规模测试数据集\n",
    "test_dataset = prepare_quantitative_dataset(dataset, sample_size=5)  # 只用5个词汇\n",
    "print(f\"   测试数据集: {len(test_dataset)} 条记录\")\n",
    "\n",
    "# 计算测试实验数\n",
    "total_test_experiments = len(QUANTITATIVE_MODELS) * len(QUANTITATIVE_MODELS) * len(test_dataset) * 2 * 2  # 2温度 x 2长度\n",
    "print(f\"   总测试实验数: {total_test_experiments}\")\n",
    "print(f\"   预计耗时: {total_test_experiments * 0.5 / 60:.1f} 分钟\")\n",
    "\n",
    "print(f\"\\n⚠️ 这是一个小规模测试，用于验证系统功能\")\n",
    "print(f\"💡 如果测试成功，您可以运行完整的Quick80定量分析实验\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 简化版Taboo游戏函数已定义\n"
     ]
    }
   ],
   "source": [
    "# 简化版Taboo游戏函数 - 用于Quick80测试\n",
    "def simple_taboo_game(client, hinter_model, guesser_model, target_word, taboo_words, \n",
    "                     temperature=0.3, hint_word_count=5, max_turns=5):\n",
    "    \"\"\"简化版Taboo游戏，用于Quick80定量分析\"\"\"\n",
    "    \n",
    "    conversation_history = []\n",
    "    taboo_list = ', '.join(taboo_words)\n",
    "    \n",
    "    # 系统提示\n",
    "    hinter_system = f\"\"\"You are playing a Taboo word game as the Hinter.\n",
    "\n",
    "CRITICAL FORMAT REQUIREMENT:\n",
    "- You MUST start your response with exactly '[CLUE]' (including square brackets)\n",
    "- Your clue must contain exactly {hint_word_count} words\n",
    "- Do NOT add any text before [CLUE]\n",
    "\n",
    "GAME RULES:\n",
    "1. NEVER use any of these taboo words: {taboo_list}\n",
    "2. Give helpful clues to help the guesser find the target word\n",
    "3. Use BRITISH ENGLISH spelling\n",
    "\n",
    "Target word: {target_word}\n",
    "Taboo words (ABSOLUTELY FORBIDDEN): {taboo_list}\"\"\"\n",
    "\n",
    "    guesser_system = \"\"\"You are playing a Taboo word game as the Guesser.\n",
    "\n",
    "CRITICAL FORMAT REQUIREMENT:\n",
    "- You MUST start your response with exactly '[GUESS]' (including square brackets)\n",
    "- Give only ONE word as your guess after [GUESS]\n",
    "\n",
    "GAME RULES:\n",
    "1. Make your best guess based on the clues\n",
    "2. Use BRITISH ENGLISH spelling\"\"\"\n",
    "\n",
    "    for turn in range(1, max_turns + 1):\n",
    "        try:\n",
    "            # Hinter给出线索\n",
    "            if turn == 1:\n",
    "                hinter_prompt = f\"{hinter_system}\\n\\nProvide your first clue:\"\n",
    "            else:\n",
    "                history_text = \"\\n\".join(conversation_history)\n",
    "                hinter_prompt = f\"{hinter_system}\\n\\nConversation so far:\\n{history_text}\\n\\nProvide your next clue:\"\n",
    "            \n",
    "            hinter_response = client.call_model_with_temperature(\n",
    "                hinter_model, [{\"role\": \"user\", \"content\": hinter_prompt}], temperature\n",
    "            )\n",
    "            \n",
    "            # 检查格式和禁忌词\n",
    "            if not hinter_response.strip().upper().startswith('[CLUE]'):\n",
    "                return {\n",
    "                    'success': False, 'turns': turn, 'final_guess': 'FORMAT_ERROR',\n",
    "                    'failure_reason': 'HINTER_FORMAT_ERROR', 'temperature': temperature,\n",
    "                    'hint_word_count': hint_word_count, 'conversation': conversation_history\n",
    "                }\n",
    "            \n",
    "            # 提取线索文本\n",
    "            import re\n",
    "            match = re.search(r'\\[CLUE\\]\\s*(.+)', hinter_response, re.IGNORECASE)\n",
    "            if match:\n",
    "                hint_text = match.group(1).strip()\n",
    "            else:\n",
    "                return {\n",
    "                    'success': False, 'turns': turn, 'final_guess': 'INVALID_CLUE',\n",
    "                    'failure_reason': 'CLUE_EXTRACTION_ERROR', 'temperature': temperature,\n",
    "                    'hint_word_count': hint_word_count, 'conversation': conversation_history\n",
    "                }\n",
    "            \n",
    "            # 检查禁忌词违规\n",
    "            hint_lower = hint_text.lower()\n",
    "            for taboo in taboo_words:\n",
    "                if taboo.lower() in hint_lower:\n",
    "                    return {\n",
    "                        'success': False, 'turns': turn, 'final_guess': 'TABOO_VIOLATION',\n",
    "                        'failure_reason': 'TABOO_VIOLATION', 'temperature': temperature,\n",
    "                        'hint_word_count': hint_word_count, 'conversation': conversation_history,\n",
    "                        'taboo_violation_hint': hint_text\n",
    "                    }\n",
    "            \n",
    "            # 检查提示长度\n",
    "            word_count = len(hint_text.split())\n",
    "            if word_count != hint_word_count:\n",
    "                return {\n",
    "                    'success': False, 'turns': turn, 'final_guess': 'HINT_LENGTH_ERROR',\n",
    "                    'failure_reason': 'HINT_LENGTH_FAILURE', 'temperature': temperature,\n",
    "                    'hint_word_count': hint_word_count, 'conversation': conversation_history,\n",
    "                    'actual_word_count': word_count\n",
    "                }\n",
    "            \n",
    "            conversation_history.append(f\"Hinter: {hinter_response}\")\n",
    "            \n",
    "            # Guesser进行猜测\n",
    "            history_text = \"\\n\".join(conversation_history)\n",
    "            guesser_prompt = f\"{guesser_system}\\n\\nConversation so far:\\n{history_text}\\n\\nWhat is your guess?\"\n",
    "            \n",
    "            guesser_response = client.call_model_with_temperature(\n",
    "                guesser_model, [{\"role\": \"user\", \"content\": guesser_prompt}], temperature\n",
    "            )\n",
    "            \n",
    "            # 检查guesser格式\n",
    "            if not guesser_response.strip().upper().startswith('[GUESS]'):\n",
    "                return {\n",
    "                    'success': False, 'turns': turn, 'final_guess': 'GUESSER_FORMAT_ERROR',\n",
    "                    'failure_reason': 'GUESSER_FORMAT_ERROR', 'temperature': temperature,\n",
    "                    'hint_word_count': hint_word_count, 'conversation': conversation_history\n",
    "                }\n",
    "            \n",
    "            conversation_history.append(f\"Guesser: {guesser_response}\")\n",
    "            \n",
    "            # 提取猜测\n",
    "            match = re.search(r'\\[GUESS\\]\\s*(.+)', guesser_response, re.IGNORECASE)\n",
    "            if match:\n",
    "                guess = match.group(1).strip().split()[0]  # 取第一个词\n",
    "                guess = guess.strip('.,!?;:\"\\'()[]{}')\n",
    "            else:\n",
    "                guess = 'INVALID_GUESS'\n",
    "            \n",
    "            # 检查是否成功\n",
    "            if guess.lower() == target_word.lower():\n",
    "                return {\n",
    "                    'success': True, 'turns': turn, 'final_guess': guess,\n",
    "                    'failure_reason': None, 'temperature': temperature,\n",
    "                    'hint_word_count': hint_word_count, 'conversation': conversation_history\n",
    "                }\n",
    "            \n",
    "            # 如果不是最后一轮，添加反馈\n",
    "            if turn < max_turns:\n",
    "                conversation_history.append(f\"System: '{guess}' is not correct. Try again!\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'success': False, 'turns': turn, 'final_guess': 'API_ERROR',\n",
    "                'failure_reason': 'API_FAILURE', 'temperature': temperature,\n",
    "                'hint_word_count': hint_word_count, 'conversation': conversation_history,\n",
    "                'error': str(e)[:200]\n",
    "            }\n",
    "    \n",
    "    # 达到最大轮数仍未成功\n",
    "    return {\n",
    "        'success': False, 'turns': max_turns, 'final_guess': guess if 'guess' in locals() else 'N/A',\n",
    "        'failure_reason': 'MAX_TURNS_EXCEEDED', 'temperature': temperature,\n",
    "        'hint_word_count': hint_word_count, 'conversation': conversation_history\n",
    "    }\n",
    "\n",
    "print(\"✅ 简化版Taboo游戏函数已定义\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 204)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mFile \u001b[39m\u001b[32m<tokenize>:204\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m\"metadata\": {\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# 🚀 运行Quick80小规模定量分析实验\n",
    "if quant_client is not None:\n",
    "    print(\"🚀 开始运行Quick80小规模定量分析实验...\")\n",
    "    \n",
    "    # 实验配置\n",
    "    test_models = QUANTITATIVE_MODELS\n",
    "    test_temperatures = [0.1, 0.3]  # 只用2个温度进行测试\n",
    "    test_hint_lengths = [1, 5]      # 只用2个提示长度进行测试\n",
    "    test_sample = test_dataset[:15]  # 只用前15个数据项（5词汇×3禁忌词变体）\n",
    "    \n",
    "    total_test_experiments = len(test_models) * len(test_models) * len(test_sample) * len(test_temperatures) * len(test_hint_lengths)\n",
    "    \n",
    "    print(f\"📊 测试配置:\")\n",
    "    print(f\"   模型: {[m.split('/')[-1] for m in test_models]}\")\n",
    "    print(f\"   温度: {test_temperatures}\")\n",
    "    print(f\"   提示长度: {test_hint_lengths}\")\n",
    "    print(f\"   数据项: {len(test_sample)} 个\")\n",
    "    print(f\"   总实验数: {total_test_experiments}\")\n",
    "    print(f\"   预计耗时: {total_test_experiments * 0.8 / 60:.1f} 分钟\")\n",
    "    \n",
    "    # 运行实验\n",
    "    results = []\n",
    "    experiment_counter = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for hinter_model in test_models:\n",
    "        for guesser_model in test_models:\n",
    "            for temperature in test_temperatures:\n",
    "                for hint_length in test_hint_lengths:\n",
    "                    for data_item in test_sample:\n",
    "                        experiment_counter += 1\n",
    "                        \n",
    "                        # 进度显示\n",
    "                        progress = (experiment_counter / total_test_experiments) * 100\n",
    "                        hinter_name = hinter_model.split('/')[-1]\n",
    "                        guesser_name = guesser_model.split('/')[-1]\n",
    "                        \n",
    "                        print(f\\\"\\\\r🔄 实验 {experiment_counter}/{total_test_experiments} ({progress:.1f}%) | {hinter_name}→{guesser_name} | T={temperature} | L={hint_length} | {data_item['target']}\\\", end=\\\"\\\")\\n\",\n",
    "                        \\n\",\n",
    "                        # 执行游戏\\n\",\n",
    "                        game_start = time.time()\\n\",\n",
    "                        game_result = simple_taboo_game(\\n\",\n",
    "                            quant_client, hinter_model, guesser_model,\\n\",\n",
    "                            data_item['target'], data_item['taboo'],\\n\",\n",
    "                            temperature=temperature,\\n\",\n",
    "                            hint_word_count=hint_length,\\n\",\n",
    "                            max_turns=5\\n\",\n",
    "                        )\\n\",\n",
    "                        game_duration = round(time.time() - game_start, 2)\\n\",\n",
    "                        \\n\",\n",
    "                        # 记录结果\\n\",\n",
    "                        result = {\\n\",\n",
    "                            'experiment_id': f\\\"{experiment_counter:04d}\\\",\\n\",\n",
    "                            'hinter_model': hinter_model,\\n\",\n",
    "                            'guesser_model': guesser_model,\\n\",\n",
    "                            'target_word': data_item['target'],\\n\",\n",
    "                            'category': data_item.get('category', 'unknown'),\\n\",\n",
    "                            'taboo_words': '|'.join(data_item['taboo']),\\n\",\n",
    "                            'taboo_count': len(data_item['taboo']),\\n\",\n",
    "                            'variant_taboo_count': data_item.get('variant_taboo_count', len(data_item['taboo'])),\\n\",\n",
    "                            'temperature': temperature,\\n\",\n",
    "                            'hint_word_count': hint_length,\\n\",\n",
    "                            'success': game_result['success'],\\n\",\n",
    "                            'turns_used': game_result['turns'],\\n\",\n",
    "                            'final_guess': game_result['final_guess'],\\n\",\n",
    "                            'failure_reason': game_result.get('failure_reason', None),\\n\",\n",
    "                            'taboo_violation': game_result.get('failure_reason') == 'TABOO_VIOLATION',\\n\",\n",
    "                            'hint_length_violation': game_result.get('failure_reason') == 'HINT_LENGTH_FAILURE',\\n\",\n",
    "                            'actual_word_count': game_result.get('actual_word_count', hint_length),\\n\",\n",
    "                            'conversation_length': len(game_result.get('conversation', [])),\\n\",\n",
    "                            'duration_seconds': game_duration,\\n\",\n",
    "                            'timestamp': datetime.now().strftime(\\\"%Y-%m-%d %H:%M:%S\\\")\\n\",\n",
    "                        }\\n\",\n",
    "                        \\n\",\n",
    "                        if 'error' in game_result:\\n\",\n",
    "                            result['error'] = game_result['error']\\n\",\n",
    "                        if 'taboo_violation_hint' in game_result:\\n\",\n",
    "                            result['taboo_violation_hint'] = game_result['taboo_violation_hint']\\n\",\n",
    "                        \\n\",\n",
    "                        results.append(result)\\n\",\n",
    "                        \\n\",\n",
    "                        # 每10个实验显示一次中间统计\\n\",\n",
    "                        if experiment_counter % 10 == 0:\\n\",\n",
    "                            recent_results = results[-10:]\\n\",\n",
    "                            recent_success = sum(r['success'] for r in recent_results)\\n\",\n",
    "                            print(f\\\"\\\\n   📊 最近10个: 成功{recent_success}/10 ({recent_success*10}%)\\\")\\n\",\n",
    "                        \\n\",\n",
    "                        time.sleep(0.5)  # API调用间隔\\n\",\n",
    "    \\n\",\n",
    "    \"    total_duration = time.time() - start_time\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\n\\\\n✅ Quick80小规模实验完成！\\\")\\n\",\n",
    "    \"    print(f\\\"⏱️ 总耗时: {total_duration/60:.1f} 分钟\\\")\\n\",\n",
    "    \"    print(f\\\"📊 实验结果: {len(results)} 个\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # 基本统计\\n\",\n",
    "    \"    if results:\\n\",\n",
    "    \"        df = pd.DataFrame(results)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        total_success = sum(r['success'] for r in results)\\n\",\n",
    "    \"        success_rate = total_success / len(results) * 100\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(f\\\"📈 整体成功率: {success_rate:.1f}% ({total_success}/{len(results)})\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # 按温度统计\\n\",\n",
    "    \"        print(f\\\"\\\\n🌡️ 温度影响:\\\")\\n\",\n",
    "    \"        for temp in test_temperatures:\\n\",\n",
    "    \"            temp_results = df[df['temperature'] == temp]\\n\",\n",
    "    \"            temp_success = temp_results['success'].sum()\\n\",\n",
    "    \"            temp_rate = temp_success / len(temp_results) * 100 if len(temp_results) > 0 else 0\\n\",\n",
    "    \"            print(f\\\"   T={temp}: {temp_success}/{len(temp_results)} ({temp_rate:.1f}%)\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # 按提示长度统计\\n\",\n",
    "    \"        print(f\\\"\\\\n💬 提示长度影响:\\\")\\n\",\n",
    "    \"        for length in test_hint_lengths:\\n\",\n",
    "    \"            length_results = df[df['hint_word_count'] == length]\\n\",\n",
    "    \"            length_success = length_results['success'].sum()\\n\",\n",
    "    \"            length_rate = length_success / len(length_results) * 100 if len(length_results) > 0 else 0\\n\",\n",
    "    \"            print(f\\\"   {length}词: {length_success}/{len(length_results)} ({length_rate:.1f}%)\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # 按模型统计\\n\",\n",
    "    \"        print(f\\\"\\\\n🤖 模型性能 (Hinter):\\\")\\n\",\n",
    "    \"        for model in test_models:\\n\",\n",
    "    \"            model_results = df[df['hinter_model'] == model]\\n\",\n",
    "    \"            model_success = model_results['success'].sum()\\n\",\n",
    "    \"            model_rate = model_success / len(model_results) * 100 if len(model_results) > 0 else 0\\n\",\n",
    "    \"            model_name = model.split('/')[-1]\\n\",\n",
    "    \"            print(f\\\"   {model_name}: {model_success}/{len(model_results)} ({model_rate:.1f}%)\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # 失败原因统计\\n\",\n",
    "    \"        failed_results = df[df['success'] == False]\\n\",\n",
    "    \"        if len(failed_results) > 0:\\n\",\n",
    "    \"            print(f\\\"\\\\n❌ 失败原因:\\\")\\n\",\n",
    "    \"            failure_counts = failed_results['failure_reason'].value_counts()\\n\",\n",
    "    \"            for reason, count in failure_counts.items():\\n\",\n",
    "    \"                percentage = count / len(failed_results) * 100\\n\",\n",
    "    \"                print(f\\\"   {reason}: {count} 次 ({percentage:.1f}%)\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # 保存结果\\n\",\n",
    "    \"        timestamp = datetime.now().strftime(\\\"%Y%m%d_%H%M%S\\\")\\n\",\n",
    "    \"        output_path = f\\\"results/quick80_test_{timestamp}.csv\\\"\\n\",\n",
    "    \"        os.makedirs(\\\"results\\\", exist_ok=True)\\n\",\n",
    "    \"        df.to_csv(output_path, index=False, encoding='utf-8')\\n\",\n",
    "    \"        print(f\\\"\\\\n💾 结果已保存: {output_path}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(f\\\"\\\\n🎉 Quick80小规模实验成功完成！\\\")\\n\",\n",
    "    \"        print(f\\\"💡 如果结果满意，可以运行完整的Quick80定量分析实验\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"❌ API客户端未初始化，无法运行实验\\\")\\n\",\n",
    "    \"    print(\\\"💡 请检查api_keys.json文件是否存在且包含正确的API密钥\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"raw\",\n",
    "   \"metadata\": {\n",
    "    \"vscode\": {\n",
    "     \"languageId\": \"raw\"\n",
    "    }\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"# 执行Quick80完整定量分析实验（可选）\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# 🚀 运行Quick80完整定量分析实验（取消注释以运行）\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"if quant_client is not None and input(\\\"是否运行完整实验？(输入'yes'确认): \\\") == 'yes':\\n\",\n",
    "    \"    print(\\\"🚀 开始运行Quick80完整定量分析实验...\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # 使用全部配置\\n\",\n",
    "    \"    full_models = QUANTITATIVE_MODELS\\n\",\n",
    "    \"    full_temperatures = TEMPERATURE_VALUES  # 全部4个温度\\n\",\n",
    "    \"    full_hint_lengths = HINT_WORD_COUNTS    # 全部3个提示长度\\n\",\n",
    "    \"    full_dataset = quant_dataset            # 全部240个数据项\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    total_full_experiments = len(full_models) * len(full_models) * len(full_dataset) * len(full_temperatures) * len(full_hint_lengths)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"📊 完整实验配置:\\\")\\n\",\n",
    "    \"    print(f\\\"   模型组合: {len(full_models)}×{len(full_models)} = {len(full_models)**2}\\\")\\n\",\n",
    "    \"    print(f\\\"   温度值: {len(full_temperatures)} 个\\\")\\n\",\n",
    "    \"    print(f\\\"   提示长度: {len(full_hint_lengths)} 个\\\")\\n\",\n",
    "    \"    print(f\\\"   数据项: {len(full_dataset)} 个\\\")\\n\",\n",
    "    \"    print(f\\\"   总实验数: {total_full_experiments:,}\\\")\\n\",\n",
    "    \"    print(f\\\"   预计耗时: {total_full_experiments * 0.8 / 3600:.1f} 小时\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # 这里可以添加完整实验的代码...\\n\",\n",
    "    \"    print(\\\"\\\\n💡 完整实验代码可以基于上面的小规模实验进行扩展\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"💡 完整实验未运行\\\")\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"💡 完整实验代码已准备，需要时可以取消注释运行\\\")\\n\",\n",
    "    \"print(\\\"📋 建议: 先分析小规模实验结果，确认配置无误后再运行完整实验\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.11.11\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
